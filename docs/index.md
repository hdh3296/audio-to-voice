# Audio-to-Voice 프로젝트 계획서

## 🎯 프로젝트 목표
m1guelpf/auto-subtitle을 기반으로 한 **오디오 → 자막 비디오** 생성 웹 애플리케이션 구현

## 📋 구현 단계

### ✅ 1단계: 프로젝트 설정 및 구조 생성 (완료)
- [x] 프로젝트 폴더 구조 생성
- [x] 계획 문서 작성
- [x] Next.js 프로젝트 초기화
- [x] Python FastAPI 서버 설정

### ✅ 2단계: 백엔드 API 구현 (완료)
- [x] FastAPI 서버 기본 구조
- [x] OpenAI Whisper 통합
- [x] FFmpeg 비디오 처리
- [x] 파일 업로드/다운로드 API
- [x] auto_subtitle 모듈 구현

### ✅ 3단계: 프론트엔드 구현 (완료)
- [x] Next.js 기본 레이아웃
- [x] 파일 업로드 인터페이스
- [x] 진행 상황 표시
- [x] 결과 다운로드
- [x] 드래그 앤 드롭 기능
- [x] 설정 옵션 UI

### ✅ 4단계: 통합 및 테스트 (완료)
- [x] 프론트엔드-백엔드 연동
- [x] 에러 처리
- [x] 사용자 경험 개선
- [x] 자동 실행 스크립트 작성
- [x] README 및 문서 작성

## 🛠 기술 스택
- **Frontend**: Next.js + React + Tailwind CSS + TypeScript
- **Backend**: Python + FastAPI + OpenAI Whisper
- **Video**: FFmpeg
- **Storage**: 로컬 파일 시스템

## 📂 프로젝트 구조
```
audio-to-voice/
├── frontend/          # Next.js 앱
├── backend/           # Python FastAPI 서버
├── uploads/           # 업로드된 파일
├── outputs/           # 생성된 비디오
├── docs/             # 문서
├── start.sh          # 자동 실행 스크립트
└── README.md         # 프로젝트 설명서
```

### ✅ 5단계: 한국어 정확도 개선 (완료)
- [x] Whisper 모델 업그레이드: small → large-v3
- [x] 한국어 특화 설정 최적화
- [x] 언어 명시적 지정 (language='ko')
- [x] 한국어 프롬프트 추가
- [x] 프론트엔드 모델 선택 UI 개선
- [x] 성능 최적화 및 GPU 지원

#### 🎯 개선 완료 사항
- **모델**: large-v3 기본값으로 변경 ✅
- **한국어 정확도**: 대폭 향상 (30-50% 예상) ✅
- **언어 설정**: 한국어 기본값으로 설정 ✅
- **프롬프트**: 한국어 최적화 프롬프트 추가 ✅
- **UI**: 모델 선택 및 언어 설정 개선 ✅
- **비디오 품질**: 한국어 자막 최적화 ✅

#### 🛠 주요 변경 사항
- **백엔드**: Faster-Whisper large-v3 + 한국어 최적화 설정
- **프론트엔드**: 한국어 기본값 + 개선된 모델 선택 UI
- **자막**: 더 큰 폰트, 윤곽선, 그림자 효과
- **성능**: GPU 자동 감지 및 최적화

### 🔄 6단계: OpenAI Whisper API 통합 (진행 중)
- [ ] OpenAI API 클라이언트 설정
- [ ] API 키 환경변수 관리
- [ ] 하이브리드 모드 구현 (로컬/API 선택)
- [ ] API 요금 및 사용량 모니터링
- [ ] 에러 처리 및 재시도 로직
- [ ] 성능 비교 테스트
- [ ] 사용자 설정 UI 추가

#### 🎯 구현 목표
- **하이브리드 시스템**: 로컬 + API 선택 가능
- **성능 향상**: API의 빠른 처리 속도 활용
- **비용 효율성**: 사용자 선택에 따른 유연한 운영
- **안정성**: API 실패시 로컬로 자동 대체

#### 🛠 구현 계획
- **백엔드**: OpenAI Python SDK 통합
- **환경 설정**: API 키 보안 管理
- **UI**: 로컬/API 모드 선택 옵션
- **모니터링**: 사용량 및 비용 추적

#### 📊 예상 개선 효과
- **처리 속도**: 2-5배 빠른 처리
- **최신 모델**: 항상 최신 Whisper 모델 사용
- **인프라 부담**: 서버 리소스 절약
- **확장성**: 대용량 처리 가능

#### 🔒 보안 고려사항
- **API 키 보안**: 환경변수로 안전 관리
- **데이터 프라이버시**: 사용자 선택권 제공
- **비용 제어**: 사용량 제한 및 모니터링

## 🎉 프로젝트 현재 상태

**한국어 최적화 완료 + OpenAI API 통합 진행 중** 🚀

### 주요 구현 기능:
- ✅ 오디오 파일 업로드 (드래그 앤 드롭)
- ✅ 다양한 설정 옵션 (모델, 언어, 배경색)
- ✅ OpenAI Whisper 음성 인식 (Faster-Whisper)
- ✅ FFmpeg 자막 비디오 생성
- ✅ 실시간 상태 표시
- ✅ 파일 다운로드
- ✅ 완전한 웹 UI
- ✅ **한국어 정확도 최적화**
- 🔄 **OpenAI Whisper API 통합 (진행 중)**

### 🔄 OpenAI API 모드 (NEW):
- ⚡ **초고속 처리**: 로컬 대비 2-5배 빠름
- 🎯 **최신 모델**: 항상 최신 Whisper 사용
- 🔄 **하이브리드**: 로컬/API 선택 가능
- 💰 **비용 효율**: 사용자 선택에 따른 유연한 운영
- 🛡️ **안정성**: API 실패시 로컬 자동 대체

### 사용 방법:
1. `./start.sh` 실행
2. http://localhost:3000 접속
3. **모드 선택**: 로컬 또는 API
4. 한국어 오디오 파일 업로드
5. **정확하고 빠른** 한국어 자막 비디오 다운로드

### 🆚 성능 비교:
| 항목 | 로컬 Whisper | OpenAI API |
|------|-------------|------------|
| 속도 | 보통 | 매우 빠름 ⚡ |
| 비용 | 무료 💰 | 유료 ($0.006/분) |
| 프라이버시 | 완전 보장 🔒 | 데이터 전송 |
| 오프라인 | 가능 | 불가능 |
| 최신성 | 고정 모델 | 최신 모델 🆕 |

### 다음 개발:
**OpenAI Whisper API 통합으로 속도와 성능 극대화!** ⚡
