"""
OpenAI Whisper API ì¼ê´€ì„± ê°œì„  í´ë¼ì´ì–¸íŠ¸
temperature=0, seed, prompt ë“±ì„ í™œìš©í•œ ê²°ê³¼ ì•ˆì •í™”
"""
import asyncio
import os
import tempfile
from typing import List, Dict, Optional, Tuple
from datetime import datetime
import aiofiles
from dotenv import load_dotenv
from openai import OpenAI
import logging
import hashlib

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class StableOpenAIWhisperClient:
    """ì¼ê´€ëœ ê²°ê³¼ë¥¼ ìœ„í•œ OpenAI Whisper API í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self):
        self.client: Optional[OpenAI] = None
        self.api_key: Optional[str] = None
        self.max_audio_length: int = 10
        self._load_environment()
    
    def _load_environment(self):
        """í™˜ê²½ë³€ìˆ˜ ë¡œë“œ"""
        try:
            load_dotenv()
            self.api_key = os.getenv("OPENAI_API_KEY")
            self.max_audio_length = int(os.getenv("MAX_AUDIO_LENGTH_MINUTES", "10"))
            
            if self.api_key and self.api_key != "your_openai_api_key_here":
                self.client = OpenAI(api_key=self.api_key)
                logger.info("âœ… OpenAI API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (ì•ˆì •í™” ëª¨ë“œ)")
            else:
                logger.warning("âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
        except Exception as e:
            logger.error(f"âŒ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def is_available(self) -> bool:
        """API ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        return self.client is not None
    
    def generate_file_seed(self, file_path: str) -> int:
        """íŒŒì¼ ê²½ë¡œ ê¸°ë°˜ ì¼ê´€ëœ ì‹œë“œ ìƒì„±"""
        # íŒŒì¼ ê²½ë¡œì™€ íŒŒì¼ í¬ê¸°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê³ ìœ í•œ ì‹œë“œ ìƒì„±
        file_size = os.path.getsize(file_path)
        seed_string = f"{file_path}_{file_size}"
        seed_hash = hashlib.md5(seed_string.encode()).hexdigest()
        # í•´ì‹œë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜ (OpenAI seedëŠ” ì •ìˆ˜ì—¬ì•¼ í•¨)
        return int(seed_hash[:8], 16) % (2**31 - 1)  # 32ë¹„íŠ¸ ì •ìˆ˜ ë²”ìœ„
    
    def create_consistent_prompt(self, language: str = "ko") -> str:
        """ì¼ê´€ëœ ê²°ê³¼ë¥¼ ìœ„í•œ ìƒì„¸í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        if language == "ko":
            return """ë‹¤ìŒì€ í•œêµ­ì–´ ìŒì„±ì…ë‹ˆë‹¤. ì •í™•í•œ í•œêµ­ì–´ í‘œì¤€ì–´ë¡œ ì „ì‚¬í•´ì£¼ì„¸ìš”. 
ë¬¸ì¥ ë¶€í˜¸ëŠ” ìì—°ìŠ¤ëŸ½ê²Œ ì‚¬ìš©í•˜ê³ , ë„ì–´ì“°ê¸°ëŠ” í•œêµ­ì–´ ë§ì¶¤ë²•ì— ë§ê²Œ í•´ì£¼ì„¸ìš”. 
ë¸Œëœë“œëª…ì´ë‚˜ ê³ ìœ ëª…ì‚¬ëŠ” ì •í™•í•˜ê²Œ í‘œê¸°í•´ì£¼ì„¸ìš”."""
        else:
            return "Please transcribe this audio accurately with proper punctuation and spacing."
    
    async def transcribe_audio_stable(
        self, 
        audio_path: str, 
        language: str = "ko",
        use_deterministic: bool = True
    ) -> Dict:
        """ì•ˆì •í™”ëœ OpenAI API ì „ì‚¬ (ì¼ê´€ëœ ê²°ê³¼)"""
        try:
            if not self.is_available():
                raise Exception("OpenAI API í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
            
            logger.info(f"ğŸ¯ ì•ˆì •í™” ëª¨ë“œ OpenAI API ì „ì‚¬ ì‹œì‘: {audio_path}")
            
            # íŒŒì¼ í¬ê¸° í™•ì¸
            file_size_mb = os.path.getsize(audio_path) / (1024 * 1024)
            if file_size_mb > 25:
                raise Exception(f"íŒŒì¼ í¬ê¸° ì œí•œ ì´ˆê³¼: {file_size_mb:.1f}MB > 25MB")
            
            # ì¼ê´€ì„±ì„ ìœ„í•œ íŒŒë¼ë¯¸í„° ì„¤ì •
            consistent_prompt = self.create_consistent_prompt(language)
            file_seed = self.generate_file_seed(audio_path) if use_deterministic else None
            
            def _stable_api_call():
                with open(audio_path, "rb") as audio_file:
                    # ì¼ê´€ì„± í–¥ìƒì„ ìœ„í•œ íŒŒë¼ë¯¸í„° ì¡°í•©
                    params = {
                        "model": "whisper-1",
                        "file": audio_file,
                        "language": language,
                        "response_format": "verbose_json",
                        "timestamp_granularities": ["segment"],
                        "prompt": consistent_prompt,  # ìƒì„¸í•œ í”„ë¡¬í”„íŠ¸
                        "temperature": 0.0,  # ğŸ”‘ ê²°ì •ë¡ ì  ê²°ê³¼ë¥¼ ìœ„í•´ 0
                    }
                    
                    # ì‹œë“œ íŒŒë¼ë¯¸í„° ì¶”ê°€ (ì§€ì›ë˜ëŠ” ê²½ìš°)
                    if file_seed is not None:
                        logger.info(f"ğŸ² íŒŒì¼ ê¸°ë°˜ ì‹œë“œ ì‚¬ìš©: {file_seed}")
                        # ì°¸ê³ : Whisper APIëŠ” í˜„ì¬ seedë¥¼ ì§€ì›í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ
                        # í•˜ì§€ë§Œ í–¥í›„ ì§€ì› ê°€ëŠ¥ì„±ì„ ìœ„í•´ ì¡°ê±´ë¶€ ì¶”ê°€
                        try:
                            params["seed"] = file_seed
                        except:
                            logger.warning("âš ï¸ Whisper APIëŠ” í˜„ì¬ seed íŒŒë¼ë¯¸í„°ë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŒ")
                    
                    return self.client.audio.transcriptions.create(**params)
            
            # ë¹„ë™ê¸° API í˜¸ì¶œ
            result = await asyncio.to_thread(_stable_api_call)
            
            # ì„¸ê·¸ë¨¼íŠ¸ ì²˜ë¦¬
            segments = []
            if result.segments:
                for segment in result.segments:
                    segments.append({
                        "start": segment.start,
                        "end": segment.end,
                        "text": segment.text.strip()
                    })
            
            logger.info(f"âœ… ì•ˆì •í™” API ì „ì‚¬ ì™„ë£Œ: {len(segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸")
            
            return {
                "success": True,
                "text": result.text.strip(),
                "segments": segments,
                "language": getattr(result, 'language', language),
                "processing_method": "openai_api_stable",
                "file_size_mb": file_size_mb,
                "used_seed": file_seed,
                "temperature": 0.0,
                "prompt": consistent_prompt
            }
        
        except Exception as e:
            logger.error(f"âŒ ì•ˆì •í™” API ì „ì‚¬ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "processing_method": "openai_api_stable"
            }
    
    async def transcribe_with_retry(
        self,
        audio_path: str,
        language: str = "ko",
        max_retries: int = 3
    ) -> Dict:
        """ì¬ì‹œë„ë¥¼ í†µí•œ ì¼ê´€ëœ ê²°ê³¼ í™•ë³´"""
        results = []
        
        for attempt in range(max_retries):
            logger.info(f"ğŸ”„ ì‹œë„ {attempt + 1}/{max_retries}")
            
            result = await self.transcribe_audio_stable(audio_path, language)
            
            if result.get("success"):
                results.append(result["text"])
                
                # ì²« ë²ˆì§¸ ì„±ê³µí•œ ê²°ê³¼ë¥¼ ë°˜í™˜ (ì¼ê´€ì„±ì„ ìœ„í•´)
                if attempt == 0:
                    logger.info("âœ… ì²« ë²ˆì§¸ ì‹œë„ ì„±ê³µ, ê²°ê³¼ ë°˜í™˜")
                    return result
                
                # ì´ì „ ê²°ê³¼ì™€ ë¹„êµ
                if len(results) >= 2 and results[-1] == results[-2]:
                    logger.info("âœ… ì¼ê´€ëœ ê²°ê³¼ í™•ì¸ë¨")
                    return result
            
            # ì‹¤íŒ¨ì‹œ ì ì‹œ ëŒ€ê¸°
            await asyncio.sleep(1)
        
        # ëª¨ë“  ì‹œë„ ì‹¤íŒ¨ì‹œ ë§ˆì§€ë§‰ ê²°ê³¼ ë°˜í™˜
        if results:
            logger.warning("âš ï¸ ì™„ì „ ì¼ê´€ëœ ê²°ê³¼ëŠ” ì–»ì§€ ëª»í–ˆì§€ë§Œ ë§ˆì§€ë§‰ ê²°ê³¼ ë°˜í™˜")
            return result
        else:
            return {
                "success": False,
                "error": "ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨",
                "processing_method": "openai_api_stable"
            }

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
stable_openai_whisper_client = StableOpenAIWhisperClient()
