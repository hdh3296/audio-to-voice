"""
Auto-subtitle ëª¨ë“ˆ
faster-whisperë¥¼ ì‚¬ìš©í•œ ê³ ì„±ëŠ¥ êµ¬í˜„
"""
from faster_whisper import WhisperModel
import ffmpeg
import os
import tempfile
from pathlib import Path
from typing import Optional, Dict, List
import subprocess
import json

class AutoSubtitle:
    def __init__(self):
        self.models = {}
    
    def load_model(self, model_name: str = "large-v3"):
        """Faster-Whisper ëª¨ë¸ ë¡œë“œ (í•œêµ­ì–´ ìµœì í™”, ì•ˆì •ì„± ìš°ì„ )"""
        if model_name not in self.models:
            print(f"ğŸ“¥ Faster-Whisper ëª¨ë¸ ë¡œë“œ ì¤‘: {model_name}")
            try:
                # ì•ˆì •ì„±ì„ ìœ„í•´ CPU ì‚¬ìš©, í•„ìš”ì‹œ GPUëŠ” ì‚¬ìš©ìê°€ ìˆ˜ë™ ì„¤ì •
                self.models[model_name] = WhisperModel(
                    model_name, 
                    device="cpu", 
                    compute_type="int8",
                    download_root=None,  # ê¸°ë³¸ ìºì‹œ ë””ë ‰í† ë¦¬ ì‚¬ìš©
                    local_files_only=False  # ì˜¨ë¼ì¸ ë‹¤ìš´ë¡œë“œ í—ˆìš©
                )
                print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_name}")
            except Exception as e:
                print(f"âŒ {model_name} ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                # large-v3 ì‹¤íŒ¨ì‹œ mediumìœ¼ë¡œ ìë™ ëŒ€ì²´
                if model_name == "large-v3":
                    print("ğŸ”„ medium ëª¨ë¸ë¡œ ìë™ ëŒ€ì²´ ì¤‘...")
                    fallback_model = "medium"
                    self.models[model_name] = WhisperModel(
                        fallback_model, 
                        device="cpu", 
                        compute_type="int8"
                    )
                    print(f"âœ… ëŒ€ì²´ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {fallback_model}")
                else:
                    raise e
        return self.models[model_name]
    
    def transcribe_audio(
        self, 
        audio_path: str, 
        model_name: str = "large-v3",
        language: Optional[str] = "ko",
        task: str = "transcribe"
    ) -> Dict:
        """ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (í•œêµ­ì–´ ìµœì í™”)"""
        try:
            model = self.load_model(model_name)
            
            # í•œêµ­ì–´ ìµœì í™” í”„ë¡¬í”„íŠ¸
            korean_prompt = "ì•ˆë…•í•˜ì„¸ìš”. ë‹¤ìŒì€ í•œêµ­ì–´ ìŒì„±ì…ë‹ˆë‹¤. ì •í™•í•œ ë¬¸ì¥ ë¶€í˜¸ì™€ ìì—°ìŠ¤ëŸ¬ìš´ ë„ì–´ì“°ê¸°ë¥¼ í¬í•¨í•´ ì£¼ì„¸ìš”."
            
            print(f"ğŸ¯ í•œêµ­ì–´ ìŒì„± ì¸ì‹ ì‹œì‘: {audio_path}")
            print(f"ğŸ“Š ëª¨ë¸: {model_name}, ì–¸ì–´: {language}")
            
            segments, info = model.transcribe(
                audio_path, 
                language=language,
                task=task,
                word_timestamps=True,
                initial_prompt=korean_prompt,
                # í•œêµ­ì–´ ìµœì í™” ì„¤ì • (ìˆ˜ì •ëœ íŒŒë¼ë¯¸í„°ëª…)
                beam_size=5,
                best_of=5,
                temperature=0.0,  # ì¼ê´€ëœ ê²°ê³¼ë¥¼ ìœ„í•´
                condition_on_previous_text=True,
                compression_ratio_threshold=2.4,
                log_prob_threshold=-1.0,  # ìˆ˜ì •: logprob_threshold -> log_prob_threshold
                no_speech_threshold=0.6
            )
            
            # ê²°ê³¼ ìˆ˜ì§‘
            segments_list = []
            full_text = ""
            
            for segment in segments:
                # í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì •ë¦¬
                cleaned_text = segment.text.strip()
                if cleaned_text:  # ë¹ˆ í…ìŠ¤íŠ¸ ì œì™¸
                    segment_dict = {
                        "start": segment.start,
                        "end": segment.end,
                        "text": cleaned_text
                    }
                    segments_list.append(segment_dict)
                    full_text += cleaned_text + " "
            
            result = {
                "text": full_text.strip(),
                "segments": segments_list,
                "language": info.language,
                "language_probability": info.language_probability
            }
            
            print(f"âœ… í•œêµ­ì–´ ìŒì„± ì¸ì‹ ì™„ë£Œ: {len(segments_list)}ê°œ êµ¬ê°„")
            return result
        
        except Exception as e:
            raise Exception(f"í•œêµ­ì–´ ìŒì„± ì¸ì‹ ì‹¤íŒ¨: {str(e)}")
    
    def generate_srt(self, result: Dict) -> str:
        """Whisper ê²°ê³¼ë¥¼ SRT í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        srt_content = ""
        
        for i, segment in enumerate(result["segments"], 1):
            start_time = self.seconds_to_srt_time(segment["start"])
            end_time = self.seconds_to_srt_time(segment["end"])
            text = segment["text"].strip()
            
            srt_content += f"{i}\n"
            srt_content += f"{start_time} --> {end_time}\n"
            srt_content += f"{text}\n\n"
        
        return srt_content
    
    def seconds_to_srt_time(self, seconds: float) -> str:
        """ì´ˆë¥¼ SRT ì‹œê°„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millisecs = int((seconds % 1) * 1000)
        
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"
    
    def get_audio_duration(self, audio_path: str) -> float:
        """ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ê¸¸ì´ë¥¼ êµ¬í•¨"""
        try:
            probe = ffmpeg.probe(audio_path)
            duration = float(probe['streams'][0]['duration'])
            return duration
        except:
            return 60.0  # ê¸°ë³¸ê°’
    
    def create_video_with_subtitles(
        self, 
        audio_path: str, 
        srt_content: str, 
        output_path: str,
        background_color: str = "black"
    ):
        """ì˜¤ë””ì˜¤ì™€ ìë§‰ìœ¼ë¡œ ë¹„ë””ì˜¤ ìƒì„± (í•œêµ­ì–´ ìµœì í™”)"""
        try:
            # ì˜¤ë””ì˜¤ ê¸¸ì´ êµ¬í•˜ê¸°
            duration = self.get_audio_duration(audio_path)
            
            with tempfile.NamedTemporaryFile(mode='w', suffix='.srt', delete=False, encoding='utf-8') as srt_file:
                srt_file.write(srt_content)
                srt_path = srt_file.name
            
            # í•œêµ­ì–´ í°íŠ¸ ì„¤ì • (ì‹œìŠ¤í…œì— ë”°ë¼ ìë™ ì„ íƒ)
            font_style = (
                'FontSize=28,'
                'PrimaryColour=&Hffffff,'
                'OutlineColour=&H000000,'
                'Outline=3,'
                'Shadow=1,'
                'Alignment=2,'  # ì¤‘ì•™ í•˜ë‹¨
                'MarginV=50'    # í•˜ë‹¨ ì—¬ë°±
            )
            
            # FFmpegë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ë””ì˜¤ ìƒì„± (í•œêµ­ì–´ ìµœì í™”)
            cmd = [
                'ffmpeg',
                '-f', 'lavfi',
                '-i', f'color=c={background_color}:s=1280x720:d={duration}',
                '-i', audio_path,
                '-vf', f'subtitles={srt_path}:force_style=\'{font_style}\'',
                '-c:v', 'libx264',
                '-preset', 'medium',  # í’ˆì§ˆê³¼ ì†ë„ ê· í˜•
                '-crf', '23',         # ê³ í’ˆì§ˆ ì„¤ì •
                '-c:a', 'aac',
                '-b:a', '128k',       # ì˜¤ë””ì˜¤ í’ˆì§ˆ
                '-shortest',
                '-y',  # ë®ì–´ì“°ê¸°
                output_path
            ]
            
            print(f"ğŸ¬ í•œêµ­ì–´ ìë§‰ ë¹„ë””ì˜¤ ìƒì„± ì¤‘: {output_path}")
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode != 0:
                raise Exception(f"FFmpeg ì˜¤ë¥˜: {result.stderr}")
            
            # ì„ì‹œ SRT íŒŒì¼ ì‚­ì œ
            os.unlink(srt_path)
            
            print(f"âœ… í•œêµ­ì–´ ìë§‰ ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ: {output_path}")
            
        except Exception as e:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if 'srt_path' in locals() and os.path.exists(srt_path):
                os.unlink(srt_path)
            raise Exception(f"ë¹„ë””ì˜¤ ìƒì„± ì‹¤íŒ¨: {str(e)}")
    
    def process_audio_to_video(
        self,
        audio_path: str,
        output_path: str,
        model_name: str = "large-v3",
        language: Optional[str] = "ko",
        task: str = "transcribe",
        background_color: str = "black"
    ) -> Dict:
        """ì „ì²´ í”„ë¡œì„¸ìŠ¤: ì˜¤ë””ì˜¤ â†’ ìë§‰ â†’ ë¹„ë””ì˜¤ (í•œêµ­ì–´ ìµœì í™”)"""
        try:
            print(f"ğŸš€ í•œêµ­ì–´ ìŒì„± ì²˜ë¦¬ ì‹œì‘ - ëª¨ë¸: {model_name}")
            
            # 1. í•œêµ­ì–´ ì˜¤ë””ì˜¤ ì „ì‚¬
            print("ğŸ“ 1ë‹¨ê³„: í•œêµ­ì–´ ìŒì„± ì¸ì‹ ì¤‘...")
            result = self.transcribe_audio(audio_path, model_name, language, task)
            
            # 2. SRT ìƒì„±
            print("ğŸ“„ 2ë‹¨ê³„: í•œêµ­ì–´ ìë§‰ ìƒì„± ì¤‘...")
            srt_content = self.generate_srt(result)
            
            # 3. í•œêµ­ì–´ ìë§‰ ë¹„ë””ì˜¤ ìƒì„±
            print("ğŸ¬ 3ë‹¨ê³„: í•œêµ­ì–´ ìë§‰ ë¹„ë””ì˜¤ ìƒì„± ì¤‘...")
            self.create_video_with_subtitles(audio_path, srt_content, output_path, background_color)
            
            return {
                "success": True,
                "output_path": output_path,
                "transcript": result["text"],
                "segments_count": len(result["segments"]),
                "language": result.get("language", "ko"),
                "language_probability": result.get("language_probability", 0.0),
                "model_used": model_name
            }
        
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
auto_subtitle = AutoSubtitle()
