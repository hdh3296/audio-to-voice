"""
ğŸš€ Phase 2: ì°¨ì„¸ëŒ€ Audio-to-Voice API ì„œë²„
- ìƒˆë¡œìš´ OpenAI ëª¨ë¸ ì§€ì› (whisper-1 ìµœì í™”)
- ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
- ì§€ëŠ¥í˜• í’ˆì§ˆ ê²€ì¦ ë° ìë™ ì¬ì²˜ë¦¬
- WebSocket ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
"""

from fastapi import FastAPI, File, UploadFile, HTTPException, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse
from fastapi.staticfiles import StaticFiles
import os
import sys
import shutil
import subprocess
import tempfile
from pathlib import Path
import uuid
from typing import Optional, Dict, List
import asyncio
from datetime import datetime
import json
from dotenv import load_dotenv

# Phase 2 ëª¨ë“ˆ ì„í¬íŠ¸
from phase2_models import Phase2ModelManager, TranscriptionResult
from phase2_streaming import StreamingTranscriber, StreamingProgress
from phase2_quality import QualityAnalyzer, AutoReprocessor
from phase2_postprocessing import Phase2PostProcessor

# ğŸ†• Phase 3.2: í…œí”Œë¦¿ ì‹œìŠ¤í…œ ì„í¬íŠ¸ (Phase 3.2.3 íŠ¸ëœì§€ì…˜ í¬í•¨)
from phase3_templates import TemplateManager, create_looped_template_video, TransitionConfig, TransitionConfig, TransitionConfig

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

app = FastAPI(
    title="Audio to Voice API - Phase 2", 
    version="3.0.0",
    description="ì°¨ì„¸ëŒ€ í•œêµ­ì–´ ìŒì„± ì¸ì‹ ì‹œìŠ¤í…œ - ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° & ì§€ëŠ¥í˜• í’ˆì§ˆ ê²€ì¦"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://localhost:3001"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ë””ë ‰í† ë¦¬ ì„¤ì •
BASE_DIR = Path(__file__).parent.parent
UPLOADS_DIR = BASE_DIR / "uploads"
OUTPUTS_DIR = BASE_DIR / "outputs"

# ë””ë ‰í† ë¦¬ ìƒì„±
UPLOADS_DIR.mkdir(exist_ok=True)
OUTPUTS_DIR.mkdir(exist_ok=True)

# ì •ì  íŒŒì¼ ì„œë¹™
app.mount("/outputs", StaticFiles(directory=str(OUTPUTS_DIR)), name="outputs")

# ì§€ì›í•˜ëŠ” ì˜¤ë””ì˜¤ í˜•ì‹
SUPPORTED_AUDIO_FORMATS = {".mp3", ".wav", ".m4a", ".aac", ".flac", ".ogg"}

# ì „ì—­ ë§¤ë‹ˆì €ë“¤
model_manager: Optional[Phase2ModelManager] = None
streaming_transcriber: Optional[StreamingTranscriber] = None
quality_analyzer: Optional[QualityAnalyzer] = None
auto_reprocessor: Optional[AutoReprocessor] = None
postprocessor: Optional[Phase2PostProcessor] = None
template_manager: Optional[TemplateManager] = None  # ğŸ†• í…œí”Œë¦¿ ë§¤ë‹ˆì €
api_available = False

# WebSocket ì—°ê²° ê´€ë¦¬
websocket_connections: Dict[str, WebSocket] = {}


def init_phase2_systems():
    """Phase 2 ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
    global model_manager, streaming_transcriber, quality_analyzer, auto_reprocessor, postprocessor, template_manager, api_available
    
    api_key = os.getenv("OPENAI_API_KEY")
    if api_key and api_key != "your_openai_api_key_here":
        print("ğŸš€ Phase 2 ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        
        try:
            # ëª¨ë¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”
            model_manager = Phase2ModelManager(api_key)
            print("âœ… Phase 2 ëª¨ë¸ ë§¤ë‹ˆì € ì´ˆê¸°í™” ì™„ë£Œ")
            
            # ìŠ¤íŠ¸ë¦¬ë° ì „ì‚¬ê¸° ì´ˆê¸°í™”
            streaming_transcriber = StreamingTranscriber(model_manager, chunk_duration=30.0)
            print("âœ… ìŠ¤íŠ¸ë¦¬ë° ì „ì‚¬ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
            
            # í’ˆì§ˆ ë¶„ì„ê¸° ì´ˆê¸°í™”
            quality_analyzer = QualityAnalyzer()
            print("âœ… í’ˆì§ˆ ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
            
            # ìë™ ì¬ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
            auto_reprocessor = AutoReprocessor(model_manager, quality_analyzer)
            print("âœ… ìë™ ì¬ì²˜ë¦¬ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
            
            # GPT í›„ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
            postprocessor = Phase2PostProcessor(api_key)
            print("âœ… GPT í›„ì²˜ë¦¬ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
            
            # ğŸ†• í…œí”Œë¦¿ ë§¤ë‹ˆì € ì´ˆê¸°í™”
            template_manager = TemplateManager()
            print("âœ… í…œí”Œë¦¿ ë§¤ë‹ˆì € ì´ˆê¸°í™” ì™„ë£Œ")
            
            api_available = True
            print("ğŸ‰ Phase 2 + 3.2 ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì„±ê³µ!")
            
        except Exception as e:
            print(f"âŒ Phase 2 ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            api_available = False
    else:
        print("âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ - Phase 2 ê¸°ëŠ¥ ì‚¬ìš© ë¶ˆê°€")


def generate_ass(segments, video_resolution: str = "1080p"):
    """ASS ìë§‰ ìƒì„± - í™”ë©´ ì¤‘ì•™ ìœ„ì¹˜ + í•œ ì¤„ ìë§‰ ì™„ì „ ì œì–´ + ì¢Œìš° ì—¬ë°±"""
    
    # í•´ìƒë„ë³„ í°íŠ¸ í¬ê¸°, ì—¬ë°±, ì¤‘ì•™ ìœ„ì¹˜ ì„¤ì •
    resolution_configs = {
        "720p": {"font_size": 18, "margin_lr": 40, "center_v": 360},    # 720p ì¤‘ì•™: 360px
        "1080p": {"font_size": 22, "margin_lr": 60, "center_v": 540},   # 1080p ì¤‘ì•™: 540px  
        "1440p": {"font_size": 28, "margin_lr": 80, "center_v": 720},   # 1440p ì¤‘ì•™: 720px
        "4k": {"font_size": 36, "margin_lr": 120, "center_v": 1080}     # 4K ì¤‘ì•™: 1080px
    }
    
    config = resolution_configs.get(video_resolution, resolution_configs["1080p"])
    font_size = config["font_size"]
    margin_lr = config["margin_lr"]
    center_v = config["center_v"]
    
    # ASS í—¤ë” (í™”ë©´ ì¤‘ì•™ ìœ„ì¹˜ + ì¢Œìš° ì—¬ë°± í¬í•¨í•œ ì™„ì „í•œ ì¤„ë°”ê¿ˆ ì œì–´)
    ass_content = f"""[Script Info]
Title: Center Position Single Line Subtitles
ScriptType: v4.00+

[V4+ Styles]
Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
Style: Default,Arial,{font_size},&Hffffff,&Hffffff,&H000000,&H80000000,0,0,0,0,100,100,0,0,1,2,1,5,{margin_lr},{margin_lr},{center_v},1

[Events]
Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
"""
    
    for i, segment in enumerate(segments):
        start_time = seconds_to_ass_time(segment["start"])
        end_time = seconds_to_ass_time(segment["end"])
        text = segment["text"].strip()
        
        # ğŸ”¥ í•œ ì¤„ ìë§‰: \\N (ê°•ì œ ì¤„ë°”ê¿ˆ) ì œê±°, ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ í•œ ì¤„ë¡œ
        text = text.replace('\\N', ' ').replace('\n', ' ')
        
        ass_content += f"Dialogue: 0,{start_time},{end_time},Default,,0,0,0,,{text}\n"
    
    return ass_content


def seconds_to_ass_time(seconds: float) -> str:
    """ì´ˆë¥¼ ASS ì‹œê°„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (H:MM:SS.CC)"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    centisecs = int((seconds % 1) * 100)
    
    return f"{hours}:{minutes:02d}:{secs:02d}.{centisecs:02d}"


async def gpt_smart_line_breaks(text: str, max_line_length: int, max_lines: int = 2) -> str:
    """
    ğŸ¤– GPT ê¸°ë°˜ ì˜ë¯¸ ë‹¨ìœ„ ìŠ¤ë§ˆíŠ¸ ë¶„í• 
    - ìì—°ìŠ¤ëŸ¬ìš´ ì˜ë¯¸ ë‹¨ìœ„ë¡œ ë¶„í• 
    - í•œêµ­ì–´ ë¬¸ë²• ê³ ë ¤ (ì¡°ì‚¬, ì–´ë¯¸ ë“±)  
    - ê· í˜•ì¡íŒ ì¤„ ê¸¸ì´
    """
    if not api_available:
        return text
    
    try:
        from openai import AsyncOpenAI
        
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            return text
            
        client = AsyncOpenAI(api_key=api_key)
        
        prompt = f"""ë‹¤ìŒ í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ìì—°ìŠ¤ëŸ½ê³  ì˜ë¯¸ìˆëŠ” ë‹¨ìœ„ë¡œ {max_lines}ì¤„ë¡œ ë‚˜ëˆ„ì–´ ì£¼ì„¸ìš”.

ğŸ¯ ë¶„í•  ì¡°ê±´:
- ê° ì¤„ì€ ìµœëŒ€ {max_line_length}ì ì´í•˜
- ì˜ë¯¸ê°€ ì™„ê²°ë˜ëŠ” ì§€ì ì—ì„œ ë¶„í• 
- ë„ˆë¬´ ì§§ì€ ì¤„(3ê¸€ì ì´í•˜) ë°©ì§€
- ì¡°ì‚¬ë‚˜ ì–´ë¯¸ê°€ í˜¼ì ë‚¨ì§€ ì•Šë„ë¡ ì£¼ì˜
- "~ì„", "~ë¥¼", "~ì— ëŒ€í•œ", "~ì„ ìœ„í•˜ì—¬" ë“±ì€ ë¶„í• í•˜ì§€ ë§ ê²ƒ
- ê· í˜•ì¡íŒ ì¤„ ê¸¸ì´ë¡œ ì¡°ì •

ğŸ“ í…ìŠ¤íŠ¸: "{text}"

âœ… ê²°ê³¼: ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„ëœ í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜ (ì„¤ëª… ì—†ì´)"""

        response = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1,
            max_tokens=1000
        )
        
        result = response.choices[0].message.content.strip()
        
        # ê²°ê³¼ ê²€ì¦: ì¤„ ìˆ˜ ë° ê¸¸ì´ ì²´í¬
        lines = result.split('\n')
        if len(lines) <= max_lines and all(len(line) <= max_line_length + 5 for line in lines):
            print(f"ğŸ¤– GPT ìŠ¤ë§ˆíŠ¸ ë¶„í•  ì„±ê³µ: {len(lines)}ì¤„")
            for i, line in enumerate(lines, 1):
                print(f"   {i}ì¤„: '{line}' (ê¸¸ì´: {len(line)}ì)")
            return result
        else:
            print(f"âš ï¸ GPT ê²°ê³¼ ê²€ì¦ ì‹¤íŒ¨ - ì›ë³¸ ì‚¬ìš©")
            return text
            
    except Exception as e:
        print(f"âŒ GPT ìŠ¤ë§ˆíŠ¸ ë¶„í•  ì˜¤ë¥˜: {str(e)} - ì›ë³¸ ì‚¬ìš©")
        return text


def needs_smart_improvement(text: str, formatted_result: str, max_line_length: int) -> bool:
    """
    ğŸ” GPT ìŠ¤ë§ˆíŠ¸ ë¶„í• ì´ í•„ìš”í•œì§€ íŒë‹¨
    - ë„ˆë¬´ ì§§ì€ ì¤„ (3ê¸€ì ì´í•˜)
    - ë¶ˆê· í˜•í•œ ì¤„ ê¸¸ì´ ì°¨ì´
    - ë¶€ìì—°ìŠ¤ëŸ¬ìš´ ë¶„í• ì  ("ë‚´ìš©ì„" ë“±)
    """
    lines = formatted_result.split('\n')
    
    # 1. ë„ˆë¬´ ì§§ì€ ì¤„ ê²€ì‚¬
    for line in lines:
        if len(line.strip()) <= 3 and len(line.strip()) > 0:
            print(f"ğŸ” ê°œì„  í•„ìš”: ë„ˆë¬´ ì§§ì€ ì¤„ ê°ì§€ - '{line.strip()}'")
            return True
    
    # 2. ì¤„ ê¸¸ì´ ë¶ˆê· í˜• ê²€ì‚¬ (2ì¤„ì¸ ê²½ìš°)
    if len(lines) == 2:
        line1_len = len(lines[0])
        line2_len = len(lines[1])
        if line1_len > 0 and line2_len > 0:
            length_ratio = abs(line1_len - line2_len) / max(line1_len, line2_len)
            if length_ratio > 0.7:  # 70% ì´ìƒ ì°¨ì´
                print(f"ğŸ” ê°œì„  í•„ìš”: ë¶ˆê· í˜•í•œ ì¤„ ê¸¸ì´ - {line1_len}ì vs {line2_len}ì")
                return True
    
    # 3. ë¶€ìì—°ìŠ¤ëŸ¬ìš´ ë¶„í• ì  ê²€ì‚¬
    problem_patterns = [
        "ë‚´ìš©ì„\n", "ê²ƒì„\n", "ì„\n", "ë¥¼\n", "ì—\n", "ì´\n", "ê°€\n"
    ]
    
    for pattern in problem_patterns:
        if pattern in formatted_result:
            print(f"ğŸ” ê°œì„  í•„ìš”: ë¶€ìì—°ìŠ¤ëŸ¬ìš´ ë¶„í• ì  ê°ì§€ - '{pattern.strip()}'")
            return True
    
    return False


def apply_word_based_line_breaks(text: str, max_line_length: int) -> str:
    """
    ğŸ“ í•œ ì¤„ ìë§‰ ì²˜ë¦¬ (ì¤„ë°”ê¿ˆ ë¹„í™œì„±í™”)
    - ëª¨ë“  ìë§‰ì„ í•œ ì¤„ë¡œ í‘œì‹œ
    - ì¤„ë°”ê¿ˆ ì²˜ë¦¬ ì™„ì „ ë¹„í™œì„±í™”
    - ì›ë³¸ í…ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ ìœ ì§€
    """
    if not text:
        return text
    
    # ğŸ”¥ í•œ ì¤„ ìë§‰ ëª¨ë“œ: ì¤„ë°”ê¿ˆ ì™„ì „ ë¹„í™œì„±í™”
    print(f"ğŸ“ í•œ ì¤„ ìë§‰ ëª¨ë“œ: '{text}' (ê¸¸ì´: {len(text)}ì)")
    
    # ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ë°˜í™˜ (ì¤„ë°”ê¿ˆ ì—†ìŒ)
    return text.strip()


def seconds_to_srt_time(seconds: float) -> str:
    """ì´ˆë¥¼ SRT ì‹œê°„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millisecs = int((seconds % 1) * 1000)
    
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"


def get_audio_duration(audio_path: str) -> float:
    """ì˜¤ë””ì˜¤ ê¸¸ì´ êµ¬í•˜ê¸°"""
    try:
        import ffmpeg
        probe = ffmpeg.probe(audio_path)
        duration = float(probe['streams'][0]['duration'])
        return duration
    except:
        return 60.0


def create_video_with_subtitles(
    audio_path: str, 
    ass_content: str, 
    output_path: str, 
    background_color: str = "black", 
    background_type: str = "color",  # ğŸ†• "color" | "template"
    template_name: str = "particles_dark",  # ğŸ†• í…œí”Œë¦¿ ì´ë¦„
    video_resolution: str = "1080p"
):
    """
    ë¹„ë””ì˜¤ ìƒì„± - ìƒ‰ìƒ ë°°ê²½ ë˜ëŠ” í…œí”Œë¦¿ ë°°ê²½ ì„ íƒ ê°€ëŠ¥
    ğŸ†• Phase 3.2: í…œí”Œë¦¿ ê¸°ë°˜ ë™ì  ë¹„ë””ì˜¤ ë°°ê²½ ì§€ì›
    """
    try:
        # ğŸ†• í…œí”Œë¦¿ ë°°ê²½ ì‚¬ìš©
        if background_type == "template" and template_manager:
            print(f"ğŸ¬ í…œí”Œë¦¿ ë°°ê²½ ëª¨ë“œ: {template_name}")
            success = create_looped_template_video(
                audio_path=audio_path,
                template_name=template_name,
                output_path=output_path,
                ass_content=ass_content,
                video_resolution=video_resolution,
                template_manager=template_manager
            )
            
            if success:
                print(f"âœ… í…œí”Œë¦¿ ê¸°ë°˜ ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ: {output_path}")
                return
            else:
                print("âš ï¸ í…œí”Œë¦¿ ìƒì„± ì‹¤íŒ¨ - ìƒ‰ìƒ ë°°ê²½ìœ¼ë¡œ ëŒ€ì²´")
                # í…œí”Œë¦¿ ì‹¤íŒ¨ì‹œ ìƒ‰ìƒ ë°°ê²½ìœ¼ë¡œ í´ë°±
        
        # ê¸°ì¡´ ìƒ‰ìƒ ë°°ê²½ ìƒì„± (ê¸°ë³¸ê°’ ë˜ëŠ” í´ë°±)
        print(f"ğŸ¨ ìƒ‰ìƒ ë°°ê²½ ëª¨ë“œ: {background_color}")
        duration = get_audio_duration(audio_path)
        
        # ğŸ¬ í•´ìƒë„ë³„ ì„¤ì •
        resolution_configs = {
            "720p": {"size": "1280x720", "description": "HD 720p"},
            "1080p": {"size": "1920x1080", "description": "Full HD 1080p (ê¶Œì¥)"},
            "1440p": {"size": "2560x1440", "description": "2K QHD"},
            "4k": {"size": "3840x2160", "description": "4K UHD"}
        }
        
        config = resolution_configs.get(video_resolution, resolution_configs["1080p"])
        
        # ASS íŒŒì¼ë¡œ ì„ì‹œ ì €ì¥
        with tempfile.NamedTemporaryFile(mode='w', suffix='.ass', delete=False, encoding='utf-8') as ass_file:
            ass_file.write(ass_content)
            ass_path = ass_file.name
        
        print(f"ğŸ¬ í™”ë©´ ì¤‘ì•™ í•œ ì¤„ ìë§‰ + ì¢Œìš° ì—¬ë°±: {config['description']} ({config['size']}) - ASS ìë§‰ ì‚¬ìš©")
        
        # FFmpeg ëª…ë ¹ì–´ (ê¸°ì¡´ ìƒ‰ìƒ ë°°ê²½)
        cmd = [
            'ffmpeg',
            '-f', 'lavfi',
            '-i', f'color=c={background_color}:s={config["size"]}:d={duration}',
            '-i', audio_path,
            '-vf', f'ass={ass_path}',  # ğŸ”¥ ASS í•„í„° ì‚¬ìš© (ì™„ì „í•œ ì œì–´)
            '-c:v', 'libx264',
            '-preset', 'medium',
            '-crf', '23',
            '-c:a', 'aac',
            '-b:a', '128k',
            '-shortest',
            '-y',
            output_path
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode != 0:
            raise Exception(f"FFmpeg ì˜¤ë¥˜: {result.stderr}")
        
        os.unlink(ass_path)
        print(f"âœ… ìƒ‰ìƒ ë°°ê²½ ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ: {output_path}")
        
    except Exception as e:
        if 'ass_path' in locals() and os.path.exists(ass_path):
            os.unlink(ass_path)
        raise Exception(f"ë¹„ë””ì˜¤ ìƒì„± ì‹¤íŒ¨: {str(e)}")



# ì„œë²„ ì‹œì‘ì‹œ ì´ˆê¸°í™”
init_phase2_systems()


@app.get("/")
async def root():
    return {
        "message": "Audio to Voice API - Phase 2", 
        "status": "running", 
        "version": "3.0.0",
        "features": {
            "streaming": "ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬",
            "quality_analysis": "ì§€ëŠ¥í˜• í’ˆì§ˆ ê²€ì¦",
            "auto_reprocessing": "ìë™ ì¬ì²˜ë¦¬",
            "advanced_models": "ì°¨ì„¸ëŒ€ AI ëª¨ë¸"
        },
        "models": {
            "whisper-1-standard": "Whisper-1 í‘œì¤€ ì„¤ì •",
            "whisper-1-optimized": "Whisper-1 ìµœì í™” ì„¤ì •",
            "whisper-1-creative": "Whisper-1 ì°½ì˜ì  ì„¤ì •"
        },
        "api_status": "Available" if api_available else "Requires API key"
    }


@app.get("/health")
async def health_check():
    return {
        "status": "healthy", 
        "timestamp": datetime.now().isoformat(),
        "phase2_systems": {
            "model_manager": model_manager is not None,
            "streaming_transcriber": streaming_transcriber is not None,
            "quality_analyzer": quality_analyzer is not None,
            "auto_reprocessor": auto_reprocessor is not None,
            "gpt_postprocessor": postprocessor is not None and postprocessor.is_available()
        }
    }


@app.get("/api-status")
async def api_status():
    """Phase 2 API ìƒíƒœ í™•ì¸"""
    return {
        "phase2_available": api_available,
        "systems_ready": {
            "model_manager": model_manager is not None,
            "streaming": streaming_transcriber is not None,
            "quality_analysis": quality_analyzer is not None,
            "auto_reprocessing": auto_reprocessor is not None,
            "gpt_postprocessing": postprocessor is not None and postprocessor.is_available()
        },
        "supported_models": list(model_manager.AVAILABLE_MODELS.keys()) if model_manager else [],
        "features": [
            "ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬",
            "ì§€ëŠ¥í˜• í’ˆì§ˆ ê²€ì¦", 
            "ìë™ ì¬ì²˜ë¦¬",
            "ì°¨ì„¸ëŒ€ AI ëª¨ë¸",
            "GPT í›„ì²˜ë¦¬ êµì •",
            "WebSocket ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸"
        ]
    }


@app.get("/templates")
async def get_templates():
    """ğŸ†• Phase 3.2: ì‚¬ìš© ê°€ëŠ¥í•œ í…œí”Œë¦¿ ëª©ë¡"""
    if not template_manager:
        raise HTTPException(status_code=503, detail="Template manager not available")
    
    try:
        templates = template_manager.get_available_templates()
        template_info = {}
        
        for template_name in templates:
            info = template_manager.get_template_info(template_name)
            if info:
                template_info[template_name] = {
                    "name": info.name,
                    "description": info.description,
                    "category": info.category,
                    "duration": info.duration,
                    "resolution": info.resolution,
                    "preview_image": info.preview_image,
                    "recommended_for": info.recommended_for,
                    "available": template_manager.validate_template(template_name)
                }
        
        return {
            "available_templates": template_info,
            "total_count": len(templates),
            "default_template": "particles_dark",
            # ğŸ†• Phase 3.2.3: íŠ¸ëœì§€ì…˜ ì •ë³´ ì¶”ê°€
            "transition_types": template_manager.templates_data.get("config", {}).get("transition_types", {})
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"í…œí”Œë¦¿ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")


@app.get("/templates/{template_name}")
async def get_template_info_api(template_name: str):
    """ğŸ†• Phase 3.2: íŠ¹ì • í…œí”Œë¦¿ ìƒì„¸ ì •ë³´"""
    if not template_manager:
        raise HTTPException(status_code=503, detail="Template manager not available")
    
    try:
        info = template_manager.get_template_info(template_name)
        if not info:
            raise HTTPException(status_code=404, detail=f"í…œí”Œë¦¿ '{template_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ì‹¤ì œ ë¹„ë””ì˜¤ ê¸¸ì´ ê°ì§€
        duration = template_manager.get_template_duration(template_name)
        
        return {
            "template_name": template_name,
            "info": {
                "name": info.name,
                "description": info.description,
                "category": info.category,
                "duration": duration,  # ì‹¤ì œ ê°ì§€ëœ ê¸¸ì´
                "resolution": info.resolution,
                "preview_image": info.preview_image,
                "recommended_for": info.recommended_for,
                "created_at": info.created_at
            },
            "available": template_manager.validate_template(template_name),
            "path": template_manager.get_template_path(template_name)
        }
    
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"í…œí”Œë¦¿ ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")


@app.post("/generate-subtitles-template/{file_id}")
async def generate_subtitles_template(
    file_id: str,
    model: str = "whisper-1-optimized",
    language: str = "ko",
    template_name: str = "particles_dark",  # ğŸ†• í…œí”Œë¦¿ ì„ íƒ
    video_resolution: str = "1080p",
    # ğŸ†• Phase 3.2.3: íŠ¸ëœì§€ì…˜ ì„¤ì •
    transition_type: str = "crossfade",     # crossfade, fade, dissolve, wipe, none
    transition_duration: float = 1.2,      # íŠ¸ëœì§€ì…˜ ê¸¸ì´ (ì´ˆ)
    transition_intensity: float = 0.8,     # íŠ¸ëœì§€ì…˜ ê°•ë„ (0.0~1.0)
    enable_quality_analysis: bool = True,
    enable_auto_reprocessing: bool = True,
    enable_gpt_postprocessing: bool = True,
    target_quality: float = 0.8
):
    """ğŸ†• Phase 3.2: í…œí”Œë¦¿ ê¸°ë°˜ ìë§‰ ë¹„ë””ì˜¤ ìƒì„±"""
    if not api_available:
        raise HTTPException(status_code=503, detail="Phase 2 features not available")
    
    if not template_manager:
        raise HTTPException(status_code=503, detail="Template manager not available")
    
    try:
        uploaded_files = list(UPLOADS_DIR.glob(f"{file_id}.*"))
        if not uploaded_files:
            raise HTTPException(status_code=404, detail="ì—…ë¡œë“œëœ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        input_file = uploaded_files[0]
        output_file = OUTPUTS_DIR / f"{file_id}_template_subtitled.mp4"
        
        # í…œí”Œë¦¿ ê²€ì¦
        if not template_manager.validate_template(template_name):
            raise HTTPException(status_code=400, detail=f"í…œí”Œë¦¿ '{template_name}'ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        processing_stages = []
        print(f"ğŸ¬ í…œí”Œë¦¿ ê¸°ë°˜ ìë§‰ ìƒì„± ì‹œì‘: {template_name} + {model} ëª¨ë¸")
        
        # 1ë‹¨ê³„: ì´ˆê¸° ì „ì‚¬ (ê¸°ì¡´ê³¼ ë™ì¼)
        print("ğŸ“ 1ë‹¨ê³„: ì´ˆê¸° ì „ì‚¬ ì¤‘...")
        processing_stages.append("ì´ˆê¸° ì „ì‚¬")
        result = await model_manager.transcribe_with_model(
            str(input_file), model, language, include_quality_metrics=True
        )
        
        if not result.success:
            raise HTTPException(status_code=500, detail=result.error)
        
        initial_result = {
            "text": result.text,
            "segments": result.segments,
            "processing_time": result.processing_time,
            "model_used": result.model_used,
            "confidence_score": result.confidence_score
        }
        
        # 2ë‹¨ê³„: í’ˆì§ˆ ë¶„ì„ (ê¸°ì¡´ê³¼ ë™ì¼)
        quality_metrics = None
        if enable_quality_analysis and quality_analyzer:
            print("ğŸ” 2ë‹¨ê³„: í’ˆì§ˆ ë¶„ì„ ì¤‘...")
            processing_stages.append("í’ˆì§ˆ ë¶„ì„")
            quality_metrics = await quality_analyzer.analyze_transcription_quality(
                result.text, result.segments, result.processing_time, result.model_used
            )
            print(f"ğŸ“Š í’ˆì§ˆ ì ìˆ˜: {quality_metrics.overall_score:.3f}")
        
        # 3ë‹¨ê³„: ìë™ ì¬ì²˜ë¦¬ (ê¸°ì¡´ê³¼ ë™ì¼)
        final_result = initial_result
        if enable_auto_reprocessing and auto_reprocessor and quality_metrics:
            if quality_metrics.needs_reprocessing and quality_metrics.overall_score < target_quality:
                print("ğŸ”„ 3ë‹¨ê³„: ìë™ ì¬ì²˜ë¦¬ ì¤‘...")
                processing_stages.append("ìë™ ì¬ì²˜ë¦¬")
                final_result = await auto_reprocessor.auto_reprocess_if_needed(
                    str(input_file), initial_result, target_quality
                )
        
        # 4ë‹¨ê³„: GPT í›„ì²˜ë¦¬ (ê¸°ì¡´ê³¼ ë™ì¼)
        postprocessing_result = None
        if enable_gpt_postprocessing and postprocessor and postprocessor.is_available():
            print("ğŸ¤– 4ë‹¨ê³„: GPT í›„ì²˜ë¦¬ ì¤‘...")
            processing_stages.append("GPT í›„ì²˜ë¦¬")
            
            postprocessing_result = await postprocessor.process_with_progress(
                segments=final_result["segments"],
                quality_metrics=quality_metrics.__dict__ if hasattr(quality_metrics, '__dict__') else None
            )
            
            if postprocessing_result["success"] and postprocessing_result["correction_applied"]:
                final_result["segments"] = postprocessing_result["corrected_segments"]
                final_result["text"] = " ".join([seg["text"] for seg in postprocessing_result["corrected_segments"]])
                final_result["gpt_correction_applied"] = True
                final_result["total_corrections"] = postprocessing_result["total_corrections"]
                final_result["correction_strategy"] = postprocessing_result["correction_strategy"]
                final_result["gpt_quality_score"] = postprocessing_result["final_quality_score"]
                
                print(f"âœ… GPT êµì • ì™„ë£Œ: {postprocessing_result['total_corrections']}ê°œ í•­ëª© ìˆ˜ì •")
        
        # ğŸ†• 5ë‹¨ê³„: í…œí”Œë¦¿ ê¸°ë°˜ ë¹„ë””ì˜¤ ìƒì„±
        final_stage_num = len(processing_stages) + 1
        print(f"ğŸ¬ {final_stage_num}ë‹¨ê³„: í…œí”Œë¦¿ ê¸°ë°˜ ë¹„ë””ì˜¤ ìƒì„± ì¤‘... ({template_name})")
        ass_content = generate_ass(final_result["segments"], video_resolution)
        
        # í…œí”Œë¦¿ ì •ë³´ ë¡œê·¸
        template_info = template_manager.get_template_info(template_name)
        template_duration = template_manager.get_template_duration(template_name)
        audio_duration = get_audio_duration(str(input_file))
        
        print(f"ğŸ¯ í…œí”Œë¦¿ ìƒì„¸:")
        print(f"   ì´ë¦„: {template_info.name if template_info else template_name}")
        print(f"   ê¸¸ì´: {template_duration:.2f}ì´ˆ")
        print(f"   ìŒì„± ê¸¸ì´: {audio_duration:.2f}ì´ˆ")
        
        # í…œí”Œë¦¿ ê¸°ë°˜ ë¹„ë””ì˜¤ ìƒì„±
        create_video_with_subtitles(
            audio_path=str(input_file),
            ass_content=ass_content,
            output_path=str(output_file),
            background_type="template",  # ğŸ†• í…œí”Œë¦¿ ëª¨ë“œ
            template_name=template_name,  # ğŸ†• í…œí”Œë¦¿ ì´ë¦„
            video_resolution=video_resolution
        )
        
        # ì‘ë‹µ ë°ì´í„° êµ¬ì„±
        response_data = {
            "file_id": file_id,
            "output_file": f"{file_id}_template_subtitled.mp4",
            "download_url": f"/download/{file_id}_template_subtitled.mp4",
            "transcript": final_result["text"],
            "segments_count": len(final_result["segments"]),
            "language": language,
            "processing_method": "phase3_2_template",  # ğŸ†• í…œí”Œë¦¿ ë°©ì‹
            "processing_stages": processing_stages,
            "model_used": final_result.get("model_used", model),
            "template_used": template_name,  # ğŸ†• ì‚¬ìš©ëœ í…œí”Œë¦¿
            "template_duration": template_duration,  # ğŸ†• í…œí”Œë¦¿ ê¸¸ì´
            "audio_duration": audio_duration,  # ğŸ†• ìŒì„± ê¸¸ì´
            "video_resolution": video_resolution,
            "gpt_postprocessing_enabled": enable_gpt_postprocessing,
            "message": f"í…œí”Œë¦¿ '{template_name}' ê¸°ë°˜ ìë§‰ ë¹„ë””ì˜¤ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ({video_resolution})"
        }
        
        # GPT í›„ì²˜ë¦¬ ê²°ê³¼ ì¶”ê°€
        if postprocessing_result:
            response_data.update({
                "gpt_correction_applied": final_result.get("gpt_correction_applied", False),
                "total_corrections": final_result.get("total_corrections", 0),
                "correction_strategy": final_result.get("correction_strategy", ""),
                "gpt_quality_score": final_result.get("gpt_quality_score", 0)
            })
        
        return response_data
    
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ í…œí”Œë¦¿ ê¸°ë°˜ ìë§‰ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"í…œí”Œë¦¿ ê¸°ë°˜ ìë§‰ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")


@app.get("/video-resolutions")
async def get_video_resolutions():
    """ì§€ì›í•˜ëŠ” ë¹„ë””ì˜¤ í•´ìƒë„ ëª©ë¡"""
    return {
        "available_resolutions": {
            "720p": {
                "size": "1280x720",
                "description": "HD 720p",
                "recommended_for": "ì¼ë°˜ ìš©ë„"
            },
            "1080p": {
                "size": "1920x1080", 
                "description": "Full HD 1080p",
                "recommended_for": "ìœ íŠœë¸Œ ê¶Œì¥ (ê¸°ë³¸ê°’)",
                "default": True
            },
            "1440p": {
                "size": "2560x1440",
                "description": "2K QHD",
                "recommended_for": "ê³ í™”ì§ˆ ì„ í˜¸"
            },
            "4k": {
                "size": "3840x2160",
                "description": "4K UHD",
                "recommended_for": "ìµœê³  í™”ì§ˆ (ìš©ëŸ‰ í¼)"
            }
        },
        "default_resolution": "1080p",
        "youtube_optimized": ["1080p", "1440p", "4k"]
    }


@app.get("/models")
async def get_available_models():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡"""
    if not model_manager:
        raise HTTPException(status_code=503, detail="Model manager not available")
    
    models_info = {}
    for model_name, info in model_manager.AVAILABLE_MODELS.items():
        models_info[model_name] = {
            **info,
            "recommended_for": model_manager.get_recommendation(60, "balanced") == model_name
        }
    
    return {
        "available_models": models_info,
        "total_count": len(models_info)
    }


@app.post("/upload-audio")
async def upload_audio(file: UploadFile = File(...)):
    """ì˜¤ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ"""
    try:
        file_extension = Path(file.filename).suffix.lower()
        if file_extension not in SUPPORTED_AUDIO_FORMATS:
            raise HTTPException(
                status_code=400, 
                detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. ì§€ì› í˜•ì‹: {', '.join(SUPPORTED_AUDIO_FORMATS)}"
            )
        
        file_id = str(uuid.uuid4())
        filename = f"{file_id}{file_extension}"
        file_path = UPLOADS_DIR / filename
        
        with open(file_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)
        
        # ì˜¤ë””ì˜¤ ì •ë³´ ë¶„ì„
        duration = get_audio_duration(str(file_path))
        
        # ì¶”ì²œ ëª¨ë¸ ê³„ì‚°
        recommended_model = None
        if model_manager:
            recommended_model = model_manager.get_recommendation(duration, "balanced")
        
        return {
            "file_id": file_id,
            "filename": filename,
            "original_name": file.filename,
            "size": file_path.stat().st_size,
            "duration": duration,
            "recommended_model": recommended_model,
            "message": "íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤."
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {str(e)}")


@app.post("/generate-subtitles-advanced/{file_id}")
async def generate_subtitles_advanced(
    file_id: str,
    model: str = "whisper-1-optimized",
    language: str = "ko",
    background_color: str = "black",
    video_resolution: str = "1080p",  # ğŸ†• í•´ìƒë„ ì„ íƒ ì˜µì…˜
    enable_quality_analysis: bool = True,
    enable_auto_reprocessing: bool = True,
    enable_gpt_postprocessing: bool = True,  # ğŸ†• GPT í›„ì²˜ë¦¬ ê¸°ë³¸ê°’ì„ Trueë¡œ ë³€ê²½ (í…ŒìŠ¤íŠ¸ìš©)
    target_quality: float = 0.8
):
    """ê³ ê¸‰ ìë§‰ ìƒì„± (í’ˆì§ˆ ë¶„ì„ + ìë™ ì¬ì²˜ë¦¬ + GPT í›„ì²˜ë¦¬)"""
    if not api_available:
        raise HTTPException(status_code=503, detail="Phase 2 features not available")
    
    try:
        # ğŸ” ë””ë²„ê¹…ìš© ë¡œê·¸ ì¶”ê°€
        print(f"ğŸ” [DEBUG] GPT í›„ì²˜ë¦¬ ì˜µì…˜ í™•ì¸:")
        print(f"   enable_gpt_postprocessing: {enable_gpt_postprocessing}")
        print(f"   postprocessor ì¡´ì¬: {postprocessor is not None}")
        print(f"   postprocessor ì‚¬ìš©ê°€ëŠ¥: {postprocessor.is_available() if postprocessor else 'N/A'}")
        
        uploaded_files = list(UPLOADS_DIR.glob(f"{file_id}.*"))
        if not uploaded_files:
            raise HTTPException(status_code=404, detail="ì—…ë¡œë“œëœ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        input_file = uploaded_files[0]
        output_file = OUTPUTS_DIR / f"{file_id}_advanced_subtitled.mp4"
        
        processing_stages = []
        gpt_suffix = " + GPTêµì •" if enable_gpt_postprocessing else ""
        print(f"ğŸš€ ê³ ê¸‰ ìë§‰ ìƒì„± ì‹œì‘: {model} ëª¨ë¸{gpt_suffix}")
        
        # 1ë‹¨ê³„: ì´ˆê¸° ì „ì‚¬
        print("ğŸ“ 1ë‹¨ê³„: ì´ˆê¸° ì „ì‚¬ ì¤‘...")
        processing_stages.append("ì´ˆê¸° ì „ì‚¬")
        result = await model_manager.transcribe_with_model(
            str(input_file), model, language, include_quality_metrics=True
        )
        
        if not result.success:
            raise HTTPException(status_code=500, detail=result.error)
        
        initial_result = {
            "text": result.text,
            "segments": result.segments,
            "processing_time": result.processing_time,
            "model_used": result.model_used,
            "confidence_score": result.confidence_score
        }
        
        # 2ë‹¨ê³„: í’ˆì§ˆ ë¶„ì„
        quality_metrics = None
        if enable_quality_analysis and quality_analyzer:
            print("ğŸ” 2ë‹¨ê³„: í’ˆì§ˆ ë¶„ì„ ì¤‘...")
            processing_stages.append("í’ˆì§ˆ ë¶„ì„")
            quality_metrics = await quality_analyzer.analyze_transcription_quality(
                result.text, result.segments, result.processing_time, result.model_used
            )
            print(f"ğŸ“Š í’ˆì§ˆ ì ìˆ˜: {quality_metrics.overall_score:.3f}")
        
        # 3ë‹¨ê³„: ìë™ ì¬ì²˜ë¦¬ (í•„ìš”ì‹œ)
        final_result = initial_result
        if enable_auto_reprocessing and auto_reprocessor and quality_metrics:
            if quality_metrics.needs_reprocessing and quality_metrics.overall_score < target_quality:
                print("ğŸ”„ 3ë‹¨ê³„: ìë™ ì¬ì²˜ë¦¬ ì¤‘...")
                processing_stages.append("ìë™ ì¬ì²˜ë¦¬")
                final_result = await auto_reprocessor.auto_reprocess_if_needed(
                    str(input_file), initial_result, target_quality
                )
        
        # ğŸ†• 4ë‹¨ê³„: GPT í›„ì²˜ë¦¬ (ì„ íƒì ) - ê°•ì œ í™œì„±í™”
        postprocessing_result = None
        print(f"ğŸ” [DEBUG] GPT í›„ì²˜ë¦¬ ë‹¨ê³„ ì§„ì…:")
        print(f"   enable_gpt_postprocessing: {enable_gpt_postprocessing}")
        print(f"   postprocessor: {postprocessor is not None}")
        print(f"   postprocessor.is_available(): {postprocessor.is_available() if postprocessor else False}")
        
        # ğŸš¨ ì„ì‹œ: í•­ìƒ GPT í›„ì²˜ë¦¬ ì‹¤í–‰ (í…ŒìŠ¤íŠ¸ìš©)
        force_gpt_processing = True
        
        if (enable_gpt_postprocessing or force_gpt_processing) and postprocessor and postprocessor.is_available():
            print("ğŸ¤– 4ë‹¨ê³„: GPT í›„ì²˜ë¦¬ ì‹œì‘! (ê°•ì œ í™œì„±í™”)")
            processing_stages.append("GPT í›„ì²˜ë¦¬")
            
            # ì›ë³¸ í…ìŠ¤íŠ¸ ë¡œê·¸
            print(f"ğŸ“ [DEBUG] ì›ë³¸ ì„¸ê·¸ë¨¼íŠ¸ ({len(final_result['segments'])}ê°œ):")
            for i, seg in enumerate(final_result["segments"][:3]):  # ì²˜ìŒ 3ê°œë§Œ ë¡œê·¸
                print(f"   {i+1}: {seg.get('text', '')}")
            
            # í’ˆì§ˆ ë¶„ì„ ê²°ê³¼ë¥¼ GPT í›„ì²˜ë¦¬ì— ì „ë‹¬
            postprocessing_result = await postprocessor.process_with_progress(
                segments=final_result["segments"],
                quality_metrics=quality_metrics.__dict__ if hasattr(quality_metrics, '__dict__') else None
            )
            
            print(f"ğŸ” [DEBUG] GPT í›„ì²˜ë¦¬ ê²°ê³¼:")
            print(f"   success: {postprocessing_result['success']}")
            print(f"   correction_applied: {postprocessing_result.get('correction_applied', False)}")
            print(f"   total_corrections: {postprocessing_result.get('total_corrections', 0)}")
            
            if postprocessing_result["success"] and postprocessing_result["correction_applied"]:
                # êµì •ëœ í…ìŠ¤íŠ¸ ë¡œê·¸
                print(f"ğŸ“ [DEBUG] êµì •ëœ ì„¸ê·¸ë¨¼íŠ¸:")
                for i, seg in enumerate(postprocessing_result["corrected_segments"][:3]):  # ì²˜ìŒ 3ê°œë§Œ ë¡œê·¸
                    print(f"   {i+1}: {seg.get('text', '')}")
                
                # GPT êµì •ëœ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ì—…ë°ì´íŠ¸
                final_result["segments"] = postprocessing_result["corrected_segments"]
                final_result["text"] = " ".join([seg["text"] for seg in postprocessing_result["corrected_segments"]])
                final_result["gpt_correction_applied"] = True
                final_result["total_corrections"] = postprocessing_result["total_corrections"]
                final_result["correction_strategy"] = postprocessing_result["correction_strategy"]
                final_result["gpt_quality_score"] = postprocessing_result["final_quality_score"]
                final_result["gpt_improvements"] = postprocessing_result["improvement_details"]
                
                print(f"âœ… GPT êµì • ì™„ë£Œ: {postprocessing_result['total_corrections']}ê°œ í•­ëª© ìˆ˜ì •")
                print(f"ğŸ” [DEBUG] ì—…ë°ì´íŠ¸ëœ ìµœì¢… í…ìŠ¤íŠ¸: {final_result['text'][:100]}...")
            else:
                print("â„¹ï¸ GPT êµì •ì´ ì ìš©ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")
                if not postprocessing_result["success"]:
                    print(f"   ì˜¤ë¥˜: {postprocessing_result.get('error', 'Unknown error')}")
                final_result["gpt_correction_applied"] = False
        else:
            print("â­ï¸ GPT í›„ì²˜ë¦¬ ê±´ë„ˆëœ€")
            if not enable_gpt_postprocessing and not force_gpt_processing:
                print("   ì´ìœ : ì‚¬ìš©ìê°€ GPT í›„ì²˜ë¦¬ë¥¼ ë¹„í™œì„±í™”í•¨")
            elif not postprocessor:
                print("   ì´ìœ : GPT í›„ì²˜ë¦¬ê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
            elif not postprocessor.is_available():
                print("   ì´ìœ : GPT í›„ì²˜ë¦¬ê¸° ì‚¬ìš© ë¶ˆê°€ (API í‚¤ í™•ì¸ í•„ìš”)")
        
        # ìµœì¢… ë‹¨ê³„: ë¹„ë””ì˜¤ ìƒì„± (ASS ìë§‰ ì‚¬ìš©)
        final_stage_num = len(processing_stages) + 1
        print(f"ğŸ¬ {final_stage_num}ë‹¨ê³„: ASS í•œ ì¤„ ìë§‰ ë¹„ë””ì˜¤ ìƒì„± ì¤‘... ({video_resolution})")
        ass_content = generate_ass(final_result["segments"], video_resolution)  # ASS ìƒì„±
        
        # ğŸ” ë””ë²„ê¹…ìš©: ASS ë‚´ìš© ì €ì¥
        debug_ass_path = OUTPUTS_DIR / f"{file_id}_advanced_subtitled_debug.ass"
        with open(debug_ass_path, 'w', encoding='utf-8') as f:
            f.write(ass_content)
        print(f"ğŸ” ë””ë²„ê¹…ìš© ASS ì €ì¥: {debug_ass_path}")
        
        create_video_with_subtitles(str(input_file), ass_content, str(output_file), background_color, video_resolution)
        
        # ì‘ë‹µ ë°ì´í„° êµ¬ì„±
        response_data = {
            "file_id": file_id,
            "output_file": f"{file_id}_advanced_subtitled.mp4",
            "download_url": f"/download/{file_id}_advanced_subtitled.mp4",
            "transcript": final_result["text"],
            "segments_count": len(final_result["segments"]),
            "language": language,
            "processing_method": "phase2_advanced",
            "processing_stages": processing_stages,
            "model_used": final_result.get("model_used", model),
            "reprocessed": final_result.get("reprocessed", False),
            "reprocess_attempts": final_result.get("total_reprocess_attempts", 0),
            "quality_metrics": final_result.get("quality_metrics"),
            "processing_time": final_result.get("processing_time", 0),
            "video_resolution": video_resolution,  # ğŸ†• ì‚¬ìš©ëœ í•´ìƒë„ ì •ë³´
            "gpt_postprocessing_enabled": enable_gpt_postprocessing,
            "message": f"Phase 2 ê³ ê¸‰ ì²˜ë¦¬ë¡œ í•œêµ­ì–´ ìë§‰ ë¹„ë””ì˜¤ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ({video_resolution})"
        }
        
        # GPT í›„ì²˜ë¦¬ ê²°ê³¼ ì¶”ê°€
        if postprocessing_result:
            response_data.update({
                "gpt_correction_applied": final_result.get("gpt_correction_applied", False),
                "total_corrections": final_result.get("total_corrections", 0),
                "correction_strategy": final_result.get("correction_strategy", ""),
                "gpt_quality_score": final_result.get("gpt_quality_score", 0),
                "gpt_improvements": final_result.get("gpt_improvements", []),
                "gpt_processing_time": postprocessing_result.get("processing_time", 0)
            })
        
        print(f"ğŸ” [DEBUG] ìµœì¢… ì‘ë‹µ ë°ì´í„°:")
        print(f"   gpt_postprocessing_enabled: {response_data['gpt_postprocessing_enabled']}")
        print(f"   gpt_correction_applied: {response_data.get('gpt_correction_applied', 'N/A')}")
        print(f"   total_corrections: {response_data.get('total_corrections', 'N/A')}")
        
        return response_data
    
    except Exception as e:
        print(f"âŒ ê³ ê¸‰ ìë§‰ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ê³ ê¸‰ ìë§‰ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")



    """í’ˆì§ˆ ë¶„ì„ ì „ìš© ì—”ë“œí¬ì¸íŠ¸"""
    if not quality_analyzer or not model_manager:
        raise HTTPException(status_code=503, detail="Quality analysis not available")
    
    try:
        uploaded_files = list(UPLOADS_DIR.glob(f"{file_id}.*"))
        if not uploaded_files:
            raise HTTPException(status_code=404, detail="ì—…ë¡œë“œëœ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        input_file = uploaded_files[0]
        
        # ì „ì‚¬ ì‹¤í–‰
        result = await model_manager.transcribe_with_model(
            str(input_file), model, language, include_quality_metrics=True
        )
        
        if not result.success:
            raise HTTPException(status_code=500, detail=result.error)
        
        # í’ˆì§ˆ ë¶„ì„
        quality_metrics = await quality_analyzer.analyze_transcription_quality(
            result.text, result.segments, result.processing_time, result.model_used
        )
        
        return {
            "file_id": file_id,
            "transcript": result.text,
            "model_used": result.model_used,
            "processing_time": result.processing_time,
            "quality_analysis": {
                "overall_score": quality_metrics.overall_score,
                "confidence_score": quality_metrics.confidence_score,
                "korean_quality_score": quality_metrics.korean_quality_score,
                "grammar_score": quality_metrics.grammar_score,
                "consistency_score": quality_metrics.consistency_score,
                "completeness_score": quality_metrics.completeness_score,
                "needs_reprocessing": quality_metrics.needs_reprocessing,
                "recommended_model": quality_metrics.recommended_model,
                "improvement_suggestions": quality_metrics.improvement_suggestions,
                "detailed_metrics": {
                    "word_count": quality_metrics.word_count,
                    "korean_word_ratio": quality_metrics.korean_word_ratio,
                    "punctuation_ratio": quality_metrics.punctuation_ratio,
                    "low_confidence_segments": quality_metrics.low_confidence_segments
                }
            }
        }
    
    except Exception as e:
        print(f"âŒ í’ˆì§ˆ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"í’ˆì§ˆ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")


@app.get("/test-smart-line-breaks")
async def test_smart_line_breaks():
    """ğŸ¤– GPT ìŠ¤ë§ˆíŠ¸ ì¤„ë°”ê¿ˆ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    
    # ë¬¸ì œê°€ ìˆëŠ” í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë“¤
    problem_cases = [
        {
            "name": "í•µì‹¬ ë¬¸ì œ: ë‚´ìš©ì„ì´ í˜¼ì ë‚¨ëŠ” ê²½ìš°",
            "text": "ì„±ê²½ì„ ì˜ ì•Œì§€ ëª»í•˜ëŠ” ë¶„ë“¤ì´ë‚˜ ì˜ˆìˆ˜ ê·¸ë¦¬ìŠ¤ë„ì— ëŒ€í•œ ë¯¿ìŒì˜ ì£¼ìš” ë‚´ìš©ì„ ë” ì˜ ì•Œê³  ì‹¶ì€ ë¶„ë“¤ì„ ìœ„í•˜ì—¬ ì„±ê²½ì˜ ì¤„ê±°ë¦¬ì™€ ë‚´ìš©ì„ ì½ê¸° ì‰½ê²Œ ì •ë¦¬í•˜ì˜€ìŠµë‹ˆë‹¤",
            "max_length": 35,
            "expected_problem": "ë‚´ìš©ì„ì´ í˜¼ì í•œ ì¤„ì— ë‚¨ì„ ê°€ëŠ¥ì„±"
        },
        {
            "name": "ë¶ˆê· í˜•í•œ ì¤„ ê¸¸ì´",
            "text": "ì´ê²ƒì€ ë§¤ìš° ê¸´ í…ìŠ¤íŠ¸ë¡œì„œ ì—¬ëŸ¬ ì¤„ë¡œ ë‚˜ëˆ„ì–´ì ¸ì•¼ í•˜ëŠ” ë‚´ìš©ì…ë‹ˆë‹¤ë§Œ ê· í˜•ì„ ë§ì¶”ê¸° ì–´ë µìŠµë‹ˆë‹¤",
            "max_length": 30,
            "expected_problem": "ì²« ì¤„ì€ ê¸¸ê³  ë‘˜ì§¸ ì¤„ì€ ì§§ì„ ê°€ëŠ¥ì„±"
        },
        {
            "name": "ì¡°ì‚¬ ë¶„ë¦¬ ìœ„í—˜",
            "text": "ì»¨ì‚¬ì´ìŠ¤ ë°”ì´ë¸”ì€ ì„±ê²½ ê³µë¶€ì— ê´€ì‹¬ì´ ìˆëŠ” ë¶„ë“¤ì„ ìœ„í•´ ì¤€ë¹„ëœ ê²ƒì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤",
            "max_length": 25,
            "expected_problem": "ì¡°ì‚¬ê°€ ë¶„ë¦¬ë  ìœ„í—˜"
        }
    ]
    
    results = []
    
    for case in problem_cases:
        print(f"\nğŸ§ª í…ŒìŠ¤íŠ¸: {case['name']}")
        print(f"ğŸ“ ì›ë³¸: {case['text']}")
        print(f"ğŸ“ ìµœëŒ€ ê¸¸ì´: {case['max_length']}ì")
        
        # Aë°©ì‹ (ê¸°ì¡´) ì ìš©
        basic_result = apply_word_based_line_breaks(case['text'], case['max_length'])
        
        # ë¬¸ì œì  ê°ì§€
        needs_improvement = needs_smart_improvement(case['text'], basic_result, case['max_length'])
        
        # GPT ìŠ¤ë§ˆíŠ¸ ë¶„í•  ì ìš© (í•„ìš”ì‹œ)
        smart_result = basic_result
        if needs_improvement:
            smart_result = await gpt_smart_line_breaks(case['text'], case['max_length'])
        
        basic_lines = basic_result.split('\n')
        smart_lines = smart_result.split('\n')
        
        result = {
            "test_name": case['name'],
            "original_text": case['text'],
            "expected_problem": case['expected_problem'],
            "max_length": case['max_length'],
            "basic_result": {
                "text": basic_result,
                "lines": basic_lines,
                "line_lengths": [len(line) for line in basic_lines],
                "needs_improvement": needs_improvement
            },
            "smart_result": {
                "text": smart_result,
                "lines": smart_lines,
                "line_lengths": [len(line) for line in smart_lines],
                "improved": smart_result != basic_result
            },
            "improvement_applied": smart_result != basic_result
        }
        
        results.append(result)
    
    return {
        "message": "ğŸ¤– GPT ìŠ¤ë§ˆíŠ¸ ì¤„ë°”ê¿ˆ í…ŒìŠ¤íŠ¸ ì™„ë£Œ",
        "test_results": results,
        "summary": {
            "total_cases": len(problem_cases),
            "improved_cases": sum(1 for r in results if r['improvement_applied']),
            "gpt_available": api_available
        }
    }


@app.get("/test-line-breaks")
async def test_line_breaks():
    """í•œ ì¤„ ìë§‰ ëª¨ë“œ í…ŒìŠ¤íŠ¸ (ì¤„ë°”ê¿ˆ ë¹„í™œì„±í™”)"""
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë“¤
    test_cases = [
        {
            "name": "ê¸°ë³¸ ì¼€ì´ìŠ¤",
            "text": "ë¶„ë“¤ì„ ìœ„í•˜ì—¬ ì„±ê²½ì˜ ì¤„ê±°ë¦¬ì™€ ë‚´ìš©ì„ ì½ê¸° ì‰½ê²Œ ì •ë¦¬í•˜ì˜€ìŠµë‹ˆë‹¤",
            "max_length": 35
        },
        {
            "name": "ê¸´ í…ìŠ¤íŠ¸",
            "text": "ì´ê²ƒì€ ë§¤ìš° ê¸´ í…ìŠ¤íŠ¸ë¡œì„œ ì—¬ëŸ¬ ì¤„ë¡œ ë‚˜ëˆ„ì–´ì ¸ì•¼ í•˜ëŠ” ë‚´ìš©ì…ë‹ˆë‹¤ ê·¸ë¦¬ê³  ë‹¨ì–´ì˜ ì™„ì „ì„±ì„ ë³´ì¥í•´ì•¼ í•©ë‹ˆë‹¤",
            "max_length": 40
        },
        {
            "name": "ì§§ì€ í…ìŠ¤íŠ¸",
            "text": "ì§§ì€ í…ìŠ¤íŠ¸",
            "max_length": 35
        },
        {
            "name": "ë‹¨ì¼ ê¸´ ë‹¨ì–´",
            "text": "ì´ˆì¥í¸ëŒ€ì„œì‚¬ì‹œê¸‰ì´ˆíŠ¹ê¸‰ì „ë¬¸ìš©ì–´",
            "max_length": 20
        }
    ]
    
    results = []
    
    for case in test_cases:
        print(f"\nğŸ§ª í…ŒìŠ¤íŠ¸: {case['name']}")
        print(f"ğŸ“ ì›ë³¸: {case['text']}")
        print(f"ğŸ“ ìµœëŒ€ ê¸¸ì´: {case['max_length']}ì")
        
        # í•œ ì¤„ ìë§‰ ì²˜ë¦¬ ì ìš©
        formatted = apply_word_based_line_breaks(case['text'], case['max_length'])
        lines = formatted.split('\n')
        
        result = {
            "test_name": case['name'],
            "original_text": case['text'],
            "max_length": case['max_length'],
            "formatted_text": formatted,
            "line_count": len(lines),
            "lines": lines,
            "line_lengths": [len(line) for line in lines],
            "single_line_mode": True  # í•œ ì¤„ ëª¨ë“œ í‘œì‹œ
        }
        
        results.append(result)
    
    return {
        "message": "í•œ ì¤„ ìë§‰ ëª¨ë“œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ (ì¤„ë°”ê¿ˆ ë¹„í™œì„±í™”)",
        "test_results": results,
        "single_line_mode": True,
        "supported_resolutions": {
            "720p": "í•œ ì¤„ í‘œì‹œ",
            "1080p": "í•œ ì¤„ í‘œì‹œ", 
            "1440p": "í•œ ì¤„ í‘œì‹œ",
            "4k": "í•œ ì¤„ í‘œì‹œ"
        }
    }
@app.get("/download/{filename}")
async def download_file(filename: str):
    """íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
    file_path = OUTPUTS_DIR / filename
    
    if not file_path.exists():
        raise HTTPException(status_code=404, detail="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    return FileResponse(
        path=str(file_path),
        filename=filename,
        media_type="application/octet-stream"
    )
    file_path = OUTPUTS_DIR / filename
    
    if not file_path.exists():
        raise HTTPException(status_code=404, detail="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    return FileResponse(
        path=str(file_path),
        filename=filename,
        media_type="application/octet-stream"
    )


@app.get("/status/{file_id}")
async def get_status(file_id: str):
    """ì²˜ë¦¬ ìƒíƒœ í™•ì¸"""
    input_files = list(UPLOADS_DIR.glob(f"{file_id}.*"))
    output_files = list(OUTPUTS_DIR.glob(f"{file_id}*"))
    
    status = "unknown"
    if not input_files:
        status = "not_found"
    elif output_files:
        status = "completed"
    else:
        status = "processing"
    
    return {
        "file_id": file_id,
        "status": status,
        "has_input": bool(input_files),
        "output_files": [f.name for f in output_files]
    }


@app.delete("/cleanup/{file_id}")
async def cleanup_files(file_id: str):
    """íŒŒì¼ ì •ë¦¬"""
    try:
        cleaned_files = []
        
        # ì—…ë¡œë“œ íŒŒì¼ ì •ë¦¬
        for file_path in UPLOADS_DIR.glob(f"{file_id}.*"):
            file_path.unlink()
            cleaned_files.append(f"uploads/{file_path.name}")
        
        # ì¶œë ¥ íŒŒì¼ ì •ë¦¬
        for file_path in OUTPUTS_DIR.glob(f"{file_id}*"):
            file_path.unlink()
            cleaned_files.append(f"outputs/{file_path.name}")
        
        return {
            "message": "íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "cleaned_files": cleaned_files
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")


if __name__ == "__main__":
    import uvicorn
    print("ğŸš€ Phase 2 Audio-to-Voice API ì„œë²„ ì‹œì‘!")
    print("ğŸ†• ìƒˆë¡œìš´ ê¸°ëŠ¥ë“¤:")
    print("  ğŸ¤– ì°¨ì„¸ëŒ€ AI ëª¨ë¸ (Whisper-1 ìµœì í™”)")
    print("  âš¡ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬")
    print("  ğŸ” ì§€ëŠ¥í˜• í’ˆì§ˆ ê²€ì¦")
    print("  ğŸ”„ ìë™ ì¬ì²˜ë¦¬ ì‹œìŠ¤í…œ")
    print("  ğŸ“¡ WebSocket ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸")
    print(f"ğŸŒ API ìƒíƒœ: {'ì‚¬ìš© ê°€ëŠ¥' if api_available else 'API í‚¤ í•„ìš”'}")
    uvicorn.run(app, host="0.0.0.0", port=8002)
