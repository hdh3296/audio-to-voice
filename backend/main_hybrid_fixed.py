from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse
from fastapi.staticfiles import StaticFiles
import os
import sys
import shutil
import subprocess
import tempfile
from pathlib import Path
import uuid
from typing import Optional
import asyncio
from datetime import datetime
import hashlib
from dotenv import load_dotenv
from openai import OpenAI
from faster_whisper import WhisperModel

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

app = FastAPI(title="Audio to Voice API (Hybrid)", version="2.0.0")

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://localhost:3001"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ë””ë ‰í† ë¦¬ ì„¤ì •
BASE_DIR = Path(__file__).parent.parent
UPLOADS_DIR = BASE_DIR / "uploads"
OUTPUTS_DIR = BASE_DIR / "outputs"

# ë””ë ‰í† ë¦¬ ìƒì„±
UPLOADS_DIR.mkdir(exist_ok=True)
OUTPUTS_DIR.mkdir(exist_ok=True)

# ì •ì  íŒŒì¼ ì„œë¹™
app.mount("/outputs", StaticFiles(directory=str(OUTPUTS_DIR)), name="outputs")

# ì§€ì›í•˜ëŠ” ì˜¤ë””ì˜¤ í˜•ì‹
SUPPORTED_AUDIO_FORMATS = {".mp3", ".wav", ".m4a", ".aac", ".flac", ".ogg"}

# ì „ì—­ ë³€ìˆ˜ë“¤
local_model = None
openai_client = None
api_available = False

def init_openai_client():
    """OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
    global openai_client, api_available
    
    api_key = os.getenv("OPENAI_API_KEY")
    if api_key and api_key != "your_openai_api_key_here":
        openai_client = OpenAI(api_key=api_key)
        api_available = True
        print("âœ… OpenAI API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
    else:
        print("âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ - ë¡œì»¬ ëª¨ë“œë§Œ ì‚¬ìš© ê°€ëŠ¥")

def load_local_model(model_name: str = "large-v3"):
    """ë¡œì»¬ Whisper ëª¨ë¸ ë¡œë“œ"""
    global local_model
    
    if local_model is None:
        print(f"ğŸ“¥ ë¡œì»¬ Whisper ëª¨ë¸ ë¡œë“œ ì¤‘: {model_name}")
        try:
            local_model = WhisperModel(model_name, device="cpu", compute_type="int8")
            print(f"âœ… ë¡œì»¬ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_name}")
        except Exception as e:
            print(f"âŒ {model_name} ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            if model_name == "large-v3":
                local_model = WhisperModel("medium", device="cpu", compute_type="int8")
                print("âœ… medium ëª¨ë¸ë¡œ ëŒ€ì²´ ì™„ë£Œ")
            else:
                raise e
    
    return local_model

async def transcribe_with_stable_api(audio_path: str, language: str = "ko"):
    """ì•ˆì •í™”ëœ OpenAI API ì „ì‚¬"""
    if not api_available or not openai_client:
        return {"success": False, "error": "API ì‚¬ìš© ë¶ˆê°€ëŠ¥"}
    
    try:
        # ìƒì„¸í•œ í•œêµ­ì–´ í”„ë¡¬í”„íŠ¸
        prompt = """ë‹¤ìŒì€ í•œêµ­ì–´ ìŒì„±ì…ë‹ˆë‹¤. ì •í™•í•œ í•œêµ­ì–´ í‘œì¤€ì–´ë¡œ ì „ì‚¬í•´ì£¼ì„¸ìš”. 
ë¬¸ì¥ ë¶€í˜¸ëŠ” ìì—°ìŠ¤ëŸ½ê²Œ ì‚¬ìš©í•˜ê³ , ë„ì–´ì“°ê¸°ëŠ” í•œêµ­ì–´ ë§ì¶¤ë²•ì— ë§ê²Œ í•´ì£¼ì„¸ìš”. 
ë¸Œëœë“œëª…ì´ë‚˜ ê³ ìœ ëª…ì‚¬ëŠ” ì •í™•í•˜ê²Œ í‘œê¸°í•´ì£¼ì„¸ìš”."""
        
        def _api_call():
            with open(audio_path, "rb") as audio_file:
                return openai_client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_file,
                    language=language,
                    response_format="verbose_json",
                    timestamp_granularities=["segment"],
                    prompt=prompt,
                    temperature=0.0  # ì•ˆì •ì„±ì„ ìœ„í•´ 0
                )
        
        result = await asyncio.to_thread(_api_call)
        
        segments = []
        if result.segments:
            for segment in result.segments:
                segments.append({
                    "start": segment.start,
                    "end": segment.end,
                    "text": segment.text.strip()
                })
        
        return {
            "success": True,
            "text": result.text.strip(),
            "segments": segments,
            "language": getattr(result, 'language', language),
            "processing_method": "openai_api_stable"
        }
        
    except Exception as e:
        return {"success": False, "error": str(e), "processing_method": "openai_api_stable"}

async def transcribe_local(audio_path: str, language: str = "ko"):
    """ë¡œì»¬ Whisper ì „ì‚¬"""
    try:
        model = load_local_model()
        
        korean_prompt = "ì•ˆë…•í•˜ì„¸ìš”. ë‹¤ìŒì€ í•œêµ­ì–´ ìŒì„±ì…ë‹ˆë‹¤. ì •í™•í•œ ë¬¸ì¥ ë¶€í˜¸ì™€ ìì—°ìŠ¤ëŸ¬ìš´ ë„ì–´ì“°ê¸°ë¥¼ í¬í•¨í•´ ì£¼ì„¸ìš”."
        
        def _transcribe():
            segments, info = model.transcribe(
                audio_path, 
                language=language,
                task="transcribe",
                initial_prompt=korean_prompt,
                beam_size=5,
                temperature=0.0
            )
            
            segments_list = []
            full_text = ""
            
            for segment in segments:
                text = segment.text.strip()
                if text:
                    segments_list.append({
                        "start": segment.start,
                        "end": segment.end,
                        "text": text
                    })
                    full_text += text + " "
            
            return {
                "success": True,
                "text": full_text.strip(),
                "segments": segments_list,
                "language": info.language,
                "processing_method": "local_whisper"
            }
        
        return await asyncio.to_thread(_transcribe)
        
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "processing_method": "local_whisper"
        }

def generate_srt(segments):
    """SRT ìë§‰ ìƒì„±"""
    srt_content = ""
    
    for i, segment in enumerate(segments, 1):
        start_time = seconds_to_srt_time(segment["start"])
        end_time = seconds_to_srt_time(segment["end"])
        text = segment["text"].strip()
        
        srt_content += f"{i}\n"
        srt_content += f"{start_time} --> {end_time}\n"
        srt_content += f"{text}\n\n"
    
    return srt_content

def seconds_to_srt_time(seconds: float) -> str:
    """ì´ˆë¥¼ SRT ì‹œê°„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millisecs = int((seconds % 1) * 1000)
    
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"

def get_audio_duration(audio_path: str) -> float:
    """ì˜¤ë””ì˜¤ ê¸¸ì´ êµ¬í•˜ê¸°"""
    try:
        import ffmpeg
        probe = ffmpeg.probe(audio_path)
        duration = float(probe['streams'][0]['duration'])
        return duration
    except:
        return 60.0

def create_video_with_subtitles(audio_path: str, srt_content: str, output_path: str, background_color: str = "black"):
    """ë¹„ë””ì˜¤ ìƒì„±"""
    try:
        duration = get_audio_duration(audio_path)
        
        with tempfile.NamedTemporaryFile(mode='w', suffix='.srt', delete=False, encoding='utf-8') as srt_file:
            srt_file.write(srt_content)
            srt_path = srt_file.name
        
        font_style = (
            'FontSize=28,'
            'PrimaryColour=&Hffffff,'
            'OutlineColour=&H000000,'
            'Outline=3,'
            'Shadow=1,'
            'Alignment=2,'
            'MarginV=50'
        )
        
        cmd = [
            'ffmpeg',
            '-f', 'lavfi',
            '-i', f'color=c={background_color}:s=1280x720:d={duration}',
            '-i', audio_path,
            '-vf', f'subtitles={srt_path}:force_style=\'{font_style}\'',
            '-c:v', 'libx264',
            '-preset', 'medium',
            '-crf', '23',
            '-c:a', 'aac',
            '-b:a', '128k',
            '-shortest',
            '-y',
            output_path
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode != 0:
            raise Exception(f"FFmpeg ì˜¤ë¥˜: {result.stderr}")
        
        os.unlink(srt_path)
        
    except Exception as e:
        if 'srt_path' in locals() and os.path.exists(srt_path):
            os.unlink(srt_path)
        raise Exception(f"ë¹„ë””ì˜¤ ìƒì„± ì‹¤íŒ¨: {str(e)}")

# ì„œë²„ ì‹œì‘ì‹œ ì´ˆê¸°í™”
init_openai_client()

@app.get("/")
async def root():
    return {
        "message": "Audio to Voice API (Hybrid)", 
        "status": "running", 
        "version": "2.0.0",
        "modes": {
            "local": "Always available",
            "api": "Available" if api_available else "Requires API key"
        }
    }

@app.get("/health")
async def health_check():
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}

@app.get("/api-status")
async def api_status():
    """OpenAI API ìƒíƒœ í™•ì¸"""
    return {
        "openai_api_available": api_available,
        "max_audio_length_minutes": 10,
        "api_configured": api_available
    }

@app.post("/upload-audio")
async def upload_audio(file: UploadFile = File(...)):
    """ì˜¤ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ"""
    try:
        file_extension = Path(file.filename).suffix.lower()
        if file_extension not in SUPPORTED_AUDIO_FORMATS:
            raise HTTPException(
                status_code=400, 
                detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. ì§€ì› í˜•ì‹: {', '.join(SUPPORTED_AUDIO_FORMATS)}"
            )
        
        file_id = str(uuid.uuid4())
        filename = f"{file_id}{file_extension}"
        file_path = UPLOADS_DIR / filename
        
        with open(file_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)
        
        return {
            "file_id": file_id,
            "filename": filename,
            "original_name": file.filename,
            "size": file_path.stat().st_size,
            "message": "íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤."
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {str(e)}")

@app.post("/generate-subtitles/{file_id}")
async def generate_subtitles(
    file_id: str,
    model: str = "large-v3",
    language: Optional[str] = "ko",
    task: str = "transcribe",
    background_color: str = "black",
    use_api: bool = False
):
    """í•˜ì´ë¸Œë¦¬ë“œ ìë§‰ ìƒì„±"""
    try:
        uploaded_files = list(UPLOADS_DIR.glob(f"{file_id}.*"))
        if not uploaded_files:
            raise HTTPException(status_code=404, detail="ì—…ë¡œë“œëœ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        input_file = uploaded_files[0]
        output_file = OUTPUTS_DIR / f"{file_id}_subtitled.mp4"
        
        mode_text = "ì•ˆì •í™” API" if use_api else "ë¡œì»¬"
        print(f"ğŸ¯ {mode_text} ëª¨ë“œë¡œ ìŒì„± ì²˜ë¦¬ ì‹œì‘")
        
        # í•˜ì´ë¸Œë¦¬ë“œ ì²˜ë¦¬
        if use_api and api_available:
            print("ğŸŒ ì•ˆì •í™” API ëª¨ë“œ ì‹œë„...")
            result = await transcribe_with_stable_api(str(input_file), language)
            
            if not result.get("success"):
                print(f"âš ï¸ API ëª¨ë“œ ì‹¤íŒ¨, ë¡œì»¬ ëª¨ë“œë¡œ ëŒ€ì²´: {result.get('error')}")
                result = await transcribe_local(str(input_file), language)
        else:
            print("ğŸ  ë¡œì»¬ ëª¨ë“œë¡œ ì²˜ë¦¬...")
            result = await transcribe_local(str(input_file), language)
        
        if not result.get("success"):
            raise HTTPException(status_code=500, detail=result.get("error"))
        
        # SRT ìƒì„± ë° ë¹„ë””ì˜¤ ìƒì„±
        srt_content = generate_srt(result["segments"])
        create_video_with_subtitles(str(input_file), srt_content, str(output_file), background_color)
        
        return {
            "file_id": file_id,
            "output_file": f"{file_id}_subtitled.mp4",
            "download_url": f"/download/{file_id}_subtitled.mp4",
            "transcript": result["text"],
            "segments_count": len(result["segments"]),
            "language": result.get("language", language),
            "processing_method": result.get("processing_method", "unknown"),
            "use_api_mode": use_api,
            "message": f"{mode_text} ëª¨ë“œë¡œ í•œêµ­ì–´ ìë§‰ ë¹„ë””ì˜¤ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤."
        }
    
    except Exception as e:
        print(f"âŒ ìë§‰ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ìë§‰ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")

@app.get("/download/{filename}")
async def download_file(filename: str):
    """íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
    file_path = OUTPUTS_DIR / filename
    
    if not file_path.exists():
        raise HTTPException(status_code=404, detail="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    return FileResponse(
        path=str(file_path),
        filename=filename,
        media_type="application/octet-stream"
    )

@app.get("/status/{file_id}")
async def get_status(file_id: str):
    """ì²˜ë¦¬ ìƒíƒœ í™•ì¸"""
    input_files = list(UPLOADS_DIR.glob(f"{file_id}.*"))
    output_file = OUTPUTS_DIR / f"{file_id}_subtitled.mp4"
    
    status = "unknown"
    if not input_files:
        status = "not_found"
    elif output_file.exists():
        status = "completed"
    else:
        status = "processing"
    
    return {
        "file_id": file_id,
        "status": status,
        "has_input": bool(input_files),
        "has_output": output_file.exists()
    }

@app.delete("/cleanup/{file_id}")
async def cleanup_files(file_id: str):
    """íŒŒì¼ ì •ë¦¬"""
    try:
        for file_path in UPLOADS_DIR.glob(f"{file_id}.*"):
            file_path.unlink()
        
        for file_path in OUTPUTS_DIR.glob(f"{file_id}*"):
            file_path.unlink()
        
        return {"message": "íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤."}
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")

if __name__ == "__main__":
    import uvicorn
    print("ğŸš€ í•˜ì´ë¸Œë¦¬ë“œ Audio-to-Voice API ì„œë²„ ì‹œì‘!")
    print("ğŸ  ë¡œì»¬ ëª¨ë“œ: Faster-Whisper (í•­ìƒ ì‚¬ìš© ê°€ëŠ¥)")
    print(f"ğŸŒ API ëª¨ë“œ: ì•ˆì •í™”ëœ OpenAI Whisper API ({'ì‚¬ìš© ê°€ëŠ¥' if api_available else 'API í‚¤ í•„ìš”'})")
    uvicorn.run(app, host="0.0.0.0", port=8000)
