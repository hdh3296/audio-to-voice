"""
ğŸš€ Phase 2: ì§€ëŠ¥í˜• í’ˆì§ˆ ê²€ì¦ ì‹œìŠ¤í…œ
- ì‹ ë¢°ë„ ê¸°ë°˜ ìë™ í’ˆì§ˆ í‰ê°€
- ìë™ ì¬ì²˜ë¦¬ ë° ìµœì í™”
- ìƒì„¸í•œ í’ˆì§ˆ ë¦¬í¬íŠ¸ ìƒì„±
"""

import asyncio
import json
import time
import statistics
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, asdict
from pathlib import Path
import re
import math


@dataclass
class QualityMetrics:
    """í’ˆì§ˆ í‰ê°€ ë©”íŠ¸ë¦­"""
    overall_score: float  # 0.0 ~ 1.0
    confidence_score: float
    korean_quality_score: float
    grammar_score: float
    consistency_score: float
    completeness_score: float
    
    # ì„¸ë¶€ ë¶„ì„
    word_count: int
    korean_word_ratio: float
    punctuation_ratio: float
    avg_segment_confidence: float
    low_confidence_segments: int
    
    # ì¶”ì²œì‚¬í•­
    needs_reprocessing: bool
    recommended_model: Optional[str]
    improvement_suggestions: List[str]


@dataclass
class QualityIssue:
    """í’ˆì§ˆ ë¬¸ì œì """
    issue_type: str
    severity: str  # "low", "medium", "high", "critical"
    description: str
    segment_id: Optional[int] = None
    start_time: Optional[float] = None
    end_time: Optional[float] = None
    suggestion: Optional[str] = None


class KoreanTextAnalyzer:
    """í•œêµ­ì–´ í…ìŠ¤íŠ¸ í’ˆì§ˆ ë¶„ì„ê¸°"""
    
    # í•œêµ­ì–´ ìœ ë‹ˆì½”ë“œ ë²”ìœ„
    KOREAN_RANGE = (0xAC00, 0xD7AF)  # ì™„ì„±í˜• í•œê¸€
    KOREAN_JAMO_RANGE = (0x1100, 0x11FF)  # í•œê¸€ ìëª¨
    
    # ì¼ë°˜ì ì¸ í•œêµ­ì–´ ë¬¸ì¥ ë¶€í˜¸
    KOREAN_PUNCTUATION = '.,!?;:()[]{}""''ã€Œã€ã€ã€â€¦Â·'
    
    def analyze_korean_quality(self, text: str) -> Dict[str, float]:
        """í•œêµ­ì–´ í’ˆì§ˆ ë¶„ì„"""
        
        if not text.strip():
            return {
                "korean_ratio": 0.0,
                "grammar_score": 0.0,
                "naturalness_score": 0.0,
                "punctuation_score": 0.0
            }
        
        # 1. í•œêµ­ì–´ ë¹„ìœ¨ ê³„ì‚°
        korean_chars = sum(1 for c in text if self._is_korean_char(c))
        total_chars = len(re.sub(r'\s+', '', text))  # ê³µë°± ì œì™¸
        korean_ratio = korean_chars / total_chars if total_chars > 0 else 0.0
        
        # 2. ë¬¸ë²• ì ìˆ˜ (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
        grammar_score = self._calculate_grammar_score(text)
        
        # 3. ìì—°ìŠ¤ëŸ¬ì›€ ì ìˆ˜
        naturalness_score = self._calculate_naturalness_score(text)
        
        # 4. ë¬¸ì¥ ë¶€í˜¸ ì ìˆ˜
        punctuation_score = self._calculate_punctuation_score(text)
        
        return {
            "korean_ratio": korean_ratio,
            "grammar_score": grammar_score,
            "naturalness_score": naturalness_score,
            "punctuation_score": punctuation_score
        }
    
    def _is_korean_char(self, char: str) -> bool:
        """í•œêµ­ì–´ ë¬¸ì íŒë³„"""
        code = ord(char)
        return (self.KOREAN_RANGE[0] <= code <= self.KOREAN_RANGE[1] or
                self.KOREAN_JAMO_RANGE[0] <= code <= self.KOREAN_JAMO_RANGE[1])
    
    def _calculate_grammar_score(self, text: str) -> float:
        """ë¬¸ë²• ì ìˆ˜ ê³„ì‚° (ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜)"""
        score = 1.0
        
        # ì¡°ì‚¬ ì‚¬ìš© íŒ¨í„´ í™•ì¸
        particles = ['ì€', 'ëŠ”', 'ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì—', 'ì—ì„œ', 'ë¡œ', 'ìœ¼ë¡œ', 'ì™€', 'ê³¼']
        particle_count = sum(text.count(p) for p in particles)
        words = len(text.split())
        
        if words > 0:
            particle_ratio = particle_count / words
            # ì ì ˆí•œ ì¡°ì‚¬ ì‚¬ìš© ë¹„ìœ¨ (0.1~0.3ì´ ìì—°ìŠ¤ëŸ¬ì›€)
            if 0.1 <= particle_ratio <= 0.3:
                score *= 1.0
            else:
                score *= max(0.5, 1.0 - abs(particle_ratio - 0.2))
        
        return score
    
    def _calculate_naturalness_score(self, text: str) -> float:
        """ìì—°ìŠ¤ëŸ¬ì›€ ì ìˆ˜"""
        score = 1.0
        
        # ë°˜ë³µ ë‹¨ì–´ íŒ¨í„´ ì²´í¬
        words = text.split()
        if len(words) > 1:
            repeated_words = len(words) - len(set(words))
            repetition_ratio = repeated_words / len(words)
            score *= max(0.5, 1.0 - repetition_ratio * 2)
        
        # ë¬¸ì¥ ê¸¸ì´ ë¶„í¬ ì²´í¬
        sentences = re.split(r'[.!?]\s*', text)
        if sentences:
            avg_sentence_length = statistics.mean(len(s.split()) for s in sentences if s.strip())
            # ì ì ˆí•œ ë¬¸ì¥ ê¸¸ì´ (5~15 ë‹¨ì–´)
            if 5 <= avg_sentence_length <= 15:
                score *= 1.0
            else:
                score *= max(0.7, 1.0 - abs(avg_sentence_length - 10) / 20)
        
        return score
    
    def _calculate_punctuation_score(self, text: str) -> float:
        """ë¬¸ì¥ ë¶€í˜¸ ì ìˆ˜"""
        if not text.strip():
            return 0.0
        
        punctuation_count = sum(1 for c in text if c in self.KOREAN_PUNCTUATION)
        total_chars = len(text)
        punctuation_ratio = punctuation_count / total_chars
        
        # ì ì ˆí•œ ë¬¸ì¥ ë¶€í˜¸ ë¹„ìœ¨ (2~8%)
        if 0.02 <= punctuation_ratio <= 0.08:
            return 1.0
        else:
            return max(0.5, 1.0 - abs(punctuation_ratio - 0.05) * 10)


class QualityAnalyzer:
    """í†µí•© í’ˆì§ˆ ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.korean_analyzer = KoreanTextAnalyzer()
        
        # í’ˆì§ˆ ì„ê³„ê°’ ì„¤ì •
        self.thresholds = {
            "confidence_min": 0.7,
            "korean_ratio_min": 0.8,
            "grammar_score_min": 0.6,
            "overall_score_min": 0.75
        }
    
    async def analyze_transcription_quality(
        self,
        text: str,
        segments: List[Dict],
        processing_time: float,
        model_used: str
    ) -> QualityMetrics:
        """ì „ì‚¬ í’ˆì§ˆ ì¢…í•© ë¶„ì„"""
        
        start_time = time.time()
        
        # 1. ê¸°ë³¸ ë©”íŠ¸ë¦­ ê³„ì‚°
        word_count = len(text.split()) if text else 0
        
        # 2. í•œêµ­ì–´ í’ˆì§ˆ ë¶„ì„
        korean_analysis = self.korean_analyzer.analyze_korean_quality(text)
        
        # 3. ì„¸ê·¸ë¨¼íŠ¸ ì‹ ë¢°ë„ ë¶„ì„
        confidences = [seg.get('confidence', 0.5) for seg in segments if seg.get('confidence')]
        avg_confidence = statistics.mean(confidences) if confidences else 0.5
        low_confidence_segments = sum(1 for c in confidences if c < self.thresholds["confidence_min"])
        
        # 4. ì™„ì„±ë„ ì ìˆ˜ (ì„¸ê·¸ë¨¼íŠ¸ ì—°ê²°ì„±)
        completeness_score = self._calculate_completeness_score(segments, text)
        
        # 5. ì¼ê´€ì„± ì ìˆ˜ (ì‹œê°„ì  ì—°ì†ì„±)
        consistency_score = self._calculate_consistency_score(segments)
        
        # 6. ì „ì²´ ì ìˆ˜ ê³„ì‚°
        overall_score = self._calculate_overall_score(
            avg_confidence,
            korean_analysis["korean_ratio"],
            korean_analysis["grammar_score"],
            completeness_score,
            consistency_score
        )
        
        # 7. ì¬ì²˜ë¦¬ í•„ìš”ì„± íŒë‹¨
        needs_reprocessing = self._should_reprocess(
            overall_score, avg_confidence, korean_analysis
        )
        
        # 8. ëª¨ë¸ ì¶”ì²œ
        recommended_model = self._recommend_model(
            overall_score, processing_time, model_used
        )
        
        # 9. ê°œì„  ì œì•ˆ
        improvement_suggestions = self._generate_improvement_suggestions(
            overall_score, avg_confidence, korean_analysis, low_confidence_segments
        )
        
        analysis_time = time.time() - start_time
        print(f"ğŸ” í’ˆì§ˆ ë¶„ì„ ì™„ë£Œ - {analysis_time:.2f}ì´ˆ")
        
        return QualityMetrics(
            overall_score=overall_score,
            confidence_score=avg_confidence,
            korean_quality_score=(korean_analysis["korean_ratio"] + korean_analysis["grammar_score"]) / 2,
            grammar_score=korean_analysis["grammar_score"],
            consistency_score=consistency_score,
            completeness_score=completeness_score,
            
            word_count=word_count,
            korean_word_ratio=korean_analysis["korean_ratio"],
            punctuation_ratio=korean_analysis["punctuation_score"],
            avg_segment_confidence=avg_confidence,
            low_confidence_segments=low_confidence_segments,
            
            needs_reprocessing=needs_reprocessing,
            recommended_model=recommended_model,
            improvement_suggestions=improvement_suggestions
        )
    
    def _calculate_completeness_score(self, segments: List[Dict], text: str) -> float:
        """ì™„ì„±ë„ ì ìˆ˜ ê³„ì‚°"""
        if not segments or not text:
            return 0.0
        
        # ì„¸ê·¸ë¨¼íŠ¸ í…ìŠ¤íŠ¸ í•©ê³„ì™€ ì „ì²´ í…ìŠ¤íŠ¸ ë¹„êµ
        segment_text = " ".join(seg.get("text", "") for seg in segments)
        segment_words = len(segment_text.split())
        total_words = len(text.split())
        
        if total_words == 0:
            return 0.0
        
        return min(1.0, segment_words / total_words)
    
    def _calculate_consistency_score(self, segments: List[Dict]) -> float:
        """ì¼ê´€ì„± ì ìˆ˜ ê³„ì‚°"""
        if len(segments) < 2:
            return 1.0
        
        # ì‹œê°„ ê°„ê²©ì˜ ì¼ê´€ì„± ì²´í¬
        gaps = []
        overlaps = 0
        
        for i in range(len(segments) - 1):
            current_end = segments[i].get("end", 0)
            next_start = segments[i + 1].get("start", 0)
            
            if next_start > current_end:
                gaps.append(next_start - current_end)
            elif next_start < current_end:
                overlaps += 1
        
        # í° ê°„ê²©ì´ë‚˜ ê²¹ì¹¨ì´ ë§ìœ¼ë©´ ì ìˆ˜ ê°ì†Œ
        score = 1.0
        
        if gaps:
            avg_gap = statistics.mean(gaps)
            if avg_gap > 2.0:  # 2ì´ˆ ì´ìƒ ê°„ê²©
                score *= max(0.5, 1.0 - (avg_gap - 2.0) / 10.0)
        
        if overlaps > 0:
            overlap_ratio = overlaps / len(segments)
            score *= max(0.5, 1.0 - overlap_ratio)
        
        return score
    
    def _calculate_overall_score(
        self,
        confidence: float,
        korean_ratio: float,
        grammar_score: float,
        completeness_score: float,
        consistency_score: float
    ) -> float:
        """ì „ì²´ ì ìˆ˜ ê³„ì‚° (ê°€ì¤‘ í‰ê· )"""
        
        weights = {
            "confidence": 0.3,
            "korean_ratio": 0.25,
            "grammar": 0.2,
            "completeness": 0.15,
            "consistency": 0.1
        }
        
        return (
            confidence * weights["confidence"] +
            korean_ratio * weights["korean_ratio"] +
            grammar_score * weights["grammar"] +
            completeness_score * weights["completeness"] +
            consistency_score * weights["consistency"]
        )
    
    def _should_reprocess(
        self,
        overall_score: float,
        confidence: float,
        korean_analysis: Dict[str, float]
    ) -> bool:
        """ì¬ì²˜ë¦¬ í•„ìš”ì„± íŒë‹¨"""
        
        return (
            overall_score < self.thresholds["overall_score_min"] or
            confidence < self.thresholds["confidence_min"] or
            korean_analysis["korean_ratio"] < self.thresholds["korean_ratio_min"] or
            korean_analysis["grammar_score"] < self.thresholds["grammar_score_min"]
        )
    
    def _recommend_model(
        self,
        overall_score: float,
        processing_time: float,
        current_model: str
    ) -> Optional[str]:
        """ëª¨ë¸ ì¶”ì²œ"""
        
        if overall_score >= 0.9:
            return None  # í˜„ì¬ ëª¨ë¸ë¡œ ì¶©ë¶„
        
        # í’ˆì§ˆì´ ë‚®ìœ¼ë©´ ë” ê°•ë ¥í•œ ëª¨ë¸ ì¶”ì²œ
        if overall_score < 0.7:
            if current_model == "whisper-1":
                return "gpt-4o-audio-preview"
            else:
                return "whisper-1"  # ë‹¤ë¥¸ ëª¨ë¸ ì‹œë„
        
        # ì²˜ë¦¬ ì‹œê°„ì´ ë„ˆë¬´ ê¸¸ë©´ ë¹ ë¥¸ ëª¨ë¸ ì¶”ì²œ
        if processing_time > 60:
            return "whisper-1"
        
        return None
    
    def _generate_improvement_suggestions(
        self,
        overall_score: float,
        confidence: float,
        korean_analysis: Dict[str, float],
        low_confidence_segments: int
    ) -> List[str]:
        """ê°œì„  ì œì•ˆ ìƒì„±"""
        
        suggestions = []
        
        if confidence < 0.7:
            suggestions.append("ì‹ ë¢°ë„ê°€ ë‚®ìŠµë‹ˆë‹¤. ë” ë†’ì€ í’ˆì§ˆì˜ ëª¨ë¸ì„ ì‚¬ìš©í•´ë³´ì„¸ìš”.")
        
        if korean_analysis["korean_ratio"] < 0.8:
            suggestions.append("í•œêµ­ì–´ ë¹„ìœ¨ì´ ë‚®ìŠµë‹ˆë‹¤. ì–¸ì–´ ì„¤ì •ì„ í™•ì¸í•˜ê³  í•œêµ­ì–´ íŠ¹í™” í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•´ë³´ì„¸ìš”.")
        
        if korean_analysis["grammar_score"] < 0.6:
            suggestions.append("ë¬¸ë²• ì ìˆ˜ê°€ ë‚®ìŠµë‹ˆë‹¤. GPT í›„ì²˜ë¦¬ë¥¼ í†µí•œ êµì •ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
        
        if low_confidence_segments > 0:
            suggestions.append(f"{low_confidence_segments}ê°œ ì„¸ê·¸ë¨¼íŠ¸ì˜ ì‹ ë¢°ë„ê°€ ë‚®ìŠµë‹ˆë‹¤. í•´ë‹¹ êµ¬ê°„ì„ ì¬ì²˜ë¦¬í•´ë³´ì„¸ìš”.")
        
        if overall_score < 0.6:
            suggestions.append("ì „ì²´ì ì¸ í’ˆì§ˆì´ ë‚®ìŠµë‹ˆë‹¤. ì˜¤ë””ì˜¤ íŒŒì¼ì˜ í’ˆì§ˆì„ í™•ì¸í•˜ê±°ë‚˜ ë‹¤ë¥¸ ëª¨ë¸ì„ ì‹œë„í•´ë³´ì„¸ìš”.")
        
        return suggestions


class AutoReprocessor:
    """ìë™ ì¬ì²˜ë¦¬ ì‹œìŠ¤í…œ"""
    
    def __init__(self, model_manager, quality_analyzer: QualityAnalyzer):
        self.model_manager = model_manager
        self.quality_analyzer = quality_analyzer
        self.max_reprocess_attempts = 2
    
    async def auto_reprocess_if_needed(
        self,
        audio_path: str,
        initial_result: Dict,
        target_quality: float = 0.8
    ) -> Dict:
        """í•„ìš”ì‹œ ìë™ ì¬ì²˜ë¦¬"""
        
        current_result = initial_result
        attempt = 0
        
        while attempt < self.max_reprocess_attempts:
            # í’ˆì§ˆ ë¶„ì„
            quality = await self.quality_analyzer.analyze_transcription_quality(
                current_result.get("text", ""),
                current_result.get("segments", []),
                current_result.get("processing_time", 0),
                current_result.get("model_used", "unknown")
            )
            
            print(f"ğŸ” í’ˆì§ˆ ì ìˆ˜: {quality.overall_score:.3f} (ëª©í‘œ: {target_quality:.3f})")
            
            # ëª©í‘œ í’ˆì§ˆ ë‹¬ì„±ì‹œ ì¢…ë£Œ
            if quality.overall_score >= target_quality:
                current_result["quality_metrics"] = asdict(quality)
                print("âœ… ëª©í‘œ í’ˆì§ˆ ë‹¬ì„±!")
                break
            
            # ì¬ì²˜ë¦¬ í•„ìš”ì„± í™•ì¸
            if not quality.needs_reprocessing:
                print("âš ï¸ ì¬ì²˜ë¦¬ê°€ ë„ì›€ì´ ë˜ì§€ ì•Šì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤.")
                break
            
            # ë‹¤ë¥¸ ëª¨ë¸ë¡œ ì¬ì²˜ë¦¬ ì‹œë„
            if quality.recommended_model:
                print(f"ğŸ”„ {quality.recommended_model} ëª¨ë¸ë¡œ ì¬ì²˜ë¦¬ ì‹œë„...")
                
                reprocess_result = await self.model_manager.transcribe_with_model(
                    audio_path,
                    quality.recommended_model,
                    "ko",
                    include_quality_metrics=True
                )
                
                if reprocess_result.success:
                    current_result = {
                        "text": reprocess_result.text,
                        "segments": reprocess_result.segments,
                        "processing_time": reprocess_result.processing_time,
                        "model_used": reprocess_result.model_used,
                        "reprocessed": True,
                        "reprocess_attempt": attempt + 1
                    }
                else:
                    print(f"âŒ ì¬ì²˜ë¦¬ ì‹¤íŒ¨: {reprocess_result.error}")
                    break
            else:
                print("âš ï¸ ì¶”ì²œí•  ëŒ€ì•ˆ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
                break
            
            attempt += 1
        
        # ìµœì¢… í’ˆì§ˆ ë¶„ì„
        final_quality = await self.quality_analyzer.analyze_transcription_quality(
            current_result.get("text", ""),
            current_result.get("segments", []),
            current_result.get("processing_time", 0),
            current_result.get("model_used", "unknown")
        )
        
        current_result["quality_metrics"] = asdict(final_quality)
        current_result["total_reprocess_attempts"] = attempt
        
        return current_result


# í…ŒìŠ¤íŠ¸ìš© í•¨ìˆ˜ë“¤
async def test_quality_system():
    """í’ˆì§ˆ ê²€ì¦ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    analyzer = QualityAnalyzer()
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    test_cases = [
        {
            "text": "ì•ˆë…•í•˜ì„¸ìš”. ì´ê²ƒì€ í•œêµ­ì–´ ìŒì„± ì¸ì‹ í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤.",
            "segments": [
                {"start": 0.0, "end": 2.0, "text": "ì•ˆë…•í•˜ì„¸ìš”.", "confidence": 0.95},
                {"start": 2.0, "end": 5.0, "text": "ì´ê²ƒì€ í•œêµ­ì–´ ìŒì„± ì¸ì‹ í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤.", "confidence": 0.89}
            ]
        },
        {
            "text": "hello world this is english test",
            "segments": [
                {"start": 0.0, "end": 3.0, "text": "hello world this is english test", "confidence": 0.75}
            ]
        }
    ]
    
    for i, test_case in enumerate(test_cases):
        print(f"\nğŸ§ª í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ {i+1}:")
        print(f"ğŸ“ í…ìŠ¤íŠ¸: {test_case['text']}")
        
        quality = await analyzer.analyze_transcription_quality(
            test_case["text"],
            test_case["segments"],
            processing_time=2.5,
            model_used="test_model"
        )
        
        print(f"ğŸ“Š í’ˆì§ˆ ë¶„ì„ ê²°ê³¼:")
        print(f"  ğŸ¯ ì „ì²´ ì ìˆ˜: {quality.overall_score:.3f}")
        print(f"  ğŸ¤– ì‹ ë¢°ë„: {quality.confidence_score:.3f}")
        print(f"  ğŸ‡°ğŸ‡· í•œêµ­ì–´ í’ˆì§ˆ: {quality.korean_quality_score:.3f}")
        print(f"  ğŸ“ ë¬¸ë²• ì ìˆ˜: {quality.grammar_score:.3f}")
        print(f"  ğŸ”„ ì¬ì²˜ë¦¬ í•„ìš”: {'ì˜ˆ' if quality.needs_reprocessing else 'ì•„ë‹ˆì˜¤'}")
        
        if quality.improvement_suggestions:
            print(f"  ğŸ’¡ ê°œì„  ì œì•ˆ:")
            for suggestion in quality.improvement_suggestions:
                print(f"    - {suggestion}")


if __name__ == "__main__":
    asyncio.run(test_quality_system())
