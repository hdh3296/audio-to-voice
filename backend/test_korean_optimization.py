#!/usr/bin/env python3
"""
OpenAI Whisper API ìµœì í™” ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
í•œêµ­ì–´ ì •í™•ë„ ê°œì„  í™•ì¸ìš©
"""
import os
import asyncio
from dotenv import load_dotenv
from openai import OpenAI
import sys

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

async def test_optimized_korean_api(audio_file_path: str):
    """ìµœì í™”ëœ í•œêµ­ì–´ OpenAI Whisper API í…ŒìŠ¤íŠ¸"""
    
    # API í‚¤ í™•ì¸
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key or api_key == "your_openai_api_key_here":
        print("âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return False
    
    # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    client = OpenAI(api_key=api_key)
    print(f"âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
    
    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(audio_file_path):
        print(f"âŒ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_file_path}")
        return False
    
    file_size = os.path.getsize(audio_file_path)
    print(f"ğŸ“ íŒŒì¼ ì •ë³´: {os.path.basename(audio_file_path)} ({file_size/1024:.1f}KB)")
    
    try:
        print("ğŸ¯ ìµœì í™”ëœ í•œêµ­ì–´ OpenAI Whisper API ì „ì‚¬ ì‹œì‘...")
        
        # í•œêµ­ì–´ ìµœì í™” í”„ë¡¬í”„íŠ¸
        korean_prompt = (
            "ë‹¤ìŒì€ í•œêµ­ì–´ ìŒì„±ì…ë‹ˆë‹¤. "
            "ì •í™•í•œ ë§ì¶¤ë²•ê³¼ ìì—°ìŠ¤ëŸ¬ìš´ ë„ì–´ì“°ê¸°ë¥¼ ì‚¬ìš©í•´ ì£¼ì„¸ìš”. "
            "ë¬¸ì¥ ë¶€í˜¸ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ê³ , êµ¬ì–´ì²´ í‘œí˜„ì„ ìì—°ìŠ¤ëŸ½ê²Œ ë³€í™˜í•´ ì£¼ì„¸ìš”."
        )
        
        # API í˜¸ì¶œì„ ë³„ë„ í•¨ìˆ˜ë¡œ ë¶„ë¦¬
        def call_optimized_api():
            with open(audio_file_path, "rb") as audio_file:
                transcript = client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_file,
                    language="ko",  # í•œêµ­ì–´ ëª…ì‹œì  ì„¤ì •
                    response_format="verbose_json",
                    timestamp_granularities=["segment"],
                    prompt=korean_prompt,  # ğŸ†• í•œêµ­ì–´ ìµœì í™” í”„ë¡¬í”„íŠ¸
                    temperature=0.0  # ğŸ†• ì¼ê´€ì„±ì„ ìœ„í•œ ë‚®ì€ ì˜¨ë„
                )
                return transcript
        
        # ë¹„ë™ê¸° ì‹¤í–‰
        result = await asyncio.to_thread(call_optimized_api)
        
        print("âœ… ìµœì í™”ëœ API ì „ì‚¬ ì™„ë£Œ!")
        print(f"ğŸŒ ê°ì§€ëœ ì–¸ì–´: {result.language}")
        print(f"ğŸ“ ì „ì‚¬ í…ìŠ¤íŠ¸: {result.text}")
        print(f"ğŸ“Š ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜: {len(result.segments) if result.segments else 0}")
        
        # ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ ìƒì„¸ ì¶œë ¥
        if result.segments:
            print("\nğŸ“‹ ì„¸ê·¸ë¨¼íŠ¸ ìƒì„¸ ì •ë³´:")
            for i, segment in enumerate(result.segments):
                start_time = f"{int(segment.start//60)}:{int(segment.start%60):02d}"
                end_time = f"{int(segment.end//60)}:{int(segment.end%60):02d}"
                print(f"  {i+1}. [{start_time}-{end_time}] {segment.text}")
        
        # ë¹„ìš© ê³„ì‚°
        duration_seconds = result.duration if hasattr(result, 'duration') else 0
        if duration_seconds == 0 and result.segments:
            duration_seconds = result.segments[-1].end
        
        cost = (duration_seconds / 60) * 0.006
        print(f"ğŸ’° ì˜ˆìƒ ë¹„ìš©: ${cost:.4f} (ì•½ {duration_seconds:.1f}ì´ˆ)")
        
        return True, result.text
        
    except Exception as e:
        print(f"âŒ ìµœì í™”ëœ API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
        return False, ""

async def compare_before_after(audio_file_path: str):
    """ê°œì„  ì „í›„ ë¹„êµ í…ŒìŠ¤íŠ¸"""
    
    api_key = os.getenv("OPENAI_API_KEY")
    client = OpenAI(api_key=api_key)
    
    print("ğŸ”„ ê°œì„  ì „í›„ ë¹„êµ í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    try:
        # 1. ê°œì„  ì „ ë°©ì‹ (ê¸°ë³¸ ì„¤ì •)
        print("1ï¸âƒ£ ê°œì„  ì „ ë°©ì‹ (ê¸°ë³¸ ì„¤ì •)")
        with open(audio_file_path, "rb") as audio_file:
            basic_result = await asyncio.to_thread(
                lambda: client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_file,
                    language="ko",
                    response_format="verbose_json",
                    timestamp_granularities=["segment"]
                )
            )
        
        print(f"ğŸ“ ê¸°ë³¸ ê²°ê³¼: {basic_result.text}")
        print()
        
        # 2. ê°œì„  í›„ ë°©ì‹ (ìµœì í™” ì„¤ì •)
        print("2ï¸âƒ£ ê°œì„  í›„ ë°©ì‹ (í•œêµ­ì–´ ìµœì í™”)")
        success, improved_text = await test_optimized_korean_api(audio_file_path)
        
        if success:
            print()
            
            # 3. ê²°ê³¼ ë¹„êµ
            print("ğŸ” ê²°ê³¼ ë¹„êµ:")
            print(f"ê°œì„  ì „: '{basic_result.text}'")
            print(f"ê°œì„  í›„: '{improved_text}'")
            
            # í’ˆì§ˆ í‰ê°€
            if len(basic_result.text) > len(improved_text) * 3:
                print("ğŸ¯ ê°œì„  í›„ ê²°ê³¼ê°€ ë” ê°„ê²°í•˜ê³  ì •í™•í•©ë‹ˆë‹¤!")
            elif basic_result.text.strip() == improved_text.strip():
                print("âš¡ ê²°ê³¼ê°€ ë™ì¼í•©ë‹ˆë‹¤.")
            else:
                print("ğŸ”„ ê²°ê³¼ê°€ ë‹¤ë¦…ë‹ˆë‹¤. ìˆ˜ë™ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        return True
        
    except Exception as e:
        print(f"âŒ ë¹„êµ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
        return False

if __name__ == "__main__":
    if len(sys.argv) != 2:
        print("ì‚¬ìš©ë²•: python test_korean_optimization.py <audio_file_path>")
        print("ì˜ˆì‹œ: python test_korean_optimization.py ../test-file/test.mp3")
        sys.exit(1)
    
    audio_path = sys.argv[1]
    print("ğŸ§ª OpenAI Whisper API í•œêµ­ì–´ ìµœì í™” ê²€ì¦ í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    # ìµœì í™”ëœ API í…ŒìŠ¤íŠ¸
    success1 = asyncio.run(test_optimized_korean_api(audio_path))
    
    print("\n" + "="*60)
    
    # ê°œì„  ì „í›„ ë¹„êµ
    success2 = asyncio.run(compare_before_after(audio_path))
    
    print("="*60)
    if success1[0] and success2:
        print("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì„±ê³µ! í•œêµ­ì–´ ìµœì í™”ê°€ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("ğŸ’¥ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨! ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
