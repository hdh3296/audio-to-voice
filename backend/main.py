from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse
from fastapi.staticfiles import StaticFiles
import os
import shutil
import subprocess
import tempfile
from pathlib import Path
import uuid
from typing import Optional
import asyncio
from datetime import datetime
# pydub ë¬¸ì œë¡œ auto_subtitle ì„í¬íŠ¸ ì œê±°

app = FastAPI(title="Audio to Voice API", version="1.0.0")

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://localhost:3001"],  # í”„ë¡ íŠ¸ì—”ë“œ í¬íŠ¸ 2ê°œ ì§€ì›
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ë””ë ‰í† ë¦¬ ì„¤ì •
BASE_DIR = Path(__file__).parent.parent
UPLOADS_DIR = BASE_DIR / "uploads"
OUTPUTS_DIR = BASE_DIR / "outputs"

# ë””ë ‰í† ë¦¬ ìƒì„±
UPLOADS_DIR.mkdir(exist_ok=True)
OUTPUTS_DIR.mkdir(exist_ok=True)

# ì •ì  íŒŒì¼ ì„œë¹™
app.mount("/outputs", StaticFiles(directory=str(OUTPUTS_DIR)), name="outputs")

# ì§€ì›í•˜ëŠ” ì˜¤ë””ì˜¤ í˜•ì‹
SUPPORTED_AUDIO_FORMATS = {".mp3", ".wav", ".m4a", ".aac", ".flac", ".ogg"}

@app.get("/")
async def root():
    return {"message": "Audio to Voice API", "status": "running"}

@app.get("/api-status")
async def api_status():
    """OpenAI API ë° GPT í›„ì²˜ë¦¬ ìƒíƒœ í™•ì¸"""
    try:
        from dotenv import load_dotenv
        load_dotenv()
        
        api_key = os.getenv("OPENAI_API_KEY")
        api_available = api_key is not None and api_key != "your_openai_api_key_here"
        
        # GPT í›„ì²˜ë¦¬ ìƒíƒœ í™•ì¸
        gpt_available = False
        try:
            # ê°„ë‹¨í•œ GPT í›„ì²˜ë¦¬ ëª¨ë“ˆ ì‚¬ìš©
            from simple_gpt_postprocessor import simple_gpt_postprocessor
            gpt_available = simple_gpt_postprocessor.is_available()
        except ImportError as e:
            print(f"âš ï¸ GPT í›„ì²˜ë¦¬ ëª¨ë“ˆ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
            gpt_available = False 
        except Exception as e:
            print(f"âš ï¸ GPT í›„ì²˜ë¦¬ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
            gpt_available = False
        
        return {
            "openai_api_available": api_available,
            "gpt_postprocessing_available": gpt_available,
            "max_audio_length_minutes": 10 if api_available else None,
            "api_configured": api_available,
            "features": {
                "whisper_api": api_available,
                "gpt_correction": gpt_available,
                "local_whisper": True  # í•­ìƒ ì‚¬ìš© ê°€ëŠ¥
            }
        }
    except Exception as e:
        print(f"âŒ API ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
        return {
            "openai_api_available": False,
            "gpt_postprocessing_available": False,
            "max_audio_length_minutes": None,
            "api_configured": False,
            "features": {
                "whisper_api": False,
                "gpt_correction": False,
                "local_whisper": True
            },
            "error": str(e)
        }

@app.get("/health")
async def health_check():
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}

@app.post("/upload-audio")
async def upload_audio(file: UploadFile = File(...)):
    """ì˜¤ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ"""
    try:
        # íŒŒì¼ í™•ì¥ì ê²€ì¦
        file_extension = Path(file.filename).suffix.lower()
        if file_extension not in SUPPORTED_AUDIO_FORMATS:
            raise HTTPException(
                status_code=400, 
                detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. ì§€ì› í˜•ì‹: {', '.join(SUPPORTED_AUDIO_FORMATS)}"
            )
        
        # ê³ ìœ  íŒŒì¼ëª… ìƒì„±
        file_id = str(uuid.uuid4())
        filename = f"{file_id}{file_extension}"
        file_path = UPLOADS_DIR / filename
        
        # íŒŒì¼ ì €ì¥
        with open(file_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)
        
        return {
            "file_id": file_id,
            "filename": filename,
            "original_name": file.filename,
            "size": file_path.stat().st_size,
            "message": "íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤."
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.post("/generate-subtitles/{file_id}")
async def generate_subtitles(
    file_id: str,
    model: str = "large-v3",  # í•œêµ­ì–´ ì •í™•ë„ í–¥ìƒì„ ìœ„í•´ large-v3 ê¸°ë³¸ê°’
    language: Optional[str] = "ko",  # í•œêµ­ì–´ ê¸°ë³¸ ì„¤ì •
    task: str = "transcribe",
    background_color: str = "black",
    use_api: bool = False,  # ğŸ†• API ëª¨ë“œ ì„ íƒ íŒŒë¼ë¯¸í„°
    use_gpt_correction: bool = False  # ğŸ†• GPT í›„ì²˜ë¦¬ ì˜µì…˜
):
    """í•œêµ­ì–´ ìë§‰ ìƒì„± ë° ë¹„ë””ì˜¤ ìƒì„± (í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ + GPT í›„ì²˜ë¦¬ ì§€ì›)"""
    try:
        # ì—…ë¡œë“œëœ íŒŒì¼ ì°¾ê¸°
        uploaded_files = list(UPLOADS_DIR.glob(f"{file_id}.*"))
        if not uploaded_files:
            raise HTTPException(status_code=404, detail="ì—…ë¡œë“œëœ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        input_file = uploaded_files[0]
        output_file = OUTPUTS_DIR / f"{file_id}_subtitled.mp4"
        
        gpt_status = " + GPTêµì •" if use_gpt_correction else ""
        mode_text = f"OpenAI API{gpt_status}" if use_api else f"ë¡œì»¬ Faster-Whisper{gpt_status}"
        print(f"ğŸ¯ {mode_text} ëª¨ë“œë¡œ ìŒì„± ì²˜ë¦¬ ì‹œì‘ - ëª¨ë¸: {model}")
        
        segments_list = []
        full_text = ""
        processing_method = ""
        language_detected = language
        language_probability = 1.0
        gpt_correction_applied = False
        total_corrections = 0
        
        if use_api:
            # OpenAI API ëª¨ë“œ - ìë™ ëŒ€ì²´ ì—†ì´ APIë§Œ ì‚¬ìš©
            print("ğŸŒ OpenAI Whisper API ì‚¬ìš©")
            try:
                from dotenv import load_dotenv
                import openai
                load_dotenv()
                
                # API í‚¤ í™•ì¸
                api_key = os.getenv("OPENAI_API_KEY")
                if not api_key or api_key == "your_openai_api_key_here":
                    raise HTTPException(
                        status_code=400, 
                        detail="OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
                    )
                
                # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
                client = openai.OpenAI(api_key=api_key)
                
                # íŒŒì¼ í¬ê¸° í™•ì¸ (25MB ì œí•œ)
                file_size = input_file.stat().st_size
                if file_size > 25 * 1024 * 1024:  # 25MB
                    raise HTTPException(
                        status_code=400,
                        detail=f"OpenAI APIëŠ” 25MB ì´í•˜ì˜ íŒŒì¼ë§Œ ì§€ì›í•©ë‹ˆë‹¤. í˜„ì¬ íŒŒì¼ í¬ê¸°: {file_size / (1024*1024):.1f}MB"
                    )
                
                # í•œêµ­ì–´ ìµœì í™” í”„ë¡¬í”„íŠ¸ ì„¤ì •
                korean_prompt = (
                    "ë‹¤ìŒì€ í•œêµ­ì–´ ìŒì„±ì…ë‹ˆë‹¤. "
                    "ì •í™•í•œ ë§ì¶¤ë²•ê³¼ ìì—°ìŠ¤ëŸ¬ìš´ ë„ì–´ì“°ê¸°ë¥¼ ì‚¬ìš©í•´ ì£¼ì„¸ìš”. "
                    "ë¬¸ì¥ ë¶€í˜¸ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ê³ , êµ¬ì–´ì²´ í‘œí˜„ì„ ìì—°ìŠ¤ëŸ½ê²Œ ë³€í™˜í•´ ì£¼ì„¸ìš”."
                ) if language == "ko" else ""
                
                # API í˜¸ì¶œ - í•œêµ­ì–´ ì •í™•ë„ í–¥ìƒì„ ìœ„í•œ ìµœì í™” ì„¤ì •
                with open(input_file, "rb") as audio_file:
                    print(f"ğŸ“¤ OpenAI APIë¡œ íŒŒì¼ ì „ì†¡ ì¤‘... ({file_size / (1024*1024):.1f}MB)")
                    
                    transcript = client.audio.transcriptions.create(
                        model="whisper-1",
                        file=audio_file,
                        language=language if language else None,
                        response_format="verbose_json",
                        timestamp_granularities=["segment"],
                        prompt=korean_prompt,  # ğŸ†• í•œêµ­ì–´ ìµœì í™” í”„ë¡¬í”„íŠ¸
                        temperature=0.0  # ğŸ†• ì¼ê´€ì„±ì„ ìœ„í•œ ë‚®ì€ ì˜¨ë„ ì„¤ì •
                    )
                    
                print(f"âœ… OpenAI API ì‘ë‹µ ë°›ìŒ - ì–¸ì–´: {transcript.language}")
                
                # ê²°ê³¼ ì²˜ë¦¬
                full_text = transcript.text
                language_detected = transcript.language
                processing_method = "openai_api"
                
                # ì„¸ê·¸ë¨¼íŠ¸ ì²˜ë¦¬
                if hasattr(transcript, 'segments') and transcript.segments:
                    for segment in transcript.segments:
                        if hasattr(segment, 'text') and segment.text.strip():
                            segment_dict = {
                                "start": segment.start,
                                "end": segment.end,
                                "text": segment.text.strip()
                            }
                            segments_list.append(segment_dict)
                else:
                    # ì„¸ê·¸ë¨¼íŠ¸ê°€ ì—†ëŠ” ê²½ìš° ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ì²˜ë¦¬
                    segments_list.append({
                        "start": 0.0,
                        "end": 30.0,  # ê¸°ë³¸ê°’
                        "text": full_text
                    })
                
            except openai.AuthenticationError:
                raise HTTPException(status_code=401, detail="OpenAI API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            except openai.RateLimitError:
                raise HTTPException(status_code=429, detail="OpenAI API ì‚¬ìš©ëŸ‰ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.")
            except openai.APIError as e:
                raise HTTPException(status_code=500, detail=f"OpenAI API ì˜¤ë¥˜: {str(e)}")
            except Exception as e:
                # API ëª¨ë“œì—ì„œëŠ” ìë™ ëŒ€ì²´í•˜ì§€ ì•Šê³  ì˜¤ë¥˜ ë°œìƒ
                raise HTTPException(status_code=500, detail=f"OpenAI API ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                
        else:
            # ë¡œì»¬ Faster-Whisper ëª¨ë“œ
            print("ğŸ  ë¡œì»¬ Faster-Whisper ì‚¬ìš©")
            from faster_whisper import WhisperModel
            
            # ë¡œì»¬ Whisper ëª¨ë¸ ë¡œë“œ
            whisper_model = WhisperModel(model, device="cpu", compute_type="int8")
            
            # í•œêµ­ì–´ ìµœì í™” ì „ì‚¬
            segments, info = whisper_model.transcribe(
                str(input_file), 
                language=language,
                task=task
            )
            
            # ê²°ê³¼ ìˆ˜ì§‘
            for segment in segments:
                text = segment.text.strip()
                if text:
                    segment_dict = {
                        "start": segment.start,
                        "end": segment.end,
                        "text": text
                    }
                    segments_list.append(segment_dict)
                    full_text += text + " "
            
            language_detected = info.language
            language_probability = info.language_probability
            processing_method = "local_whisper"
        
        # GPT í›„ì²˜ë¦¬ ì ìš© (ëª¨ë“  ëª¨ë“œì—ì„œ ì‚¬ìš© ê°€ëŠ¥)
        if use_gpt_correction:
            try:
                print("ğŸ¤– GPT í›„ì²˜ë¦¬ë¡œ ì˜¤íƒ€ êµì • ì¤‘...")
                
                # ê°„ë‹¨í•œ GPT í›„ì²˜ë¦¬ ëª¨ë“ˆ ì‚¬ìš©
                from simple_gpt_postprocessor import simple_gpt_postprocessor
                
                if simple_gpt_postprocessor.is_available():
                    # íƒ€ì„ìŠ¤íƒ¬í”„ ë³´ì¡´ ê°•í™” ë²„ì „ ì‚¬ìš©
                    correction_result = await simple_gpt_postprocessor.correct_segments_preserve_timing(
                        segments_list,
                        context="í•œêµ­ì–´ ìŒì„± ì¸ì‹ ê²°ê³¼ì˜ ì˜¤íƒ€ ë° ë§ì¶¤ë²• êµì •"
                    )
                    
                    if correction_result.get("success"):
                        # êµì •ëœ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ì—…ë°ì´íŠ¸
                        corrected_segments = correction_result.get("corrected_segments", [])
                        corrected_text = " ".join([seg.get("text", "") for seg in corrected_segments])
                        
                        segments_list = corrected_segments
                        full_text = corrected_text
                        gpt_correction_applied = correction_result.get("correction_applied", False)
                        total_corrections = correction_result.get("total_corrections", 0)
                        processing_method += " + GPTêµì •"
                        
                        print(f"âœ… GPT êµì • ì™„ë£Œ: {total_corrections}ê°œ ìˆ˜ì •")
                    else:
                        print(f"âš ï¸ GPT êµì • ì‹¤íŒ¨: {correction_result.get('error', 'Unknown error')}")
                else:
                    print("âš ï¸ GPT í›„ì²˜ë¦¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (API í‚¤ í™•ì¸ í•„ìš”)")
                    
            except Exception as e:
                print(f"âš ï¸ GPT êµì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ì›ë³¸ ìœ ì§€): {str(e)}")
                # GPT êµì • ì‹¤íŒ¨í•´ë„ ì›ë³¸ ê²°ê³¼ëŠ” ìœ ì§€
        
        # SRT ìƒì„± (ë””ë²„ê¹… ì •ë³´ ì¶”ê°€)
        srt_content = ""
        print(f"ğŸ“„ SRT ìƒì„±: {len(segments_list)}ê°œ ì„¸ê·¸ë¨¼íŠ¸")
        
        for i, segment in enumerate(segments_list, 1):
            start_time = seconds_to_srt_time(segment["start"])
            end_time = seconds_to_srt_time(segment["end"])
            text = segment["text"].strip()
            
            print(f"  {i}: {start_time} â†’ {end_time} | {text[:50]}...")
            
            srt_content += f"{i}\n"
            srt_content += f"{start_time} --> {end_time}\n"
            srt_content += f"{text}\n\n"
        
        # ë¹„ë””ì˜¤ ìƒì„±
        create_video_with_srt(str(input_file), srt_content, str(output_file), background_color)
        
        return {
            "file_id": file_id,
            "output_file": f"{file_id}_subtitled.mp4",
            "download_url": f"/download/{file_id}_subtitled.mp4",
            "transcript": full_text.strip(),
            "segments_count": len(segments_list),
            "language": language_detected,
            "language_probability": language_probability,
            "model_used": model if not use_api else "whisper-1",
            "processing_method": processing_method,
            "use_api_mode": use_api,
            "gpt_correction_applied": gpt_correction_applied,
            "total_corrections": total_corrections,
            "message": f"{mode_text} ëª¨ë“œë¡œ í•œêµ­ì–´ ìë§‰ ë¹„ë””ì˜¤ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤."
        }
    
    except HTTPException:
        # HTTPExceptionì€ ê·¸ëŒ€ë¡œ ì¬ë°œìƒ
        raise
    except Exception as e:
        print(f"âŒ í•œêµ­ì–´ ìë§‰ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"í•œêµ­ì–´ ìë§‰ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")

def seconds_to_srt_time(seconds: float) -> str:
    """ì´ˆë¥¼ SRT ì‹œê°„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millisecs = int((seconds % 1) * 1000)
    
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"

def get_audio_duration(audio_path: str) -> float:
    """FFprobeë¥¼ ì‚¬ìš©í•˜ì—¬ ì •í™•í•œ ì˜¤ë””ì˜¤ ê¸¸ì´ êµ¬í•˜ê¸°"""
    try:
        cmd = [
            'ffprobe',
            '-v', 'quiet',
            '-show_entries', 'format=duration',
            '-of', 'csv=p=0',
            audio_path
        ]
        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode == 0:
            duration = float(result.stdout.strip())
            print(f"ğŸ“Š ì˜¤ë””ì˜¤ ê¸¸ì´: {duration:.2f}ì´ˆ")
            return duration
        else:
            print(f"âš ï¸ FFprobe ì˜¤ë¥˜: {result.stderr}")
            return 60.0  # ê¸°ë³¸ê°’
    except Exception as e:
        print(f"âš ï¸ ì˜¤ë””ì˜¤ ê¸¸ì´ ê³„ì‚° ì‹¤íŒ¨: {e}")
        return 60.0  # ê¸°ë³¸ê°’

def create_video_with_srt(audio_path: str, srt_content: str, output_path: str, background_color: str = "black"):
    """ì˜¤ë””ì˜¤ì™€ ìë§‰ìœ¼ë¡œ ë¹„ë””ì˜¤ ìƒì„± (ì •í™•í•œ ì‹±í¬)"""
    import subprocess
    import tempfile
    
    # ì‹¤ì œ ì˜¤ë””ì˜¤ ê¸¸ì´ êµ¬í•˜ê¸°
    duration = get_audio_duration(audio_path)
    print(f"ğŸ¬ ë¹„ë””ì˜¤ ìƒì„±: {duration:.2f}ì´ˆ ê¸¸ì´ë¡œ ì„¤ì •")
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.srt', delete=False, encoding='utf-8') as srt_file:
        srt_file.write(srt_content)
        srt_path = srt_file.name
    
    try:
        # í•œêµ­ì–´ í°íŠ¸ ì„¤ì • (ë” ëª…í™•í•œ ìë§‰ì„ ìœ„í•´ ê°œì„ )
        font_style = (
            'FontSize=24,'
            'PrimaryColour=&Hffffff,'  # í°ìƒ‰ í…ìŠ¤íŠ¸
            'OutlineColour=&H000000,'  # ê²€ì€ìƒ‰ ì™¸ê³½ì„ 
            'BackColour=&H80000000,'   # ë°˜íˆ¬ëª… ë°°ê²½
            'Outline=2,'               # ì™¸ê³½ì„  ë‘ê»˜
            'Shadow=2,'                # ê·¸ë¦¼ì
            'Alignment=2,'             # í•˜ë‹¨ ì¤‘ì•™
            'MarginV=30,'              # í•˜ë‹¨ ì—¬ë°±
            'Bold=1'                   # êµµê²Œ
        )
        
        # FFmpeg ëª…ë ¹ì–´ (ë” ì •í™•í•œ ì‹±í¬ë¥¼ ìœ„í•´ ê°œì„ )
        cmd = [
            'ffmpeg',
            '-f', 'lavfi',
            '-i', f'color=c={background_color}:s=1280x720:d={duration}',  # ì •í™•í•œ ê¸¸ì´ ì‚¬ìš©
            '-i', audio_path,
            '-vf', f'subtitles={srt_path}:force_style=\'{font_style}\'',
            '-c:v', 'libx264',
            '-preset', 'medium',
            '-crf', '23',
            '-c:a', 'aac',
            '-b:a', '128k',
            '-map', '0:v',      # ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ëª…ì‹œì  ë§¤í•‘
            '-map', '1:a',      # ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ëª…ì‹œì  ë§¤í•‘
            '-shortest',        # ê°€ì¥ ì§§ì€ ìŠ¤íŠ¸ë¦¼ì— ë§ì¶¤
            '-avoid_negative_ts', 'make_zero',  # íƒ€ì„ìŠ¤íƒ¬í”„ ë³´ì •
            '-y',
            output_path
        ]
        
        print(f"ğŸ”§ FFmpeg ì‹¤í–‰ ì¤‘...")
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode != 0:
            print(f"âŒ FFmpeg ìƒì„¸ ì˜¤ë¥˜:\n{result.stderr}")
            raise Exception(f"FFmpeg ì˜¤ë¥˜: {result.stderr}")
        
        print(f"âœ… ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ: {output_path}")
        
    except Exception as e:
        print(f"âŒ ë¹„ë””ì˜¤ ìƒì„± ì‹¤íŒ¨: {e}")
        raise e
    finally:
        # ì„ì‹œ SRT íŒŒì¼ ì‚­ì œ
        if os.path.exists(srt_path):
            os.unlink(srt_path)

@app.get("/download/{filename}")
async def download_file(filename: str):
    """ìƒì„±ëœ íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
    file_path = OUTPUTS_DIR / filename
    
    if not file_path.exists():
        raise HTTPException(status_code=404, detail="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    return FileResponse(
        path=str(file_path),
        filename=filename,
        media_type="application/octet-stream"
    )

@app.get("/status/{file_id}")
async def get_status(file_id: str):
    """ì²˜ë¦¬ ìƒíƒœ í™•ì¸"""
    input_files = list(UPLOADS_DIR.glob(f"{file_id}.*"))
    output_file = OUTPUTS_DIR / f"{file_id}_subtitled.mp4"
    
    status = "unknown"
    if not input_files:
        status = "not_found"
    elif output_file.exists():
        status = "completed"
    else:
        status = "processing"
    
    return {
        "file_id": file_id,
        "status": status,
        "has_input": bool(input_files),
        "has_output": output_file.exists()
    }

@app.delete("/cleanup/{file_id}")
async def cleanup_files(file_id: str):
    """ì„ì‹œ íŒŒì¼ ì •ë¦¬"""
    try:
        # ì…ë ¥ íŒŒì¼ ì‚­ì œ
        for file_path in UPLOADS_DIR.glob(f"{file_id}.*"):
            file_path.unlink()
        
        # ì¶œë ¥ íŒŒì¼ ì‚­ì œ
        for file_path in OUTPUTS_DIR.glob(f"{file_id}*"):
            file_path.unlink()
        
        return {"message": "íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤."}
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
