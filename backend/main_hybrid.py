from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse
from fastapi.staticfiles import StaticFiles
import os
import shutil
import subprocess
import tempfile
from pathlib import Path
import uuid
from typing import Optional
import asyncio
from datetime import datetime

# pydub ëŒ€ì‹  ì•ˆì •í™”ëœ OpenAI í´ë¼ì´ì–¸íŠ¸ë§Œ ì‚¬ìš©
from auto_subtitle.openai_stable_client import stable_openai_whisper_client
from faster_whisper import WhisperModel

app = FastAPI(title="Audio to Voice API (Hybrid)", version="2.0.0")

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://localhost:3001"],  # ë‘ í¬íŠ¸ ëª¨ë‘ ì§€ì›
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ë””ë ‰í† ë¦¬ ì„¤ì •
BASE_DIR = Path(__file__).parent.parent
UPLOADS_DIR = BASE_DIR / "uploads"
OUTPUTS_DIR = BASE_DIR / "outputs"

# ë””ë ‰í† ë¦¬ ìƒì„±
UPLOADS_DIR.mkdir(exist_ok=True)
OUTPUTS_DIR.mkdir(exist_ok=True)

# ì •ì  íŒŒì¼ ì„œë¹™
app.mount("/outputs", StaticFiles(directory=str(OUTPUTS_DIR)), name="outputs")

# ì§€ì›í•˜ëŠ” ì˜¤ë””ì˜¤ í˜•ì‹
SUPPORTED_AUDIO_FORMATS = {".mp3", ".wav", ".m4a", ".aac", ".flac", ".ogg"}

# ë¡œì»¬ Whisper ëª¨ë¸ (ì „ì—­)
local_model = None

def load_local_model(model_name: str = "large-v3"):
    """ë¡œì»¬ Whisper ëª¨ë¸ ë¡œë“œ (í•„ìš”ì‹œ)"""
    global local_model
    
    if local_model is None:
        print(f"ğŸ“¥ ë¡œì»¬ Whisper ëª¨ë¸ ë¡œë“œ ì¤‘: {model_name}")
        try:
            local_model = WhisperModel(
                model_name, 
                device="cpu", 
                compute_type="int8"
            )
            print(f"âœ… ë¡œì»¬ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_name}")
        except Exception as e:
            print(f"âŒ ë¡œì»¬ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            # mediumìœ¼ë¡œ ëŒ€ì²´
            if model_name == "large-v3":
                local_model = WhisperModel("medium", device="cpu", compute_type="int8")
                print("âœ… medium ëª¨ë¸ë¡œ ëŒ€ì²´ ì™„ë£Œ")
            else:
                raise e
    
    return local_model

async def transcribe_local(audio_path: str, language: str = "ko"):
    """ë¡œì»¬ Whisper ì „ì‚¬"""
    try:
        model = load_local_model()
        
        korean_prompt = "ì•ˆë…•í•˜ì„¸ìš”. ë‹¤ìŒì€ í•œêµ­ì–´ ìŒì„±ì…ë‹ˆë‹¤. ì •í™•í•œ ë¬¸ì¥ ë¶€í˜¸ì™€ ìì—°ìŠ¤ëŸ¬ìš´ ë„ì–´ì“°ê¸°ë¥¼ í¬í•¨í•´ ì£¼ì„¸ìš”."
        
        def _transcribe():
            segments, info = model.transcribe(
                audio_path, 
                language=language,
                task="transcribe",
                initial_prompt=korean_prompt,
                beam_size=5,
                temperature=0.0
            )
            
            segments_list = []
            full_text = ""
            
            for segment in segments:
                text = segment.text.strip()
                if text:
                    segments_list.append({
                        "start": segment.start,
                        "end": segment.end,
                        "text": text
                    })
                    full_text += text + " "
            
            return {
                "success": True,
                "text": full_text.strip(),
                "segments": segments_list,
                "language": info.language,
                "processing_method": "local_whisper"
            }
        
        return await asyncio.to_thread(_transcribe)
        
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "processing_method": "local_whisper"
        }

def generate_srt(segments):
    """SRT ìë§‰ ìƒì„±"""
    srt_content = ""
    
    for i, segment in enumerate(segments, 1):
        start_time = seconds_to_srt_time(segment["start"])
        end_time = seconds_to_srt_time(segment["end"])
        text = segment["text"].strip()
        
        srt_content += f"{i}\n"
        srt_content += f"{start_time} --> {end_time}\n"
        srt_content += f"{text}\n\n"
    
    return srt_content

def seconds_to_srt_time(seconds: float) -> str:
    """ì´ˆë¥¼ SRT ì‹œê°„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millisecs = int((seconds % 1) * 1000)
    
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"

def get_audio_duration(audio_path: str) -> float:
    """ì˜¤ë””ì˜¤ ê¸¸ì´ êµ¬í•˜ê¸°"""
    try:
        import ffmpeg
        probe = ffmpeg.probe(audio_path)
        duration = float(probe['streams'][0]['duration'])
        return duration
    except:
        return 60.0  # ê¸°ë³¸ê°’

def create_video_with_subtitles(audio_path: str, srt_content: str, output_path: str, background_color: str = "black"):
    """ë¹„ë””ì˜¤ ìƒì„±"""
    try:
        duration = get_audio_duration(audio_path)
        
        with tempfile.NamedTemporaryFile(mode='w', suffix='.srt', delete=False, encoding='utf-8') as srt_file:
            srt_file.write(srt_content)
            srt_path = srt_file.name
        
        font_style = (
            'FontSize=28,'
            'PrimaryColour=&Hffffff,'
            'OutlineColour=&H000000,'
            'Outline=3,'
            'Shadow=1,'
            'Alignment=2,'
            'MarginV=50'
        )
        
        cmd = [
            'ffmpeg',
            '-f', 'lavfi',
            '-i', f'color=c={background_color}:s=1280x720:d={duration}',
            '-i', audio_path,
            '-vf', f'subtitles={srt_path}:force_style=\'{font_style}\'',
            '-c:v', 'libx264',
            '-preset', 'medium',
            '-crf', '23',
            '-c:a', 'aac',
            '-b:a', '128k',
            '-shortest',
            '-y',
            output_path
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode != 0:
            raise Exception(f"FFmpeg ì˜¤ë¥˜: {result.stderr}")
        
        os.unlink(srt_path)
        
    except Exception as e:
        if 'srt_path' in locals() and os.path.exists(srt_path):
            os.unlink(srt_path)
        raise Exception(f"ë¹„ë””ì˜¤ ìƒì„± ì‹¤íŒ¨: {str(e)}")

@app.get("/")
async def root():
    return {"message": "Audio to Voice API (Hybrid)", "status": "running", "version": "2.0.0"}

@app.get("/health")
async def health_check():
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}

@app.get("/api-status")
async def api_status():
    """OpenAI API ìƒíƒœ í™•ì¸"""
    return {
        "openai_api_available": stable_openai_whisper_client.is_available(),
        "max_audio_length_minutes": stable_openai_whisper_client.max_audio_length if stable_openai_whisper_client.is_available() else None,
        "api_configured": stable_openai_whisper_client.api_key is not None and stable_openai_whisper_client.api_key != "your_openai_api_key_here"
    }

@app.post("/upload-audio")
async def upload_audio(file: UploadFile = File(...)):
    """ì˜¤ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ"""
    try:
        file_extension = Path(file.filename).suffix.lower()
        if file_extension not in SUPPORTED_AUDIO_FORMATS:
            raise HTTPException(
                status_code=400, 
                detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. ì§€ì› í˜•ì‹: {', '.join(SUPPORTED_AUDIO_FORMATS)}"
            )
        
        file_id = str(uuid.uuid4())
        filename = f"{file_id}{file_extension}"
        file_path = UPLOADS_DIR / filename
        
        with open(file_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)
        
        return {
            "file_id": file_id,
            "filename": filename,
            "original_name": file.filename,
            "size": file_path.stat().st_size,
            "message": "íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤."
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.post("/generate-subtitles/{file_id}")
async def generate_subtitles(
    file_id: str,
    model: str = "large-v3",
    language: Optional[str] = "ko",
    task: str = "transcribe",
    background_color: str = "black",
    use_api: bool = False  # ğŸ†• í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ
):
    """í•˜ì´ë¸Œë¦¬ë“œ ìë§‰ ìƒì„± (ì•ˆì •í™”ëœ API + ë¡œì»¬)"""
    try:
        uploaded_files = list(UPLOADS_DIR.glob(f"{file_id}.*"))
        if not uploaded_files:
            raise HTTPException(status_code=404, detail="ì—…ë¡œë“œëœ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        input_file = uploaded_files[0]
        output_file = OUTPUTS_DIR / f"{file_id}_subtitled.mp4"
        
        mode_text = "ì•ˆì •í™” API" if use_api else "ë¡œì»¬"
        print(f"ğŸ¯ {mode_text} ëª¨ë“œë¡œ ìŒì„± ì²˜ë¦¬ ì‹œì‘")
        
        # í•˜ì´ë¸Œë¦¬ë“œ ì²˜ë¦¬
        if use_api and stable_openai_whisper_client.is_available():
            print("ğŸŒ ì•ˆì •í™” API ëª¨ë“œ ì‹œë„...")
            result = await stable_openai_whisper_client.transcribe_audio_stable(
                str(input_file), language
            )
            
            if not result.get("success"):
                print(f"âš ï¸ API ëª¨ë“œ ì‹¤íŒ¨, ë¡œì»¬ ëª¨ë“œë¡œ ëŒ€ì²´: {result.get('error')}")
                result = await transcribe_local(str(input_file), language)
        else:
            print("ğŸ  ë¡œì»¬ ëª¨ë“œë¡œ ì²˜ë¦¬...")
            result = await transcribe_local(str(input_file), language)
        
        if not result.get("success"):
            raise HTTPException(status_code=500, detail=result.get("error"))
        
        # SRT ìƒì„± ë° ë¹„ë””ì˜¤ ìƒì„±
        srt_content = generate_srt(result["segments"])
        create_video_with_subtitles(str(input_file), srt_content, str(output_file), background_color)
        
        return {
            "file_id": file_id,
            "output_file": f"{file_id}_subtitled.mp4",
            "download_url": f"/download/{file_id}_subtitled.mp4",
            "transcript": result["text"],
            "segments_count": len(result["segments"]),
            "language": result.get("language", language),
            "processing_method": result.get("processing_method", "unknown"),
            "use_api_mode": use_api,
            "message": f"{mode_text} ëª¨ë“œë¡œ í•œêµ­ì–´ ìë§‰ ë¹„ë””ì˜¤ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤."
        }
    
    except Exception as e:
        print(f"âŒ ìë§‰ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ìë§‰ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")

@app.get("/download/{filename}")
async def download_file(filename: str):
    """ìƒì„±ëœ íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
    file_path = OUTPUTS_DIR / filename
    
    if not file_path.exists():
        raise HTTPException(status_code=404, detail="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    return FileResponse(
        path=str(file_path),
        filename=filename,
        media_type="application/octet-stream"
    )

@app.get("/status/{file_id}")
async def get_status(file_id: str):
    """ì²˜ë¦¬ ìƒíƒœ í™•ì¸"""
    input_files = list(UPLOADS_DIR.glob(f"{file_id}.*"))
    output_file = OUTPUTS_DIR / f"{file_id}_subtitled.mp4"
    
    status = "unknown"
    if not input_files:
        status = "not_found"
    elif output_file.exists():
        status = "completed"
    else:
        status = "processing"
    
    return {
        "file_id": file_id,
        "status": status,
        "has_input": bool(input_files),
        "has_output": output_file.exists()
    }

@app.delete("/cleanup/{file_id}")
async def cleanup_files(file_id: str):
    """ì„ì‹œ íŒŒì¼ ì •ë¦¬"""
    try:
        for file_path in UPLOADS_DIR.glob(f"{file_id}.*"):
            file_path.unlink()
        
        for file_path in OUTPUTS_DIR.glob(f"{file_id}*"):
            file_path.unlink()
        
        return {"message": "íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤."}
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")

if __name__ == "__main__":
    import uvicorn
    print("ğŸš€ í•˜ì´ë¸Œë¦¬ë“œ Audio-to-Voice API ì„œë²„ ì‹œì‘!")
    print("ğŸ  ë¡œì»¬ ëª¨ë“œ: Faster-Whisper")
    print("ğŸŒ API ëª¨ë“œ: ì•ˆì •í™”ëœ OpenAI Whisper API")
    uvicorn.run(app, host="0.0.0.0", port=8000)
