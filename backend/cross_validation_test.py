#!/usr/bin/env python3
"""
ìµœì¢… êµì°¨ ê²€ì¦ í…ŒìŠ¤íŠ¸
OpenAI APIì™€ ë¡œì»¬ Whisperì˜ ë‹¤ì–‘í•œ ì„¤ì •ìœ¼ë¡œ êµì°¨ ê²€ì¦
"""
import os
import asyncio
from dotenv import load_dotenv
from openai import OpenAI
import sys
from collections import Counter

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

async def cross_validation_test(audio_file_path: str):
    """OpenAI APIì™€ ë¡œì»¬ Whisper êµì°¨ ê²€ì¦"""
    
    print("ğŸ¯ êµì°¨ ê²€ì¦ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("="*60)
    
    results = []
    
    # 1. OpenAI API í…ŒìŠ¤íŠ¸ (ì—¬ëŸ¬ ì„¤ì •)
    print("ğŸŒ OpenAI API í…ŒìŠ¤íŠ¸")
    print("-" * 30)
    
    api_key = os.getenv("OPENAI_API_KEY")
    if api_key and api_key != "your_openai_api_key_here":
        client = OpenAI(api_key=api_key)
        
        api_configs = [
            {"name": "API-ê¸°ë³¸", "params": {"language": "ko", "temperature": 0.0}},
            {"name": "API-ì–¸ì–´ìë™", "params": {"temperature": 0.0}},
            {"name": "API-ì˜¨ë„ë†’ì„", "params": {"language": "ko", "temperature": 0.3}},
        ]
        
        for config in api_configs:
            try:
                def call_api():
                    with open(audio_file_path, "rb") as audio_file:
                        return client.audio.transcriptions.create(
                            model="whisper-1",
                            file=audio_file,
                            response_format="verbose_json",
                            timestamp_granularities=["segment"],
                            **config["params"]
                        )
                
                result = await asyncio.to_thread(call_api)
                text = result.text.strip()
                results.append({"method": config["name"], "text": text, "source": "OpenAI"})
                print(f"âœ… {config['name']}: '{text}'")
                
            except Exception as e:
                print(f"âŒ {config['name']}: {str(e)}")
                results.append({"method": config["name"], "text": f"ì˜¤ë¥˜: {str(e)}", "source": "OpenAI"})
    
    # 2. ë¡œì»¬ Whisper í…ŒìŠ¤íŠ¸ (ì—¬ëŸ¬ ëª¨ë¸)
    print(f"\nğŸ  ë¡œì»¬ Whisper í…ŒìŠ¤íŠ¸")
    print("-" * 30)
    
    try:
        from faster_whisper import WhisperModel
        
        local_configs = [
            {"name": "ë¡œì»¬-large-v3", "model": "large-v3"},
            {"name": "ë¡œì»¬-medium", "model": "medium"},
        ]
        
        for config in local_configs:
            try:
                print(f"ğŸ“¥ {config['model']} ëª¨ë¸ ë¡œë“œ ì¤‘...")
                model = WhisperModel(config["model"], device="cpu", compute_type="int8")
                
                segments, info = model.transcribe(
                    audio_file_path, 
                    language="ko",
                    task="transcribe"
                )
                
                text_parts = []
                for segment in segments:
                    if segment.text.strip():
                        text_parts.append(segment.text.strip())
                
                full_text = " ".join(text_parts).strip()
                results.append({"method": config["name"], "text": full_text, "source": "Local"})
                print(f"âœ… {config['name']}: '{full_text}'")
                
            except Exception as e:
                print(f"âŒ {config['name']}: {str(e)}")
                results.append({"method": config["name"], "text": f"ì˜¤ë¥˜: {str(e)}", "source": "Local"})
                
    except ImportError:
        print("âš ï¸ faster-whisperê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    # 3. ê²°ê³¼ ë¶„ì„
    print(f"\n{'='*60}")
    print("ğŸ“Š êµì°¨ ê²€ì¦ ê²°ê³¼ ë¶„ì„")
    print("="*60)
    
    successful_results = [r for r in results if not r["text"].startswith("ì˜¤ë¥˜:")]
    
    if successful_results:
        print("ğŸ“ ëª¨ë“  ê²°ê³¼:")
        for result in successful_results:
            print(f"  {result['method']} ({result['source']}): '{result['text']}'")
        
        # í…ìŠ¤íŠ¸ ë¹ˆë„ ë¶„ì„
        texts = [r["text"] for r in successful_results]
        text_counter = Counter(texts)
        
        print(f"\nğŸ¯ ê²°ê³¼ ë¹ˆë„ ë¶„ì„:")
        for text, count in text_counter.most_common():
            percentage = (count / len(successful_results)) * 100
            methods = [r["method"] for r in successful_results if r["text"] == text]
            print(f"  '{text}': {count}íšŒ ({percentage:.1f}%)")
            print(f"    â”” ë°©ë²•: {', '.join(methods)}")
        
        # ì†ŒìŠ¤ë³„ ë¶„ì„
        openai_results = [r for r in successful_results if r["source"] == "OpenAI"]
        local_results = [r for r in successful_results if r["source"] == "Local"]
        
        print(f"\nğŸ” ì†ŒìŠ¤ë³„ ì¼ê´€ì„±:")
        if openai_results:
            openai_texts = [r["text"] for r in openai_results]
            openai_counter = Counter(openai_texts)
            if len(openai_counter) == 1:
                print(f"  ğŸŒ OpenAI API: ì™„ì „ ì¼ê´€ë¨ - '{list(openai_counter.keys())[0]}'")
            else:
                print(f"  ğŸŒ OpenAI API: {len(openai_counter)}ê°€ì§€ ê²°ê³¼")
                for text, count in openai_counter.items():
                    print(f"    - '{text}': {count}íšŒ")
        
        if local_results:
            local_texts = [r["text"] for r in local_results]
            local_counter = Counter(local_texts)
            if len(local_counter) == 1:
                print(f"  ğŸ  ë¡œì»¬ Whisper: ì™„ì „ ì¼ê´€ë¨ - '{list(local_counter.keys())[0]}'")
            else:
                print(f"  ğŸ  ë¡œì»¬ Whisper: {len(local_counter)}ê°€ì§€ ê²°ê³¼")
                for text, count in local_counter.items():
                    print(f"    - '{text}': {count}íšŒ")
        
        # ìµœì¢… ê¶Œì¥ì‚¬í•­
        print(f"\nğŸ’¡ ìµœì¢… ê¶Œì¥ì‚¬í•­:")
        if len(text_counter) == 1:
            print("  âœ… ëª¨ë“  ë°©ë²•ì´ ë™ì¼í•œ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.")
            print(f"  ğŸ¯ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ê²°ê³¼: '{list(text_counter.keys())[0]}'")
        else:
            most_common_text, most_common_count = text_counter.most_common(1)[0]
            print(f"  ğŸ¯ ê°€ì¥ ë¹ˆë²ˆí•œ ê²°ê³¼: '{most_common_text}' ({most_common_count}íšŒ)")
            
            if most_common_count >= len(successful_results) * 0.5:
                print("  âœ… ê³¼ë°˜ìˆ˜ ì´ìƒì˜ ë°©ë²•ì´ ë™ì¼í•œ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.")
                print("  ğŸ“‹ ê¶Œì¥: ì´ ê²°ê³¼ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
            else:
                print("  âš ï¸ ê²°ê³¼ê°€ ë¶„ì‚°ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                print("  ğŸ“‹ ê¶Œì¥: ì˜¤ë””ì˜¤ í’ˆì§ˆì„ í™•ì¸í•˜ê±°ë‚˜ ìˆ˜ë™ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

if __name__ == "__main__":
    if len(sys.argv) != 2:
        print("ì‚¬ìš©ë²•: python cross_validation_test.py <audio_file_path>")
        sys.exit(1)
    
    audio_path = sys.argv[1]
    
    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(audio_path):
        print(f"âŒ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_path}")
        sys.exit(1)
    
    file_size = os.path.getsize(audio_path)
    print(f"ğŸ“ íŒŒì¼ ì •ë³´: {os.path.basename(audio_path)} ({file_size/1024:.1f}KB)")
    
    # ë¹„ë™ê¸° ì‹¤í–‰
    asyncio.run(cross_validation_test(audio_path))
    
    print("\n" + "="*60)
    print("ğŸ‰ êµì°¨ ê²€ì¦ ì™„ë£Œ!")
