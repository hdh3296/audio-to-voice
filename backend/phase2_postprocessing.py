"""
ğŸ¤– Phase 2: GPT í›„ì²˜ë¦¬ ëª¨ë“ˆ
- ì°¨ì„¸ëŒ€ í…ìŠ¤íŠ¸ êµì • ì‹œìŠ¤í…œ
- í’ˆì§ˆ ë¶„ì„ í†µí•©
- ì‹¤ì‹œê°„ ì§„í–‰ë¥  í‘œì‹œ
- í•œêµ­ì–´ íŠ¹í™” êµì •
"""

import asyncio
import os
from typing import Dict, List, Optional
from openai import AsyncOpenAI
import logging
from datetime import datetime
import json

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class Phase2PostProcessor:
    """Phase 2 ì „ìš© GPT í›„ì²˜ë¦¬ ì‹œìŠ¤í…œ"""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.client = None
        self.is_enabled = False
        
        if self.api_key and self.api_key != "your_openai_api_key_here":
            try:
                self.client = AsyncOpenAI(api_key=self.api_key)
                self.is_enabled = True
                logger.info("âœ… Phase 2 GPT-4.1 mini í›„ì²˜ë¦¬ ëª¨ë“ˆ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                logger.error(f"âŒ Phase 2 GPT í›„ì²˜ë¦¬ ëª¨ë“ˆ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.is_enabled = False
        else:
            logger.warning("âš ï¸ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ GPT í›„ì²˜ë¦¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    def is_available(self) -> bool:
        """GPT í›„ì²˜ë¦¬ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        return self.is_enabled and self.client is not None
    
    async def process_with_progress(
        self, 
        segments: List[Dict], 
        quality_metrics: Optional[Dict] = None,
        websocket=None,
        session_id: str = "unknown"
    ) -> Dict:
        """ì§„í–‰ë¥ ê³¼ í•¨ê»˜ GPT í›„ì²˜ë¦¬ ì‹¤í–‰"""
        
        if not self.is_available():
            return {
                "success": False,
                "error": "GPT í›„ì²˜ë¦¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.",
                "original_segments": segments,
                "corrected_segments": segments
            }
        
        if not segments:
            return {
                "success": True,
                "corrected_segments": [],
                "original_segments": [],
                "total_corrections": 0,
                "processing_time": 0
            }
        
        start_time = datetime.now()
        
        try:
            logger.info(f"ğŸ¤– Phase 2 GPT-4.1 mini í›„ì²˜ë¦¬ ì‹œì‘: {len(segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸")
            
            # WebSocketìœ¼ë¡œ ì§„í–‰ë¥  ì „ì†¡
            if websocket:
                await self._send_progress(websocket, {
                    "stage": "gpt_postprocessing",
                    "progress": 0,
                    "message": "GPT-4.1 mini í›„ì²˜ë¦¬ ì‹œì‘...",
                    "session_id": session_id
                })
            
            # í’ˆì§ˆ ê¸°ë°˜ êµì • ì „ëµ ê²°ì •
            correction_strategy = self._determine_correction_strategy(quality_metrics)
            logger.info(f"ğŸ“ êµì • ì „ëµ: {correction_strategy['name']}")
            
            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            if websocket:
                await self._send_progress(websocket, {
                    "stage": "gpt_postprocessing", 
                    "progress": 10,
                    "message": f"êµì • ì „ëµ ì„¤ì •: {correction_strategy['name']}",
                    "session_id": session_id
                })
            
            # ì„¸ê·¸ë¨¼íŠ¸ë³„ êµì • ì‹¤í–‰
            corrected_segments = []
            total_corrections = 0
            
            batch_size = 5  # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
            total_batches = (len(segments) + batch_size - 1) // batch_size
            
            for batch_idx, i in enumerate(range(0, len(segments), batch_size)):
                batch_segments = segments[i:i + batch_size]
                
                # ë°°ì¹˜ ì²˜ë¦¬
                batch_result = await self._process_batch(
                    batch_segments, 
                    correction_strategy,
                    batch_idx + 1,
                    total_batches
                )
                
                corrected_segments.extend(batch_result["corrected_segments"])
                total_corrections += batch_result["corrections_count"]
                
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                progress = 10 + (80 * (batch_idx + 1) / total_batches)
                if websocket:
                    await self._send_progress(websocket, {
                        "stage": "gpt_postprocessing",
                        "progress": int(progress),
                        "message": f"ë°°ì¹˜ {batch_idx + 1}/{total_batches} ì²˜ë¦¬ ì™„ë£Œ ({batch_result['corrections_count']}ê°œ êµì •)",
                        "session_id": session_id
                    })
                
                # API ì œí•œ ë°©ì§€ìš© ëŒ€ê¸°
                await asyncio.sleep(0.2)
            
            # ìµœì¢… í’ˆì§ˆ ê²€ì¦
            if websocket:
                await self._send_progress(websocket, {
                    "stage": "gpt_postprocessing",
                    "progress": 90,
                    "message": "ìµœì¢… í’ˆì§ˆ ê²€ì¦ ì¤‘...",
                    "session_id": session_id
                })
            
            final_quality = await self._validate_final_quality(segments, corrected_segments)
            
            processing_time = (datetime.now() - start_time).total_seconds()
            
            # ì™„ë£Œ
            if websocket:
                await self._send_progress(websocket, {
                    "stage": "gpt_postprocessing",
                    "progress": 100,
                    "message": f"GPT-4.1 mini í›„ì²˜ë¦¬ ì™„ë£Œ! {total_corrections}ê°œ í•­ëª© êµì •ë¨",
                    "session_id": session_id
                })
            
            logger.info(f"âœ… Phase 2 GPT-4.1 mini í›„ì²˜ë¦¬ ì™„ë£Œ: {total_corrections}ê°œ êµì •, {processing_time:.2f}ì´ˆ")
            
            return {
                "success": True,
                "corrected_segments": corrected_segments,
                "original_segments": segments,
                "total_corrections": total_corrections,
                "processing_time": processing_time,
                "correction_strategy": correction_strategy["name"],
                "final_quality_score": final_quality["score"],
                "improvement_details": final_quality["improvements"],
                "correction_applied": total_corrections > 0
            }
            
        except Exception as e:
            logger.error(f"âŒ Phase 2 GPT-4.1 mini í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            
            if websocket:
                await self._send_progress(websocket, {
                    "stage": "gpt_postprocessing",
                    "progress": 0,
                    "message": f"GPT-4.1 mini í›„ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}",
                    "error": True,
                    "session_id": session_id
                })
            
            return {
                "success": False,
                "error": str(e),
                "original_segments": segments,
                "corrected_segments": segments,
                "total_corrections": 0
            }
    
    def _determine_correction_strategy(self, quality_metrics: Optional[Dict]) -> Dict:
        """í’ˆì§ˆ ì§€í‘œ ê¸°ë°˜ êµì • ì „ëµ ê²°ì •"""
        
        if not quality_metrics:
            return {
                "name": "í‘œì¤€ êµì •",
                "model": "gpt-4.1-mini",
                "temperature": 0.1,
                "focus": "ì „ë°˜ì ì¸ ë§ì¶¤ë²•ê³¼ ë„ì–´ì“°ê¸°"
            }
        
        overall_score = quality_metrics.get("overall_score", 0.5)
        korean_score = quality_metrics.get("korean_quality_score", 0.5)
        grammar_score = quality_metrics.get("grammar_score", 0.5)
        
        if overall_score >= 0.9:
            return {
                "name": "ì •ë°€ êµì •",
                "model": "gpt-4.1-mini",
                "temperature": 0.05,
                "focus": "ì„¸ë°€í•œ ë¬¸ë²•ê³¼ ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„"
            }
        elif korean_score < 0.7:
            return {
                "name": "í•œêµ­ì–´ ì§‘ì¤‘ êµì •",
                "model": "gpt-4.1-mini", 
                "temperature": 0.1,
                "focus": "í•œêµ­ì–´ í‘œí˜„ê³¼ ì–´íœ˜ ê°œì„ "
            }
        elif grammar_score < 0.6:
            return {
                "name": "ë¬¸ë²• ì§‘ì¤‘ êµì •",
                "model": "gpt-4.1-mini",
                "temperature": 0.1,
                "focus": "ë¬¸ë²• ì˜¤ë¥˜ì™€ ë¬¸ì¥ êµ¬ì¡° ê°œì„ "
            }
        else:
            return {
                "name": "ê· í˜• êµì •",
                "model": "gpt-4.1-mini",
                "temperature": 0.1,
                "focus": "ë§ì¶¤ë²•, ë„ì–´ì“°ê¸°, ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„"
            }
    
    async def _process_batch(
        self, 
        batch_segments: List[Dict], 
        strategy: Dict,
        batch_num: int,
        total_batches: int
    ) -> Dict:
        """ë°°ì¹˜ ë‹¨ìœ„ ì„¸ê·¸ë¨¼íŠ¸ ì²˜ë¦¬"""
        
        logger.info(f"ğŸ“¦ ë°°ì¹˜ {batch_num}/{total_batches} ì²˜ë¦¬ ì¤‘... ({len(batch_segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸)")
        
        corrected_segments = []
        corrections_count = 0
        
        # ë°°ì¹˜ ë‚´ ì„¸ê·¸ë¨¼íŠ¸ë“¤ì„ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ ê²°í•©
        combined_text = "\n".join([
            f"[{i+1}] {seg.get('text', '').strip()}" 
            for i, seg in enumerate(batch_segments) 
            if seg.get('text', '').strip()
        ])
        
        if not combined_text.strip():
            return {
                "corrected_segments": batch_segments,
                "corrections_count": 0
            }
        
        try:
            # GPTë¥¼ ì‚¬ìš©í•œ ë°°ì¹˜ êµì •
            system_prompt = f"""ë‹¹ì‹ ì€ í•œêµ­ì–´ ì „ë¬¸ êµì •ìì…ë‹ˆë‹¤. ìŒì„± ì¸ì‹ ê²°ê³¼ë¥¼ êµì •í•´ì£¼ì„¸ìš”.

**êµì • ì „ëµ: {strategy['focus']}**

**êµì • ì›ì¹™ (GPT-4.1 mini ìµœì í™”):**
1. ğŸ”¥ **ìŒì„±í•™ì  ì˜¤ë¥˜ ìˆ˜ì •**: "ì¤„ê±°ë˜" â†’ "ì¤„ê±°ë¦¬", "ë˜ìš”" â†’ "ë¼ìš”", "í• ê»˜ìš”" â†’ "í• ê²Œìš”"
2. ğŸ”¥ **ë„ì–´ì“°ê¸° ì •ê·œí™”**: "í• ìˆ˜ìˆë‹¤" â†’ "í•  ìˆ˜ ìˆë‹¤", "ì½ê¸°ì‰½ê²Œ" â†’ "ì½ê¸° ì‰½ê²Œ"
3. ğŸ”¥ **ë§ì¶¤ë²• êµì •**: í‘œì¤€ í•œêµ­ì–´ ë§ì¶¤ë²• ì¤€ìˆ˜
4. ğŸ”¥ **ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„**: êµ¬ì–´ì²´ë¥¼ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì–´ì²´ë¡œ
5. ğŸ”¥ **ì›ë³¸ ì˜ë¯¸ ì ˆëŒ€ ë³´ì¡´**: ì˜ë¯¸ë¥¼ ë³€ê²½í•˜ì§€ ë§ˆì„¸ìš”
6. ğŸ†• **ë¬¸ë§¥ ì´í•´ ê°•í™”**: ì•ë’¤ ë¬¸ë§¥ì„ ê³ ë ¤í•œ ì •í™•í•œ êµì •
7. ğŸ†• **ì¼ê´€ì„± ìœ ì§€**: ì „ì²´ í…ìŠ¤íŠ¸ì˜ í†¤ê³¼ ìŠ¤íƒ€ì¼ ì¼ê´€ì„±
8. ğŸŒŸ **ì™¸ë˜ì–´ í‘œê¸°ë²• êµì •**: êµ­ë¦½êµ­ì–´ì› ì™¸ë˜ì–´ í‘œê¸°ë²• ì¤€ìˆ˜

**íŠ¹ë³„ ì£¼ì˜ì‚¬í•­ (GPT-4.1 mini ì „ìš©):**
- "ì¤„ê±°ë˜"ëŠ” ë°˜ë“œì‹œ "ì¤„ê±°ë¦¬"ë¡œ êµì •
- "ì½ê¸°ì‰½ê²Œ"ëŠ” ë°˜ë“œì‹œ "ì½ê¸° ì‰½ê²Œ"ë¡œ êµì •
- ëª¨ë“  ìŒì„± ì¸ì‹ ì˜¤ë¥˜ë¥¼ ì •í™•íˆ ê°ì§€í•˜ê³  ìˆ˜ì •
- ê¸´ í…ìŠ¤íŠ¸ì—ì„œë„ ì¼ê´€ëœ í’ˆì§ˆ ìœ ì§€
- ë³µì¡í•œ ë¬¸ì¥ êµ¬ì¡°ë„ ìì—°ìŠ¤ëŸ½ê²Œ ê°œì„ 

**ì™¸ë˜ì–´ í‘œê¸°ë²• êµì • (í•„ìˆ˜ ì ìš©):**
- "ì½˜ì‚¬ì´ìŠ¤" â†’ "ì»¨ì‚¬ì´ìŠ¤" (Concise)
- "ë©”ë‰´ì–¼" â†’ "ë§¤ë‰´ì–¼" (Manual)  
- "ë¦¬ë·°" â†’ "ë¦¬ë·°" (Review - ì´ë¯¸ ì •í™•)
- "í”„ë¡œì íŠ¸" â†’ "í”„ë¡œì íŠ¸" (Project - ì´ë¯¸ ì •í™•)
- "ì‹œìŠ¤í…œ" â†’ "ì‹œìŠ¤í…œ" (System - ì´ë¯¸ ì •í™•)
- "ì»´í“¨í„°" â†’ "ì»´í“¨í„°" (Computer - ì´ë¯¸ ì •í™•)
- "ì„¼í„°" â†’ "ì„¼í„°" (Center - ì´ë¯¸ ì •í™•)
- "ì¸í„°ë„·" â†’ "ì¸í„°ë„·" (Internet - ì´ë¯¸ ì •í™•)
- ê¸°íƒ€ êµ­ë¦½êµ­ì–´ì› ì™¸ë˜ì–´ í‘œê¸°ë²• ì¤€ìˆ˜

**ì…ë ¥ í˜•ì‹:** [ë²ˆí˜¸] í…ìŠ¤íŠ¸
**ì¶œë ¥ í˜•ì‹:** ë™ì¼í•œ ë²ˆí˜¸ë¡œ êµì •ëœ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥

ê° ì¤„ì€ ë°˜ë“œì‹œ [ë²ˆí˜¸] í˜•ì‹ì„ ìœ ì§€í•˜ê³ , êµì •ëœ í…ìŠ¤íŠ¸ë§Œ ì œê³µí•˜ì„¸ìš”."""

            response = await self.client.chat.completions.create(
                model=strategy["model"],
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"ë‹¤ìŒ í…ìŠ¤íŠ¸ë“¤ì„ êµì •í•´ì£¼ì„¸ìš”:\n\n{combined_text}"}
                ],
                temperature=strategy["temperature"],
                max_tokens=2000,
                timeout=45.0
            )
            
            corrected_text = response.choices[0].message.content.strip()
            
            # êµì • ê²°ê³¼ë¥¼ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ë‹¤ì‹œ ë¶„í• 
            corrected_lines = corrected_text.split('\n')
            corrected_dict = {}
            
            for line in corrected_lines:
                line = line.strip()
                if line.startswith('[') and '] ' in line:
                    try:
                        bracket_end = line.find('] ')
                        num_str = line[1:bracket_end]
                        corrected_content = line[bracket_end + 2:].strip()
                        corrected_dict[int(num_str)] = corrected_content
                    except:
                        continue
            
            # ì›ë³¸ ì„¸ê·¸ë¨¼íŠ¸ì™€ êµì • ê²°ê³¼ ë§¤ì¹­
            for i, original_seg in enumerate(batch_segments):
                original_text = original_seg.get('text', '').strip()
                
                if not original_text:
                    corrected_segments.append(original_seg.copy())
                    continue
                
                segment_num = i + 1
                if segment_num in corrected_dict:
                    corrected_text = corrected_dict[segment_num]
                    
                    # êµì •ì´ ì‹¤ì œë¡œ ì ìš©ë˜ì—ˆëŠ”ì§€ í™•ì¸
                    if corrected_text != original_text and len(corrected_text) >= len(original_text) * 0.5:
                        corrected_segment = {
                            "start": original_seg.get("start", 0),
                            "end": original_seg.get("end", 0),
                            "text": corrected_text
                        }
                        corrected_segments.append(corrected_segment)
                        corrections_count += 1
                        logger.info(f"  âœï¸  êµì •: '{original_text}' â†’ '{corrected_text}'")
                    else:
                        corrected_segments.append(original_seg.copy())
                else:
                    corrected_segments.append(original_seg.copy())
        
        except Exception as e:
            logger.error(f"âŒ ë°°ì¹˜ {batch_num} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            corrected_segments = batch_segments.copy()
        
        return {
            "corrected_segments": corrected_segments,
            "corrections_count": corrections_count
        }
    
    async def _validate_final_quality(
        self, 
        original_segments: List[Dict], 
        corrected_segments: List[Dict]
    ) -> Dict:
        """ìµœì¢… í’ˆì§ˆ ê²€ì¦"""
        
        try:
            original_text = " ".join([seg.get("text", "") for seg in original_segments])
            corrected_text = " ".join([seg.get("text", "") for seg in corrected_segments])
            
            # ê¸°ë³¸ í’ˆì§ˆ ì§€í‘œ ê³„ì‚°
            improvements = []
            
            # ê¸¸ì´ ë¹„êµ
            if len(corrected_text) >= len(original_text) * 0.8:
                improvements.append("ì ì ˆí•œ í…ìŠ¤íŠ¸ ê¸¸ì´ ìœ ì§€")
            
            # í•œê¸€ ë¹„ìœ¨ ê°œì„  í™•ì¸
            original_korean = sum(1 for char in original_text if 'ê°€' <= char <= 'í£')
            corrected_korean = sum(1 for char in corrected_text if 'ê°€' <= char <= 'í£')
            
            if corrected_korean >= original_korean:
                improvements.append("í•œêµ­ì–´ í‘œí˜„ ê°œì„ ")
            
            # ë„ì–´ì“°ê¸° ê°œì„  í™•ì¸
            original_spaces = original_text.count(' ')
            corrected_spaces = corrected_text.count(' ')
            
            if corrected_spaces > original_spaces * 0.8:
                improvements.append("ë„ì–´ì“°ê¸° ì •ê·œí™”")
            
            # ë¬¸ì¥ë¶€í˜¸ ê°œì„  í™•ì¸
            punctuation = '.!?,'
            original_punct = sum(1 for char in original_text if char in punctuation)
            corrected_punct = sum(1 for char in corrected_text if char in punctuation)
            
            if corrected_punct >= original_punct:
                improvements.append("ë¬¸ì¥ë¶€í˜¸ ìµœì í™”")
            
            # ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            quality_score = min(1.0, len(improvements) / 4.0 + 0.5)
            
            return {
                "score": quality_score,
                "improvements": improvements
            }
            
        except Exception as e:
            logger.error(f"âŒ ìµœì¢… í’ˆì§ˆ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return {
                "score": 0.5,
                "improvements": ["í’ˆì§ˆ ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ"]
            }
    
    async def _send_progress(self, websocket, data: Dict):
        """WebSocketìœ¼ë¡œ ì§„í–‰ë¥  ì „ì†¡"""
        try:
            if websocket:
                message = {
                    "type": "progress",
                    "timestamp": datetime.now().isoformat(),
                    **data
                }
                await websocket.send_text(json.dumps(message))
        except Exception as e:
            logger.warning(f"âš ï¸ WebSocket ì§„í–‰ë¥  ì „ì†¡ ì‹¤íŒ¨: {e}")


class PostProcessingResult:
    """í›„ì²˜ë¦¬ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""
    
    def __init__(
        self,
        success: bool,
        corrected_segments: List[Dict],
        original_segments: List[Dict],
        total_corrections: int = 0,
        processing_time: float = 0,
        correction_strategy: str = "",
        final_quality_score: float = 0,
        improvement_details: List[str] = None,
        error: str = None
    ):
        self.success = success
        self.corrected_segments = corrected_segments
        self.original_segments = original_segments
        self.total_corrections = total_corrections
        self.processing_time = processing_time
        self.correction_strategy = correction_strategy
        self.final_quality_score = final_quality_score
        self.improvement_details = improvement_details or []
        self.error = error
    
    def to_dict(self) -> Dict:
        return {
            "success": self.success,
            "corrected_segments": self.corrected_segments,
            "original_segments": self.original_segments,
            "total_corrections": self.total_corrections,
            "processing_time": self.processing_time,
            "correction_strategy": self.correction_strategy,
            "final_quality_score": self.final_quality_score,
            "improvement_details": self.improvement_details,
            "error": self.error,
            "correction_applied": self.total_corrections > 0
        }
