#!/usr/bin/env python3
"""
ë…ë¦½ì ì¸ ì•ˆì •í™” API í…ŒìŠ¤íŠ¸ (pydub ì˜ì¡´ì„± ì—†ìŒ)
"""
import os
import sys
import asyncio
import hashlib
from dotenv import load_dotenv
from openai import OpenAI

class DirectStableAPITest:
    """ì§ì ‘ ì•ˆì •í™” API í…ŒìŠ¤íŠ¸"""
    
    def __init__(self):
        load_dotenv()
        self.api_key = os.getenv("OPENAI_API_KEY")
        self.client = None
        
        if self.api_key and self.api_key != "your_openai_api_key_here":
            self.client = OpenAI(api_key=self.api_key)
    
    def is_available(self):
        return self.client is not None
    
    def generate_file_seed(self, file_path: str) -> int:
        """íŒŒì¼ ê¸°ë°˜ ì¼ê´€ëœ ì‹œë“œ ìƒì„±"""
        file_size = os.path.getsize(file_path)
        seed_string = f"{file_path}_{file_size}"
        seed_hash = hashlib.md5(seed_string.encode()).hexdigest()
        return int(seed_hash[:8], 16) % (2**31 - 1)
    
    async def transcribe_stable(self, audio_path: str, use_enhanced_prompt: bool = True):
        """ì•ˆì •í™”ëœ ì „ì‚¬"""
        if not self.is_available():
            return {"success": False, "error": "API í‚¤ ì—†ìŒ"}
        
        # í–¥ìƒëœ í”„ë¡¬í”„íŠ¸
        if use_enhanced_prompt:
            prompt = """ë‹¤ìŒì€ í•œêµ­ì–´ ìŒì„±ì…ë‹ˆë‹¤. ì •í™•í•œ í•œêµ­ì–´ í‘œì¤€ì–´ë¡œ ì „ì‚¬í•´ì£¼ì„¸ìš”. 
ë¬¸ì¥ ë¶€í˜¸ëŠ” ìì—°ìŠ¤ëŸ½ê²Œ ì‚¬ìš©í•˜ê³ , ë„ì–´ì“°ê¸°ëŠ” í•œêµ­ì–´ ë§ì¶¤ë²•ì— ë§ê²Œ í•´ì£¼ì„¸ìš”. 
ë¸Œëœë“œëª…ì´ë‚˜ ê³ ìœ ëª…ì‚¬ëŠ” ì •í™•í•˜ê²Œ í‘œê¸°í•´ì£¼ì„¸ìš”."""
        else:
            prompt = ""
        
        def _api_call():
            with open(audio_path, "rb") as audio_file:
                return self.client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_file,
                    language="ko",
                    response_format="verbose_json",
                    prompt=prompt,
                    temperature=0.0  # ğŸ”‘ ì•ˆì •ì„±ì„ ìœ„í•´ 0
                )
        
        try:
            result = await asyncio.to_thread(_api_call)
            return {
                "success": True,
                "text": result.text.strip(),
                "temperature": 0.0,
                "prompt_used": bool(prompt)
            }
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def transcribe_baseline(self, audio_path: str):
        """ê¸°ì¡´ ë°©ì‹ (ë¹„êµìš©)"""
        if not self.is_available():
            return {"success": False, "error": "API í‚¤ ì—†ìŒ"}
        
        def _api_call():
            with open(audio_path, "rb") as audio_file:
                return self.client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_file,
                    language="ko",
                    response_format="verbose_json"
                    # temperatureì™€ prompt ì—†ìŒ (ê¸°ë³¸ê°’ ì‚¬ìš©)
                )
        
        try:
            result = await asyncio.to_thread(_api_call)
            return {
                "success": True,
                "text": result.text.strip(),
                "method": "baseline"
            }
        except Exception as e:
            return {"success": False, "error": str(e)}

async def main():
    if len(sys.argv) != 2:
        print("ì‚¬ìš©ë²•: python direct_stability_test.py <audio_file>")
        sys.exit(1)
    
    audio_path = sys.argv[1]
    
    if not os.path.exists(audio_path):
        print(f"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {audio_path}")
        sys.exit(1)
    
    tester = DirectStableAPITest()
    
    if not tester.is_available():
        print("âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
        sys.exit(1)
    
    print("ğŸ§ª OpenAI API ì•ˆì •í™” íš¨ê³¼ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    print(f"ğŸ“ íŒŒì¼: {os.path.basename(audio_path)}")
    print()
    
    # 1. ê¸°ì¡´ ë°©ì‹ í…ŒìŠ¤íŠ¸ (5íšŒ)
    print("ğŸ“Š 1ë‹¨ê³„: ê¸°ì¡´ ë°©ì‹ (temperature ê¸°ë³¸ê°’, í”„ë¡¬í”„íŠ¸ ì—†ìŒ)")
    print("-" * 50)
    
    baseline_results = []
    for i in range(5):
        print(f"ğŸ“¡ {i+1}ë²ˆì§¸ í˜¸ì¶œ...")
        result = await tester.transcribe_baseline(audio_path)
        
        if result.get("success"):
            text = result["text"]
            baseline_results.append(text)
            print(f"   ê²°ê³¼: {text}")
        else:
            print(f"   âŒ ì‹¤íŒ¨: {result.get('error')}")
            baseline_results.append(f"ERROR: {result.get('error')}")
    
    # ê¸°ì¡´ ë°©ì‹ ë¶„ì„
    baseline_unique = list(set([r for r in baseline_results if not r.startswith("ERROR")]))
    baseline_errors = len([r for r in baseline_results if r.startswith("ERROR")])
    
    print(f"\nğŸ“ˆ ê¸°ì¡´ ë°©ì‹ ê²°ê³¼:")
    print(f"   ì„±ê³µ: {len(baseline_results) - baseline_errors}/5íšŒ")
    print(f"   ê³ ìœ  ê²°ê³¼: {len(baseline_unique)}ê°œ")
    for i, result in enumerate(baseline_unique):
        count = baseline_results.count(result)
        print(f"      {i+1}. \"{result}\" ({count}íšŒ)")
    
    # 2. ì•ˆì •í™” ë°©ì‹ í…ŒìŠ¤íŠ¸ (5íšŒ)
    print(f"\nğŸ¯ 2ë‹¨ê³„: ì•ˆì •í™” ë°©ì‹ (temperature=0, ìƒì„¸ í”„ë¡¬í”„íŠ¸)")
    print("-" * 50)
    
    stable_results = []
    for i in range(5):
        print(f"ğŸ“¡ {i+1}ë²ˆì§¸ í˜¸ì¶œ...")
        result = await tester.transcribe_stable(audio_path, use_enhanced_prompt=True)
        
        if result.get("success"):
            text = result["text"]
            stable_results.append(text)
            print(f"   ê²°ê³¼: {text}")
        else:
            print(f"   âŒ ì‹¤íŒ¨: {result.get('error')}")
            stable_results.append(f"ERROR: {result.get('error')}")
    
    # ì•ˆì •í™” ë°©ì‹ ë¶„ì„
    stable_unique = list(set([r for r in stable_results if not r.startswith("ERROR")]))
    stable_errors = len([r for r in stable_results if r.startswith("ERROR")])
    
    print(f"\nğŸ“ˆ ì•ˆì •í™” ë°©ì‹ ê²°ê³¼:")
    print(f"   ì„±ê³µ: {len(stable_results) - stable_errors}/5íšŒ")
    print(f"   ê³ ìœ  ê²°ê³¼: {len(stable_unique)}ê°œ")
    for i, result in enumerate(stable_unique):
        count = stable_results.count(result)
        print(f"      {i+1}. \"{result}\" ({count}íšŒ)")
    
    # 3. ë¹„êµ ë° ê²°ë¡ 
    print(f"\nğŸ†š ë¹„êµ ê²°ê³¼:")
    print("=" * 60)
    print(f"ê¸°ì¡´ ë°©ì‹:")
    print(f"   ê³ ìœ  ê²°ê³¼ ìˆ˜: {len(baseline_unique)}ê°œ")
    print(f"   ë³€ë™ì„±: {'ë†’ìŒ' if len(baseline_unique) > 3 else 'ë³´í†µ' if len(baseline_unique) > 1 else 'ë‚®ìŒ'}")
    
    print(f"ì•ˆì •í™” ë°©ì‹:")
    print(f"   ê³ ìœ  ê²°ê³¼ ìˆ˜: {len(stable_unique)}ê°œ")
    print(f"   ë³€ë™ì„±: {'ë†’ìŒ' if len(stable_unique) > 3 else 'ë³´í†µ' if len(stable_unique) > 1 else 'ë‚®ìŒ'}")
    
    # ê°œì„  íš¨ê³¼ ê³„ì‚°
    improvement = len(baseline_unique) - len(stable_unique)
    
    print(f"\nğŸ† ê°œì„  íš¨ê³¼:")
    if improvement > 0:
        print(f"   âœ… {improvement}ê°œ ê²°ê³¼ ê°ì†Œ - ì•ˆì •ì„± í–¥ìƒ!")
        if len(stable_unique) == 1:
            print("   ğŸ‰ ì™„ë²½í•œ ì¼ê´€ì„± ë‹¬ì„±!")
        else:
            print("   ğŸ“ˆ ì¼ê´€ì„± í¬ê²Œ ê°œì„ ë¨")
    elif improvement == 0:
        print("   âš–ï¸ ìœ ì‚¬í•œ ìˆ˜ì¤€ì˜ ì¼ê´€ì„±")
    else:
        print("   âš ï¸ ì•ˆì •í™” íš¨ê³¼ ë¯¸ë¯¸")
    
    print(f"\nğŸ’¡ ê²°ë¡ :")
    if len(stable_unique) <= 1:
        print("   â†’ âœ… ì•ˆì •í™”ëœ API ëª¨ë“œ ì‚¬ìš© ê¶Œì¥")
        print("   â†’ ìë§‰ ì‘ì—…ì— ì í•©í•œ ì¼ê´€ì„± í™•ë³´")
    elif len(stable_unique) < len(baseline_unique):
        print("   â†’ âš¡ ì•ˆì •í™” ëª¨ë“œê°€ ê¸°ë³¸ ëª¨ë“œë³´ë‹¤ ê°œì„ ë¨")
        print("   â†’ ì¤‘ìš”í•œ ì‘ì—…ì— ì•ˆì •í™” ëª¨ë“œ ê¶Œì¥")
    else:
        print("   â†’ ğŸ  ì¤‘ìš”í•œ ìë§‰ ì‘ì—…ì—ëŠ” ë¡œì»¬ ëª¨ë“œ ì‚¬ìš© ê¶Œì¥")
        print("   â†’ APIëŠ” ì†ë„ê°€ ìš°ì„ ì¸ ê²½ìš°ì—ë§Œ ì‚¬ìš©")

if __name__ == "__main__":
    asyncio.run(main())
