"""
ğŸš€ Phase 2: ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì „ì‚¬ ì‹œìŠ¤í…œ
- WebSocket ê¸°ë°˜ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
- ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬ë¡œ ë¹ ë¥¸ ì‘ë‹µ
- ì§„í–‰ë¥  ì‹¤ì‹œê°„ í‘œì‹œ
"""

import asyncio
import json
import time
import tempfile
import os
from typing import Dict, List, Optional, AsyncGenerator, Callable
from pathlib import Path
import numpy as np
from dataclasses import dataclass, asdict

# pydub ê´€ë ¨ ì„í¬íŠ¸ë¥¼ try-exceptë¡œ ì²˜ë¦¬
try:
    from pydub import AudioSegment
    from pydub.silence import split_on_silence
    PYDUB_AVAILABLE = True
except ImportError:
    print("âš ï¸ pydubë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì²­í‚¹ ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    PYDUB_AVAILABLE = False


@dataclass 
class StreamingProgress:
    """ìŠ¤íŠ¸ë¦¬ë° ì§„í–‰ ìƒí™©"""
    total_chunks: int
    processed_chunks: int
    current_chunk: int
    progress_percent: float
    current_text: str
    estimated_remaining_time: float
    status: str  # "processing", "completed", "error"
    error_message: Optional[str] = None


@dataclass
class StreamingChunk:
    """ìŠ¤íŠ¸ë¦¬ë° ì²­í¬ ë°ì´í„°"""
    chunk_id: int
    start_time: float
    end_time: float
    audio_data: bytes
    text: Optional[str] = None
    confidence: Optional[float] = None
    processing_time: Optional[float] = None


class AudioChunker:
    """ì˜¤ë””ì˜¤ ì²­í‚¹ ì‹œìŠ¤í…œ"""
    
    def __init__(self, chunk_duration: float = 30.0, overlap: float = 2.0):
        """
        ì´ˆê¸°í™”
        Args:
            chunk_duration: ì²­í¬ ê¸¸ì´ (ì´ˆ)
            overlap: ì²­í¬ ê°„ ê²¹ì¹¨ (ì´ˆ)
        """
        self.chunk_duration = chunk_duration
        self.overlap = overlap
    
    async def chunk_audio_file(self, audio_path: str) -> List[StreamingChunk]:
        """ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì²­í¬ë¡œ ë¶„í•  (ê°„ë‹¨í•œ ì‹œê°„ ê¸°ë°˜ ë°©ì‹)"""
        
        try:
            if PYDUB_AVAILABLE:
                return await self._chunk_with_pydub(audio_path)
            else:
                return await self._chunk_simple(audio_path)
        except Exception as e:
            print(f"âŒ ì˜¤ë””ì˜¤ ì²­í‚¹ ì‹¤íŒ¨: {str(e)}")
            raise
    
    async def _chunk_simple(self, audio_path: str) -> List[StreamingChunk]:
        """ê°„ë‹¨í•œ ì‹œê°„ ê¸°ë°˜ ì²­í‚¹ (pydub ì—†ì´)"""
        
        # ffprobeë¥¼ ì‚¬ìš©í•´ì„œ ì˜¤ë””ì˜¤ ê¸¸ì´ êµ¬í•˜ê¸°
        try:
            import subprocess
            cmd = ['ffprobe', '-v', 'quiet', '-show_entries', 'format=duration', 
                   '-of', 'csv=p=0', audio_path]
            result = subprocess.run(cmd, capture_output=True, text=True)
            total_duration = float(result.stdout.strip())
        except:
            total_duration = 60.0  # ê¸°ë³¸ê°’
        
        chunks = []
        chunk_id = 0
        start_time = 0.0
        
        print(f"ğŸµ ì˜¤ë””ì˜¤ ì´ ê¸¸ì´: {total_duration:.1f}ì´ˆ (ê°„ë‹¨í•œ ì²­í‚¹)")
        print(f"ğŸ“Š ì²­í¬ í¬ê¸°: {self.chunk_duration}ì´ˆ, ê²¹ì¹¨: {self.overlap}ì´ˆ")
        
        while start_time < total_duration:
            end_time = min(start_time + self.chunk_duration, total_duration)
            
            # ì‹¤ì œ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ì²­í‚¹í•˜ì§€ ì•Šê³ )
            with open(audio_path, 'rb') as f:
                audio_data = f.read()
            
            chunk = StreamingChunk(
                chunk_id=chunk_id,
                start_time=start_time,
                end_time=end_time,
                audio_data=audio_data  # ì „ì²´ íŒŒì¼ ì‚¬ìš©
            )
            
            chunks.append(chunk)
            print(f"  ğŸ“¦ ì²­í¬ {chunk_id}: {start_time:.1f}s - {end_time:.1f}s")
            
            start_time = end_time - self.overlap
            chunk_id += 1
            
            if end_time >= total_duration:
                break
        
        print(f"âœ… ì´ {len(chunks)}ê°œ ì²­í¬ ìƒì„± ì™„ë£Œ (ê°„ë‹¨í•œ ë°©ì‹)")
        return chunks
    
    async def _chunk_with_pydub(self, audio_path: str) -> List[StreamingChunk]:
        """pydubë¥¼ ì‚¬ìš©í•œ ì •í™•í•œ ì²­í‚¹"""
        
        # ì˜¤ë””ì˜¤ ë¡œë“œ
        audio = AudioSegment.from_file(audio_path)
        total_duration = len(audio) / 1000.0  # ì´ˆ ë‹¨ìœ„
        
        chunks = []
        chunk_id = 0
        start_ms = 0
        chunk_duration_ms = int(self.chunk_duration * 1000)
        overlap_ms = int(self.overlap * 1000)
        
        print(f"ğŸµ ì˜¤ë””ì˜¤ ì´ ê¸¸ì´: {total_duration:.1f}ì´ˆ")
        print(f"ğŸ“Š ì²­í¬ í¬ê¸°: {self.chunk_duration}ì´ˆ, ê²¹ì¹¨: {self.overlap}ì´ˆ")
        
        while start_ms < len(audio):
            # ì²­í¬ ë ì§€ì  ê³„ì‚°
            end_ms = min(start_ms + chunk_duration_ms, len(audio))
            
            # ì˜¤ë””ì˜¤ ì²­í¬ ì¶”ì¶œ
            chunk_audio = audio[start_ms:end_ms]
            
            # ì²­í¬ ë°ì´í„° ìƒì„±
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
                chunk_audio.export(temp_file.name, format="wav")
                
                with open(temp_file.name, 'rb') as f:
                    audio_data = f.read()
                
                os.unlink(temp_file.name)
            
            chunk = StreamingChunk(
                chunk_id=chunk_id,
                start_time=start_ms / 1000.0,
                end_time=end_ms / 1000.0,
                audio_data=audio_data
            )
            
            chunks.append(chunk)
            
            print(f"  ğŸ“¦ ì²­í¬ {chunk_id}: {chunk.start_time:.1f}s - {chunk.end_time:.1f}s")
            
            # ë‹¤ìŒ ì²­í¬ ì‹œì‘ì  (ê²¹ì¹¨ ê³ ë ¤)
            start_ms = end_ms - overlap_ms
            chunk_id += 1
            
            # ë§ˆì§€ë§‰ ì²­í¬ì¸ ê²½ìš° ì¢…ë£Œ
            if end_ms >= len(audio):
                break
        
        print(f"âœ… ì´ {len(chunks)}ê°œ ì²­í¬ ìƒì„± ì™„ë£Œ")
        return chunks


class StreamingTranscriber:
    """ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì „ì‚¬ê¸°"""
    
    def __init__(self, model_manager, chunk_duration: float = 30.0):
        """ì´ˆê¸°í™”"""
        self.model_manager = model_manager
        self.chunker = AudioChunker(chunk_duration)
        self.active_sessions: Dict[str, Dict] = {}
    
    async def transcribe_streaming(
        self,
        session_id: str,
        audio_path: str,
        model: str = "gpt-4o-audio-preview",
        language: str = "ko",
        progress_callback: Optional[Callable] = None
    ) -> AsyncGenerator[StreamingProgress, None]:
        """ìŠ¤íŠ¸ë¦¬ë° ì „ì‚¬ ì‹¤í–‰"""
        
        start_time = time.time()
        
        try:
            # ì„¸ì…˜ ì´ˆê¸°í™”
            self.active_sessions[session_id] = {
                "status": "chunking",
                "start_time": start_time,
                "model": model
            }
            
            # 1ë‹¨ê³„: ì˜¤ë””ì˜¤ ì²­í‚¹
            yield StreamingProgress(
                total_chunks=0,
                processed_chunks=0,
                current_chunk=0,
                progress_percent=0.0,
                current_text="ì˜¤ë””ì˜¤ë¥¼ ë¶„ì„ ì¤‘...",
                estimated_remaining_time=0.0,
                status="chunking"
            )
            
            chunks = await self.chunker.chunk_audio_file(audio_path)
            total_chunks = len(chunks)
            
            # 2ë‹¨ê³„: ë³‘ë ¬ ì „ì‚¬ ì‹œì‘
            self.active_sessions[session_id]["status"] = "processing"
            full_text = ""
            all_segments = []
            processing_times = []
            
            for i, chunk in enumerate(chunks):
                chunk_start_time = time.time()
                
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                progress_percent = (i / total_chunks) * 100
                
                # ë‚¨ì€ ì‹œê°„ ì¶”ì •
                if processing_times:
                    avg_processing_time = sum(processing_times) / len(processing_times)
                    remaining_chunks = total_chunks - i
                    estimated_remaining_time = avg_processing_time * remaining_chunks
                else:
                    estimated_remaining_time = 0.0
                
                yield StreamingProgress(
                    total_chunks=total_chunks,
                    processed_chunks=i,
                    current_chunk=i + 1,
                    progress_percent=progress_percent,
                    current_text=f"ì²­í¬ {i+1}/{total_chunks} ì²˜ë¦¬ ì¤‘...",
                    estimated_remaining_time=estimated_remaining_time,
                    status="processing"
                )
                
                # ì²­í¬ ì „ì‚¬
                try:
                    with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
                        temp_file.write(chunk.audio_data)
                        temp_file.flush()
                        
                        result = await self.model_manager.transcribe_with_model(
                            temp_file.name, model, language, include_quality_metrics=True
                        )
                        
                        os.unlink(temp_file.name)
                    
                    if result.success and result.text.strip():
                        chunk.text = result.text.strip()
                        chunk.confidence = result.confidence_score
                        
                        # ì‹œê°„ ì˜¤í”„ì…‹ ì¡°ì •
                        adjusted_segments = []
                        for segment in result.segments:
                            adj_segment = segment.copy()
                            adj_segment["start"] += chunk.start_time
                            adj_segment["end"] += chunk.start_time
                            adjusted_segments.append(adj_segment)
                        
                        all_segments.extend(adjusted_segments)
                        full_text += " " + chunk.text
                        
                        print(f"  âœ… ì²­í¬ {i+1}: {chunk.text[:50]}...")
                    
                    else:
                        print(f"  âš ï¸ ì²­í¬ {i+1}: ì „ì‚¬ ì‹¤íŒ¨ ë˜ëŠ” ë¹ˆ ê²°ê³¼")
                
                except Exception as e:
                    print(f"  âŒ ì²­í¬ {i+1} ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
                
                # ì²˜ë¦¬ ì‹œê°„ ê¸°ë¡
                chunk_processing_time = time.time() - chunk_start_time
                processing_times.append(chunk_processing_time)
                chunk.processing_time = chunk_processing_time
                
                # ì¤‘ê°„ ê²°ê³¼ ì—…ë°ì´íŠ¸
                yield StreamingProgress(
                    total_chunks=total_chunks,
                    processed_chunks=i + 1,
                    current_chunk=i + 1,
                    progress_percent=((i + 1) / total_chunks) * 100,
                    current_text=full_text.strip(),
                    estimated_remaining_time=estimated_remaining_time,
                    status="processing"
                )
                
                # í”„ë¡œê·¸ë ˆìŠ¤ ì½œë°± í˜¸ì¶œ
                if progress_callback:
                    await progress_callback(session_id, i + 1, total_chunks)
            
            # 3ë‹¨ê³„: ì™„ë£Œ
            total_processing_time = time.time() - start_time
            self.active_sessions[session_id]["status"] = "completed"
            self.active_sessions[session_id]["result"] = {
                "text": full_text.strip(),
                "segments": all_segments,
                "total_processing_time": total_processing_time,
                "chunks_processed": len(chunks)
            }
            
            yield StreamingProgress(
                total_chunks=total_chunks,
                processed_chunks=total_chunks,
                current_chunk=total_chunks,
                progress_percent=100.0,
                current_text=full_text.strip(),
                estimated_remaining_time=0.0,
                status="completed"
            )
            
            print(f"ğŸ‰ ìŠ¤íŠ¸ë¦¬ë° ì „ì‚¬ ì™„ë£Œ - ì´ {total_processing_time:.2f}ì´ˆ")
            
        except Exception as e:
            error_msg = str(e)
            print(f"âŒ ìŠ¤íŠ¸ë¦¬ë° ì „ì‚¬ ì˜¤ë¥˜: {error_msg}")
            
            self.active_sessions[session_id]["status"] = "error"
            self.active_sessions[session_id]["error"] = error_msg
            
            yield StreamingProgress(
                total_chunks=0,
                processed_chunks=0,
                current_chunk=0,
                progress_percent=0.0,
                current_text="",
                estimated_remaining_time=0.0,
                status="error",
                error_message=error_msg
            )
    
    def get_session_status(self, session_id: str) -> Optional[Dict]:
        """ì„¸ì…˜ ìƒíƒœ ì¡°íšŒ"""
        return self.active_sessions.get(session_id)
    
    def cancel_session(self, session_id: str) -> bool:
        """ì„¸ì…˜ ì·¨ì†Œ"""
        if session_id in self.active_sessions:
            self.active_sessions[session_id]["status"] = "cancelled"
            return True
        return False
    
    def cleanup_session(self, session_id: str) -> bool:
        """ì„¸ì…˜ ì •ë¦¬"""
        if session_id in self.active_sessions:
            del self.active_sessions[session_id]
            return True
        return False


class StreamingWebSocketHandler:
    """WebSocket ìŠ¤íŠ¸ë¦¬ë° í•¸ë“¤ëŸ¬ (ì„ íƒì  ê¸°ëŠ¥)"""
    
    def __init__(self, streaming_transcriber: StreamingTranscriber):
        self.transcriber = streaming_transcriber
        self.connections: Dict[str, any] = {}  # WebSocket ì—°ê²° íƒ€ì… ì¼ë°˜í™”
    
    async def handle_connection(self, websocket, path):
        """WebSocket ì—°ê²° ì²˜ë¦¬ (websockets íŒ¨í‚¤ì§€ í•„ìš”ì‹œì—ë§Œ ì‚¬ìš©)"""
        session_id = None
        
        try:
            # ì‹¤ì œ WebSocket ì²˜ë¦¬ëŠ” main_phase2.pyì—ì„œ ì²˜ë¦¬
            pass
            
        except Exception as e:
            print(f"âŒ WebSocket ì˜¤ë¥˜: {str(e)}")
        
        finally:
            if session_id and session_id in self.connections:
                del self.connections[session_id]


# í…ŒìŠ¤íŠ¸ìš© í•¨ìˆ˜ë“¤
async def test_streaming_system():
    """ìŠ¤íŠ¸ë¦¬ë° ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    from phase2_models import Phase2ModelManager
    import os
    from dotenv import load_dotenv
    
    load_dotenv()
    api_key = os.getenv("OPENAI_API_KEY")
    
    if not api_key:
        print("âŒ OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤")
        return
    
    # ë§¤ë‹ˆì € ì´ˆê¸°í™”
    model_manager = Phase2ModelManager(api_key)
    transcriber = StreamingTranscriber(model_manager, chunk_duration=20.0)
    
    # í…ŒìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ
    test_audio = "/path/to/test/audio.mp3"
    
    if not os.path.exists(test_audio):
        print("âŒ í…ŒìŠ¤íŠ¸ ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
        return
    
    # ìŠ¤íŠ¸ë¦¬ë° ì „ì‚¬ í…ŒìŠ¤íŠ¸
    session_id = "test_session_001"
    
    print("ğŸš€ ìŠ¤íŠ¸ë¦¬ë° ì „ì‚¬ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    async for progress in transcriber.transcribe_streaming(
        session_id, test_audio, "gpt-4o-audio-preview", "ko"
    ):
        print(f"ğŸ“Š ì§„í–‰ë¥ : {progress.progress_percent:.1f}% - {progress.current_text[:50]}...")
        
        if progress.status == "completed":
            print("ğŸ‰ ìŠ¤íŠ¸ë¦¬ë° ì „ì‚¬ ì™„ë£Œ!")
            break
        elif progress.status == "error":
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {progress.error_message}")
            break


if __name__ == "__main__":
    asyncio.run(test_streaming_system())
